#!/usr/bin/env python3
"""
Aè‚¡å…¨ç»´åº¦æ•°æ®è·å–ç³»ç»Ÿ
åŸºäºTuShare Proæ¥å£è·å–åŸºæœ¬é¢ã€è´¢åŠ¡ã€èµ„é‡‘æµã€è‚¡ä¸œã€å…¬å‘Šç­‰å¤šç»´åº¦ä¿¡æ¯
"""
import pandas as pd
import tushare as ts
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import logging
import time
import sys, os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config
from utils.db_helper import db
from utils.comprehensive_data_schema import ComprehensiveDataSchema
from tqdm import tqdm
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

logger = logging.getLogger(__name__)

class ComprehensiveDataFetcher:
    """å…¨ç»´åº¦æ•°æ®è·å–å™¨"""
    
    def __init__(self):
        ts.set_token(config.TS_TOKEN)
        self.pro = ts.pro_api()
        self.rate_limit_delay = 60 / config.TS_RATE_LIMIT  # é™é¢‘å»¶è¿Ÿ
        self.schema = ComprehensiveDataSchema()
        
        # æ•°æ®æ›´æ–°é¢‘ç‡é…ç½®
        self.update_frequency = {
            'stock_basic': 'weekly',      # åŸºæœ¬ä¿¡æ¯æ¯å‘¨æ›´æ–°
            'financial': 'quarterly',    # è´¢åŠ¡æ•°æ®æ¯å­£åº¦æ›´æ–°  
            'money_flow': 'daily',       # èµ„é‡‘æµå‘æ¯æ—¥æ›´æ–°
            'holders': 'quarterly',      # è‚¡ä¸œä¿¡æ¯æ¯å­£åº¦æ›´æ–°
            'announcements': 'daily',    # å…¬å‘Šæ¯æ—¥æ›´æ–°
            'market_ext': 'daily',       # è¡Œæƒ…æ‰©å±•æ¯æ—¥æ›´æ–°
            'macro': 'monthly'           # å®è§‚æ•°æ®æ¯æœˆæ›´æ–°
        }
        
    def _clean_ann_date_data(self, df, required_cols=['ann_date']):
        """é€šç”¨æ•°æ®æ¸…æ´—æ–¹æ³•ï¼šå¤„ç†ann_dateç­‰å¿…éœ€å­—æ®µä¸ºç©ºçš„é—®é¢˜
        
        Args:
            df: åŸå§‹DataFrame
            required_cols: å¿…éœ€éç©ºçš„åˆ—ååˆ—è¡¨
            
        Returns:
            tuple: (æ¸…æ´—åçš„DataFrame, æ˜¯å¦æœ‰æ•ˆæ•°æ®)
        """
        if df.empty:
            return df, False
            
        # å¤„ç†æ—¥æœŸå­—æ®µ
        date_cols = [col for col in df.columns if 'date' in col.lower()]
        for col in date_cols:
            df[col] = pd.to_datetime(df[col], errors='coerce')
            
        # è¿‡æ»¤æ‰å¿…éœ€å­—æ®µä¸ºç©ºçš„è®°å½•
        initial_count = len(df)
        df_clean = df.dropna(subset=required_cols)
        final_count = len(df_clean)
        
        if initial_count > final_count:
            logger.warning(f"è¿‡æ»¤æ‰{initial_count - final_count}æ¡å¿…éœ€å­—æ®µä¸ºç©ºçš„è®°å½•")
            
        return df_clean, not df_clean.empty
            
    def fetch_all_comprehensive_data(self, mode='incremental'):
        """è·å–æ‰€æœ‰ç»´åº¦æ•°æ®
        
        Args:
            mode: 'full' å…¨é‡è·å–, 'incremental' å¢é‡æ›´æ–°
        """
        logger.info(f"ğŸš€ å¼€å§‹è·å–Aè‚¡å…¨ç»´åº¦æ•°æ® - æ¨¡å¼: {mode}")
        
        try:
            # 1. åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„
            logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„...")
            self.schema.create_all_tables(db)
            
            # 2. è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯(ä¼˜å…ˆçº§æœ€é«˜)
            self.fetch_basic_info_data(mode)
            
            # 3. å¹¶è¡Œè·å–å…¶ä»–ç»´åº¦æ•°æ®
            with ThreadPoolExecutor(max_workers=config.TS_THREAD_COUNT) as executor:
                futures = []
                
                # æäº¤å„ç±»æ•°æ®è·å–ä»»åŠ¡
                futures.append(executor.submit(self.fetch_financial_data, mode))
                futures.append(executor.submit(self.fetch_money_flow_data, mode))
                futures.append(executor.submit(self.fetch_shareholder_data, mode))
                futures.append(executor.submit(self.fetch_announcement_data, mode))
                futures.append(executor.submit(self.fetch_market_extension_data, mode))
                futures.append(executor.submit(self.fetch_macro_data, mode))
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                for future in as_completed(futures):
                    try:
                        result = future.result()
                        logger.info(f"âœ… æ•°æ®è·å–ä»»åŠ¡å®Œæˆ: {result}")
                    except Exception as e:
                        logger.error(f"âŒ æ•°æ®è·å–ä»»åŠ¡å¤±è´¥: {e}")
                        
            logger.info("ğŸ‰ å…¨ç»´åº¦æ•°æ®è·å–å®Œæˆ!")
            
        except Exception as e:
            logger.error(f"âŒ å…¨ç»´åº¦æ•°æ®è·å–å¤±è´¥: {e}")
            raise
            
    def fetch_basic_info_data(self, mode='incremental'):
        """è·å–åŸºæœ¬é¢ä¿¡æ¯æ•°æ®"""
        logger.info("ğŸ“Š å¼€å§‹è·å–åŸºæœ¬é¢ä¿¡æ¯æ•°æ®...")
        
        try:
            # 1. è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆå…è´¹æ¥å£ï¼‰
            self._fetch_stock_basic()
            
            # 2. åœå¤ç‰Œä¿¡æ¯ï¼ˆå…è´¹æ¥å£ï¼‰
            self._fetch_suspend_data()
            
            # 3. è¡Œä¸šåˆ†ç±»ä¿¡æ¯ï¼ˆä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼‰
            self._fetch_industry_classification()
            
            # 4. è·³è¿‡è‚¡æœ¬ç»“æ„ï¼ˆå¤ªè€—æ—¶ï¼Œå·²æœ‰27000+è®°å½•ï¼‰
            logger.info("â­ï¸ è·³è¿‡è‚¡æœ¬ç»“æ„æ•°æ®è·å–ï¼ˆå·²æœ‰å……è¶³æ•°æ®ï¼Œé¿å…é•¿æ—¶é—´è¿è¡Œï¼‰")
            
            logger.info("âœ… åŸºæœ¬é¢ä¿¡æ¯æ•°æ®è·å–å®Œæˆ")
            return "åŸºæœ¬é¢ä¿¡æ¯æ•°æ®è·å–å®Œæˆ"
            
        except Exception as e:
            logger.error(f"âŒ åŸºæœ¬é¢ä¿¡æ¯æ•°æ®è·å–å¤±è´¥: {e}")
            raise
            
    def _fetch_stock_basic(self):
        """è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        logger.info("ğŸ“‹ è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
        
        try:
            # è·å–åŸºæœ¬ä¿¡æ¯
            df = self.pro.stock_basic()  # ä¸æŒ‡å®šfieldsï¼Œè·å–æ‰€æœ‰å­—æ®µ
            
            if not df.empty:
                # TuShareå®é™…è¿”å›çš„å­—æ®µ: ts_code, symbol, name, area, industry, cnspell, market, list_date, act_name, act_ent_type
                # é€‰æ‹©è¡¨ä¸­å­˜åœ¨ä¸”æ¥å£è¿”å›çš„å­—æ®µ
                available_columns = list(df.columns)
                table_columns = ['ts_code', 'symbol', 'name', 'area', 'industry', 'market', 'list_date']
                
                # åªä¿ç•™å­˜åœ¨çš„å­—æ®µ
                df_filtered = df[table_columns].copy()
                
                # è½¬æ¢æ•°æ®æ ¼å¼
                df_filtered['list_date'] = pd.to_datetime(df_filtered['list_date'], errors='coerce')
                
                # æ·»åŠ ç¼ºå¤±çš„å­—æ®µè®¾ä¸ºé»˜è®¤å€¼
                df_filtered['fullname'] = None
                df_filtered['enname'] = None  
                df_filtered['exchange'] = None
                df_filtered['curr_type'] = None
                df_filtered['list_status'] = 'L'  # é»˜è®¤ä¸ºä¸Šå¸‚
                df_filtered['delist_date'] = None
                df_filtered['is_hs'] = None
                
                # æ‰¹é‡æ’å…¥æ•°æ®åº“
                success_count = db.upsert_dataframe(
                    df_filtered, 't_stock_basic', 
                    unique_cols=['ts_code'],
                    update_cols=['name', 'industry', 'area']
                )
                
                logger.info(f"âœ… è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æ’å…¥æˆåŠŸ: {success_count} æ¡")
            
            time.sleep(self.rate_limit_delay)
            
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
    def _fetch_suspend_data(self):
        """è·å–åœå¤ç‰Œä¿¡æ¯ï¼ˆå…è´¹æ¥å£ï¼‰"""
        logger.info("ğŸ›‘ è·å–åœå¤ç‰Œä¿¡æ¯...")
        
        try:
            from datetime import datetime, timedelta
            
            # è·å–æœ€è¿‘1å¹´çš„åœå¤ç‰Œæ•°æ®
            end_date = datetime.now()
            start_date = end_date - timedelta(days=365)
            
            df = self.pro.suspend_d(
                start_date=start_date.strftime('%Y%m%d'),
                end_date=end_date.strftime('%Y%m%d')
            )
            
            if not df.empty:
                # è½¬æ¢æ•°æ®æ ¼å¼ï¼ŒåŒ¹é…è¡¨ç»“æ„
                df['suspend_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d', errors='coerce')
                df['resume_date'] = None  # TuShareæ¥å£æ²¡æœ‰å¤ç‰Œæ—¥æœŸ
                df['ann_date'] = df['suspend_date']  # ä½¿ç”¨åœç‰Œæ—¥æœŸä½œä¸ºå…¬å‘Šæ—¥æœŸ
                df['suspend_reason'] = df['suspend_type']  # åœç‰Œç±»å‹ä½œä¸ºåŸå› 
                df['reason_type'] = df['suspend_timing']  # åœç‰Œæ—¶ç‚¹
                
                # é€‰æ‹©éœ€è¦çš„å­—æ®µ
                df_insert = df[['ts_code', 'suspend_date', 'resume_date', 'ann_date', 'suspend_reason', 'reason_type']].copy()
                
                success_count = db.upsert_dataframe(
                    df_insert, 't_suspend',
                    unique_cols=['ts_code', 'suspend_date'],
                    update_cols=['resume_date', 'suspend_reason', 'reason_type']
                )
                
                logger.info(f"âœ… åœå¤ç‰Œæ•°æ®æ’å…¥: {success_count} æ¡")
            else:
                logger.warning("âš ï¸ åœå¤ç‰Œæ•°æ®ä¸ºç©º")
                
        except Exception as e:
            logger.error(f"âŒ è·å–åœå¤ç‰Œä¿¡æ¯å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
    def _fetch_industry_classification(self):
        """è·å–è¡Œä¸šåˆ†ç±»ä¿¡æ¯"""
        logger.info("ğŸ­ è·å–è¡Œä¸šåˆ†ç±»ä¿¡æ¯...")
        
        try:
            # ä½¿ç”¨hs_constæ¥å£è·å–è¡Œä¸šåˆ†ç±»æ•°æ®
            logger.info("ğŸ“‹ è·å–ç”³ä¸‡è¡Œä¸šåˆ†ç±»...")
            
            # è·å–ç”³ä¸‡ä¸€çº§è¡Œä¸šåˆ†ç±»
            df_sw_l1 = self.pro.hs_const(hs_type='SW_L1')
            if not df_sw_l1.empty:
                df_sw_l1['classifier'] = 'SW2021'
                df_sw_l1['level'] = 'L1'
                df_sw_l1 = df_sw_l1.rename(columns={'code': 'industry_code', 'name': 'industry_name'})
                
                success_count = db.upsert_dataframe(
                    df_sw_l1[['ts_code', 'classifier', 'level', 'industry_code', 'industry_name']],
                    't_industry_classification',
                    unique_cols=['ts_code', 'classifier', 'level', 'industry_code']
                )
                logger.info(f"âœ… ç”³ä¸‡ä¸€çº§è¡Œä¸šæ’å…¥: {success_count} æ¡")
                return  # æˆåŠŸè·å–åˆ°æ•°æ®å°±è¿”å›
                
            # å¦‚æœç”³ä¸‡æ¥å£è¿”å›ç©ºæ•°æ®ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
            logger.warning("âš ï¸ ç”³ä¸‡è¡Œä¸šåˆ†ç±»è¿”å›ç©ºæ•°æ®ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
            self._use_basic_industry_as_fallback()
                
        except Exception as e:
            logger.error(f"âŒ è·å–è¡Œä¸šåˆ†ç±»ä¿¡æ¯å¤±è´¥: {e}")
            # ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
            self._use_basic_industry_as_fallback()
            
    def _use_basic_industry_as_fallback(self):
        """ä½¿ç”¨è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ä¸­çš„è¡Œä¸šä½œä¸ºå¤‡ç”¨åˆ†ç±»æ–¹æ¡ˆ"""
        logger.info("ğŸ”„ ä½¿ç”¨åŸºæœ¬ä¿¡æ¯ä¸­çš„è¡Œä¸šæ•°æ®ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ...")
        
        try:
            from sqlalchemy import text
            import pandas as pd
            
            # ä»stock_basicè¡¨æå–è¡Œä¸šä¿¡æ¯
            with db.engine.connect() as conn:
                sql = """
                SELECT ts_code, industry as industry_name, 
                       CONCAT('IND_', SUBSTRING(MD5(industry), 1, 8)) as industry_code
                FROM stock_basic 
                WHERE industry IS NOT NULL AND industry != ''
                """
                result = conn.execute(text(sql))
                rows = result.fetchall()
                
            if rows:
                # æ„å»ºDataFrameï¼ŒåŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ
                df_industry = pd.DataFrame(rows, columns=['ts_code', 'industry_name', 'industry_code'])
                df_industry['classifier'] = 'BASIC'
                df_industry['level'] = 'L1'
                df_industry['src'] = 'stock_basic'  # æ·»åŠ æ•°æ®æºå­—æ®µ
                df_industry['start_date'] = None  # å¯é€‰å­—æ®µè®¾ä¸ºNone
                df_industry['end_date'] = None
                df_industry['is_new'] = 'Y'
                
                success_count = db.upsert_dataframe(
                    df_industry, 't_industry_classification',
                    unique_cols=['ts_code', 'classifier', 'level', 'industry_code']
                )
                logger.info(f"âœ… åŸºæœ¬è¡Œä¸šåˆ†ç±»æ’å…¥: {success_count} æ¡")
            else:
                logger.warning("âš ï¸ åŸºæœ¬ä¿¡æ¯ä¸­ä¹Ÿæ— è¡Œä¸šæ•°æ®")
                
        except Exception as e:
            logger.error(f"âŒ å¤‡ç”¨è¡Œä¸šåˆ†ç±»æ–¹æ¡ˆå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
    def _fetch_index_components(self):
        """è·å–æŒ‡æ•°æˆåˆ†è‚¡"""
        logger.info("ğŸ“ˆ è·å–æŒ‡æ•°æˆåˆ†è‚¡ä¿¡æ¯...")
        
        try:
            # æš‚æ—¶è·³è¿‡æŒ‡æ•°æˆåˆ†è‚¡ï¼Œå› ä¸ºå¯èƒ½éœ€è¦æ›´é«˜æƒé™
            logger.info("â­ï¸ æš‚æ—¶è·³è¿‡æŒ‡æ•°æˆåˆ†è‚¡è·å–ï¼ˆéœ€è¦æ›´é«˜APIæƒé™ï¼‰")
            return
                
        except Exception as e:
            logger.error(f"âŒ è·å–æŒ‡æ•°æˆåˆ†è‚¡å¤±è´¥: {e}")
            
    def _fetch_share_structure(self):
        """è·å–è‚¡æœ¬ç»“æ„"""
        logger.info("ğŸ“ˆ è·å–è‚¡æœ¬ç»“æ„ä¿¡æ¯...")
        
        try:
            stock_codes = self._get_stock_codes()
            
            for i in tqdm(range(0, len(stock_codes), config.TS_BATCH_SIZE), 
                         desc="è‚¡æœ¬ç»“æ„"):
                batch_codes = stock_codes[i:i+config.TS_BATCH_SIZE]
                
                for ts_code in batch_codes:
                    try:
                        df = self.pro.share_float(
                            ts_code=ts_code,
                            fields='ts_code,ann_date,float_date,float_share,float_ratio,holder_num'
                        )
                        
                        if not df.empty:
                            # æ•°æ®æ¸…æ´—ï¼šç¡®ä¿ann_dateä¸ä¸ºç©º
                            df['ann_date'] = pd.to_datetime(df['ann_date'], errors='coerce')
                            df['float_date'] = pd.to_datetime(df['float_date'], errors='coerce')
                            
                            # è¿‡æ»¤æ‰ann_dateä¸ºç©ºçš„è®°å½•
                            df = df.dropna(subset=['ann_date'])
                            
                            if not df.empty:  # ç¡®ä¿è¿‡æ»¤åè¿˜æœ‰æ•°æ®
                                db.upsert_dataframe(
                                    df, 't_share_structure',
                                    unique_cols=['ts_code', 'ann_date']
                                )
                            else:
                                logger.warning(f"{ts_code}è‚¡æœ¬ç»“æ„æ•°æ®ann_dateå…¨ä¸ºç©ºï¼Œè·³è¿‡")
                            
                    except Exception as e:
                        logger.warning(f"è·å–{ts_code}è‚¡æœ¬ç»“æ„å¤±è´¥: {e}")
                        
                    time.sleep(self.rate_limit_delay)
                    
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡æœ¬ç»“æ„å¤±è´¥: {e}")
            
    def _fetch_company_managers(self):
        """è·å–å…¬å¸é«˜ç®¡ä¿¡æ¯"""
        logger.info("ğŸ‘¥ è·å–å…¬å¸é«˜ç®¡ä¿¡æ¯...")
        
        try:
            # æš‚æ—¶è·³è¿‡å…¬å¸é«˜ç®¡ä¿¡æ¯ï¼Œå› ä¸ºå¯èƒ½éœ€è¦æ›´é«˜æƒé™
            logger.info("â­ï¸ æš‚æ—¶è·³è¿‡å…¬å¸é«˜ç®¡ä¿¡æ¯è·å–ï¼ˆéœ€è¦æ›´é«˜APIæƒé™ï¼‰")
            return
                    
        except Exception as e:
            logger.error(f"âŒ è·å–å…¬å¸é«˜ç®¡ä¿¡æ¯å¤±è´¥: {e}")
            
    def fetch_financial_data(self, mode='incremental'):
        """è·å–è´¢åŠ¡ç±»ä¿¡æ¯æ•°æ®"""
        logger.info("ğŸ’¼ å¼€å§‹è·å–è´¢åŠ¡ç±»ä¿¡æ¯æ•°æ®...")
        
        try:
            # 1. èµ„äº§è´Ÿå€ºè¡¨
            self._fetch_balance_sheet()
            
            # 2. åˆ©æ¶¦è¡¨
            self._fetch_income_statement()
            
            # 3. ç°é‡‘æµé‡è¡¨
            self._fetch_cashflow_statement()
            
            # 4. è´¢åŠ¡æŒ‡æ ‡
            self._fetch_financial_indicators()
            
            # 5. ä¸šç»©é¢„å‘Š
            self._fetch_performance_forecast()
            
            # 6. ä¸šç»©å¿«æŠ¥
            self._fetch_performance_express()
            
            return "è´¢åŠ¡ç±»ä¿¡æ¯æ•°æ®è·å–å®Œæˆ"
            
        except Exception as e:
            logger.error(f"âŒ è´¢åŠ¡ç±»ä¿¡æ¯æ•°æ®è·å–å¤±è´¥: {e}")
            raise
            
    def _fetch_balance_sheet(self):
        """è·å–èµ„äº§è´Ÿå€ºè¡¨"""
        logger.info("ğŸ’° è·å–èµ„äº§è´Ÿå€ºè¡¨...")
        
        try:
            # è·å–æœ€è¿‘8ä¸ªå­£åº¦çš„èµ„äº§è´Ÿå€ºè¡¨
            for i in range(8):
                period = self._get_period_by_offset(i)
                logger.info(f"ğŸ“Š è·å–{period}æœŸèµ„äº§è´Ÿå€ºè¡¨...")
                
                df = self.pro.balancesheet(
                    period=period,
                    fields='ts_code,ann_date,end_date,total_share,cap_rese,undistr_porfit,'
                           'surplus_rese,special_rese,money_cap,trad_asset,notes_receiv,'
                           'accounts_receiv,oth_receiv,prepayment,div_receiv,int_receiv,'
                           'inventories,amor_exp,nca_within_1y,sett_rsrv,loanto_oth_bank_fi'
                )
                
                if not df.empty:
                    # ä½¿ç”¨é€šç”¨æ•°æ®æ¸…æ´—æ–¹æ³•
                    df_clean, has_data = self._clean_ann_date_data(df, ['ann_date'])
                    
                    if has_data:
                        success_count = db.upsert_dataframe(
                            df_clean, 't_balance_sheet',
                            unique_cols=['ts_code', 'ann_date', 'end_date']
                        )
                        
                        logger.info(f"âœ… {period}èµ„äº§è´Ÿå€ºè¡¨æ’å…¥: {success_count} æ¡")
                    else:
                        logger.warning(f"{period}èµ„äº§è´Ÿå€ºè¡¨æ•°æ®æ— æ•ˆï¼Œè·³è¿‡")
                        
                time.sleep(self.rate_limit_delay)
                
        except Exception as e:
            logger.error(f"âŒ è·å–èµ„äº§è´Ÿå€ºè¡¨å¤±è´¥: {e}")
            
    def _fetch_income_statement(self):
        """è·å–åˆ©æ¶¦è¡¨"""
        logger.info("ğŸ“ˆ è·å–åˆ©æ¶¦è¡¨...")
        
        try:
            # è·å–æœ€è¿‘8ä¸ªå­£åº¦çš„åˆ©æ¶¦è¡¨
            for i in range(8):
                period = self._get_period_by_offset(i)
                logger.info(f"ğŸ“Š è·å–{period}æœŸåˆ©æ¶¦è¡¨...")
                
                df = self.pro.income(
                    period=period,
                    fields='ts_code,ann_date,end_date,basic_eps,total_revenue,revenue,'
                           'int_income,prem_earned,comm_income,n_commis_income,n_oth_income,'
                           'n_oth_b_income,prem_income,out_prem,une_prem_reser,reins_income'
                )
                
                if not df.empty:
                    # ä½¿ç”¨é€šç”¨æ•°æ®æ¸…æ´—æ–¹æ³•
                    df_clean, has_data = self._clean_ann_date_data(df, ['ann_date'])
                    
                    if has_data:
                        success_count = db.upsert_dataframe(
                            df_clean, 't_income_statement',
                            unique_cols=['ts_code', 'ann_date', 'end_date']
                        )
                        
                        logger.info(f"âœ… {period}åˆ©æ¶¦è¡¨æ’å…¥: {success_count} æ¡")
                    else:
                        logger.warning(f"{period}åˆ©æ¶¦è¡¨æ•°æ®æ— æ•ˆï¼Œè·³è¿‡")
                        
                time.sleep(self.rate_limit_delay)
                
        except Exception as e:
            logger.error(f"âŒ è·å–åˆ©æ¶¦è¡¨å¤±è´¥: {e}")
            
    def _fetch_cashflow_statement(self):
        """è·å–ç°é‡‘æµé‡è¡¨"""
        logger.info("ğŸ’§ è·å–ç°é‡‘æµé‡è¡¨...")
        
        try:
            # è·å–æœ€è¿‘8ä¸ªå­£åº¦çš„ç°é‡‘æµé‡è¡¨
            for i in range(8):
                period = self._get_period_by_offset(i)
                logger.info(f"ğŸ“Š è·å–{period}æœŸç°é‡‘æµé‡è¡¨...")
                
                df = self.pro.cashflow(
                    period=period,
                    fields='ts_code,ann_date,end_date,net_profit,finan_exp,c_fr_sale_sg,'
                          'c_paid_goods_s,c_paid_to_for_empl,c_paid_for_taxes,n_cashflow_act,'
                          'c_paid_invest,n_cashflow_inv_act,c_recp_borrow,free_cashflow,'
                          'n_cash_flows_fnc_act,n_incr_cash_cash_equ'
                )
                
                if not df.empty:
                    # ä½¿ç”¨é€šç”¨æ•°æ®æ¸…æ´—æ–¹æ³•
                    df_clean, has_data = self._clean_ann_date_data(df, ['ann_date'])
                    
                    if has_data:
                        success_count = db.upsert_dataframe(
                            df_clean, 't_cashflow_statement',
                            unique_cols=['ts_code', 'ann_date', 'end_date']
                        )
                        
                        logger.info(f"âœ… {period}ç°é‡‘æµé‡è¡¨æ’å…¥: {success_count} æ¡")
                    else:
                        logger.warning(f"{period}ç°é‡‘æµé‡è¡¨æ•°æ®æ— æ•ˆï¼Œè·³è¿‡")
                    
                time.sleep(self.rate_limit_delay)
                
        except Exception as e:
            logger.error(f"âŒ è·å–ç°é‡‘æµé‡è¡¨å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
    def _fetch_financial_indicators(self):
        """è·å–è´¢åŠ¡æŒ‡æ ‡"""
        logger.info("ğŸ“ˆ è·å–è´¢åŠ¡æŒ‡æ ‡...")
        
        try:
            periods = self._get_recent_periods(8)
            
            for period in periods:
                logger.info(f"è·å–{period}è´¢åŠ¡æŒ‡æ ‡...")
                
                df = self.pro.fina_indicator(
                    period=period,
                    fields='ts_code,ann_date,end_date,eps,dt_eps,revenue_ps,bps,ocfps,'
                          'netprofit_margin,grossprofit_margin,current_ratio,quick_ratio,'
                          'ar_turn,ca_turn,fa_turn,assets_turn,roe,roe_waa,roa,roic,'
                          'debt_to_assets,assets_to_eqt,debt_to_eqt,current_exint,'
                          'noncurrent_exint,interestdebt,netdebt'
                )
                
                if not df.empty:
                    df['ann_date'] = pd.to_datetime(df['ann_date'], errors='coerce')
                    df['end_date'] = pd.to_datetime(df['end_date'], errors='coerce')
                    
                    success_count = db.upsert_dataframe(
                        df, 't_financial_indicators',
                        unique_cols=['ts_code', 'end_date']
                    )
                    
                    logger.info(f"âœ… {period}è´¢åŠ¡æŒ‡æ ‡æ’å…¥: {success_count} æ¡")
                    
                time.sleep(self.rate_limit_delay)
                
        except Exception as e:
            logger.error(f"âŒ è·å–è´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {e}")
            
    def _fetch_performance_forecast(self):
        """è·å–ä¸šç»©é¢„å‘Š"""
        logger.info("ğŸ“¢ è·å–ä¸šç»©é¢„å‘Š...")
        
        try:
            # è·å–æœ€è¿‘ä¸¤å¹´çš„ä¸šç»©é¢„å‘Š
            start_date = (datetime.now() - timedelta(days=730)).strftime('%Y%m%d')
            end_date = datetime.now().strftime('%Y%m%d')
            
            df = self.pro.forecast(
                start_date=start_date,
                end_date=end_date,
                fields='ts_code,ann_date,end_date,type,p_change_min,p_change_max,'
                      'net_profit_min,net_profit_max,last_parent_net,first_ann_date,summary'
            )
            
            if not df.empty:
                df['ann_date'] = pd.to_datetime(df['ann_date'], errors='coerce')
                df['end_date'] = pd.to_datetime(df['end_date'], errors='coerce')
                df['first_ann_date'] = pd.to_datetime(df['first_ann_date'], errors='coerce')
                
                success_count = db.upsert_dataframe(
                    df, 't_performance_forecast',
                    unique_cols=['ts_code', 'ann_date', 'end_date']
                )
                
                logger.info(f"âœ… ä¸šç»©é¢„å‘Šæ’å…¥: {success_count} æ¡")
                
        except Exception as e:
            logger.error(f"âŒ è·å–ä¸šç»©é¢„å‘Šå¤±è´¥: {e}")
            
    def _fetch_performance_express(self):
        """è·å–ä¸šç»©å¿«æŠ¥"""
        logger.info("âš¡ è·å–ä¸šç»©å¿«æŠ¥...")
        
        try:
            periods = self._get_recent_periods(4)  # æœ€è¿‘4ä¸ªå­£åº¦
            
            for period in periods:
                logger.info(f"è·å–{period}ä¸šç»©å¿«æŠ¥...")
                
                df = self.pro.express(
                    period=period,
                    fields='ts_code,ann_date,end_date,revenue,operate_profit,total_profit,'
                          'n_income,total_assets,total_hldr_eqy_exc_min_int,diluted_eps,'
                          'diluted_roe,yoy_net_profit,bps,yoy_sales,yoy_op'
                )
                
                if not df.empty:
                    df['ann_date'] = pd.to_datetime(df['ann_date'], errors='coerce')
                    df['end_date'] = pd.to_datetime(df['end_date'], errors='coerce')
                    
                    success_count = db.upsert_dataframe(
                        df, 't_performance_express',
                        unique_cols=['ts_code', 'ann_date', 'end_date']
                    )
                    
                    logger.info(f"âœ… {period}ä¸šç»©å¿«æŠ¥æ’å…¥: {success_count} æ¡")
                    
                time.sleep(self.rate_limit_delay)
                
        except Exception as e:
            logger.error(f"âŒ è·å–ä¸šç»©å¿«æŠ¥å¤±è´¥: {e}")
            
    def fetch_money_flow_data(self, mode='incremental'):
        """è·å–èµ„é‡‘æµå‘æ•°æ®"""
        logger.info("ğŸ’¸ å¼€å§‹è·å–èµ„é‡‘æµå‘æ•°æ®...")
        
        try:
            # 1. ä¸ªè‚¡èµ„é‡‘æµå‘
            self._fetch_money_flow()
            
            # 2. é¾™è™æ¦œæ•°æ®
            self._fetch_dragon_tiger_list()
            
            return "èµ„é‡‘æµå‘æ•°æ®è·å–å®Œæˆ"
            
        except Exception as e:
            logger.error(f"âŒ èµ„é‡‘æµå‘æ•°æ®è·å–å¤±è´¥: {e}")
            raise
            
    def _fetch_money_flow(self):
        """è·å–ä¸ªè‚¡èµ„é‡‘æµå‘"""
        logger.info("ğŸ”„ è·å–ä¸ªè‚¡èµ„é‡‘æµå‘...")
        
        try:
            # è·å–æœ€è¿‘30ä¸ªäº¤æ˜“æ—¥çš„èµ„é‡‘æµå‘
            start_date = (datetime.now() - timedelta(days=60)).strftime('%Y%m%d')
            end_date = datetime.now().strftime('%Y%m%d')
            
            stock_codes = self._get_active_stock_codes(500)  # è·å–æ´»è·ƒè‚¡ç¥¨
            
            for i in tqdm(range(0, len(stock_codes), config.TS_BATCH_SIZE), 
                         desc="ä¸ªè‚¡èµ„é‡‘æµå‘"):
                batch_codes = stock_codes[i:i+config.TS_BATCH_SIZE]
                
                for ts_code in batch_codes:
                    try:
                        df = self.pro.moneyflow(
                            ts_code=ts_code,
                            start_date=start_date,
                            end_date=end_date,
                            fields='ts_code,trade_date,buy_sm_vol,buy_sm_amount,sell_sm_vol,'
                                  'sell_sm_amount,buy_md_vol,buy_md_amount,sell_md_vol,'
                                  'sell_md_amount,buy_lg_vol,buy_lg_amount,sell_lg_vol,'
                                  'sell_lg_amount,buy_elg_vol,buy_elg_amount,sell_elg_vol,'
                                  'sell_elg_amount,net_mf_vol,net_mf_amount'
                        )
                        
                        if not df.empty:
                            df['trade_date'] = pd.to_datetime(df['trade_date'], errors='coerce')
                            
                            db.upsert_dataframe(
                                df, 't_money_flow',
                                unique_cols=['ts_code', 'trade_date']
                            )
                            
                    except Exception as e:
                        logger.warning(f"è·å–{ts_code}èµ„é‡‘æµå‘å¤±è´¥: {e}")
                        
                    time.sleep(self.rate_limit_delay)
                    
        except Exception as e:
            logger.error(f"âŒ è·å–ä¸ªè‚¡èµ„é‡‘æµå‘å¤±è´¥: {e}")
            
    def _fetch_dragon_tiger_list(self):
        """è·å–é¾™è™æ¦œæ•°æ®"""
        logger.info("ğŸ‰ è·å–é¾™è™æ¦œæ•°æ®...")
        
        try:
            # è·å–æœ€è¿‘30ä¸ªäº¤æ˜“æ—¥çš„é¾™è™æ¦œ
            start_date = (datetime.now() - timedelta(days=60)).strftime('%Y%m%d')
            end_date = datetime.now().strftime('%Y%m%d')
            
            df = self.pro.top_list(
                start_date=start_date,
                end_date=end_date,
                fields='trade_date,ts_code,name,close,pct_chg,turnover_rate,amount,'
                      'l_sell,l_buy,l_amount,net_amount,net_rate,amount_rate,reason'
            )
            
            if not df.empty:
                df['trade_date'] = pd.to_datetime(df['trade_date'], errors='coerce')
                
                success_count = db.upsert_dataframe(
                    df, 't_dragon_tiger_list',
                    unique_cols=['trade_date', 'ts_code']
                )
                
                logger.info(f"âœ… é¾™è™æ¦œæ•°æ®æ’å…¥: {success_count} æ¡")
                
        except Exception as e:
            logger.error(f"âŒ è·å–é¾™è™æ¦œæ•°æ®å¤±è´¥: {e}")
            
    def fetch_shareholder_data(self, mode='incremental'):
        """è·å–è‚¡ä¸œåŠè‚¡æƒå˜åŠ¨æ•°æ®"""
        logger.info("ğŸ‘¥ å¼€å§‹è·å–è‚¡ä¸œåŠè‚¡æƒå˜åŠ¨æ•°æ®...")
        
        try:
            # 1. åå¤§è‚¡ä¸œ
            self._fetch_top10_holders()
            
            # 2. åå¤§æµé€šè‚¡ä¸œ
            self._fetch_top10_float_holders()
            
            # 3. è‚¡ä¸œæˆ·æ•°
            self._fetch_holder_number()
            
            # 4. é™å”®è§£ç¦
            self._fetch_share_float()
            
            return "è‚¡ä¸œåŠè‚¡æƒå˜åŠ¨æ•°æ®è·å–å®Œæˆ"
            
        except Exception as e:
            logger.error(f"âŒ è‚¡ä¸œåŠè‚¡æƒå˜åŠ¨æ•°æ®è·å–å¤±è´¥: {e}")
            raise
            
    def _fetch_top10_holders(self):
        """è·å–åå¤§è‚¡ä¸œ"""
        logger.info("ğŸ”Ÿ è·å–åå¤§è‚¡ä¸œ...")
        
        try:
            periods = self._get_recent_periods(4)  # æœ€è¿‘4ä¸ªå­£åº¦
            
            for period in periods:
                logger.info(f"è·å–{period}åå¤§è‚¡ä¸œ...")
                
                df = self.pro.top10_holders(
                    period=period,
                    fields='ts_code,ann_date,end_date,holder_name,hold_amount,hold_ratio'
                )
                
                if not df.empty:
                    df['ann_date'] = pd.to_datetime(df['ann_date'], errors='coerce')
                    df['end_date'] = pd.to_datetime(df['end_date'], errors='coerce')
                    
                    success_count = db.upsert_dataframe(
                        df, 't_top10_holders',
                        unique_cols=['ts_code', 'end_date', 'holder_name']
                    )
                    
                    logger.info(f"âœ… {period}åå¤§è‚¡ä¸œæ’å…¥: {success_count} æ¡")
                    
                time.sleep(self.rate_limit_delay)
                
        except Exception as e:
            logger.error(f"âŒ è·å–åå¤§è‚¡ä¸œå¤±è´¥: {e}")
            
    def _fetch_top10_float_holders(self):
        """è·å–åå¤§æµé€šè‚¡ä¸œ"""
        logger.info("ğŸ”„ è·å–åå¤§æµé€šè‚¡ä¸œ...")
        
        try:
            periods = self._get_recent_periods(4)
            
            for period in periods:
                logger.info(f"è·å–{period}åå¤§æµé€šè‚¡ä¸œ...")
                
                df = self.pro.top10_floatholders(
                    period=period,
                    fields='ts_code,ann_date,end_date,holder_name,hold_amount,hold_ratio'
                )
                
                if not df.empty:
                    df['ann_date'] = pd.to_datetime(df['ann_date'], errors='coerce')
                    df['end_date'] = pd.to_datetime(df['end_date'], errors='coerce')
                    
                    success_count = db.upsert_dataframe(
                        df, 't_top10_float_holders',
                        unique_cols=['ts_code', 'end_date', 'holder_name']
                    )
                    
                    logger.info(f"âœ… {period}åå¤§æµé€šè‚¡ä¸œæ’å…¥: {success_count} æ¡")
                    
                time.sleep(self.rate_limit_delay)
                
        except Exception as e:
            logger.error(f"âŒ è·å–åå¤§æµé€šè‚¡ä¸œå¤±è´¥: {e}")
            
    def _fetch_holder_number(self):
        """è·å–è‚¡ä¸œæˆ·æ•°"""
        logger.info("ğŸ  è·å–è‚¡ä¸œæˆ·æ•°...")
        
        try:
            # è·å–æœ€è¿‘ä¸¤å¹´çš„è‚¡ä¸œæˆ·æ•°
            start_date = (datetime.now() - timedelta(days=730)).strftime('%Y%m%d')
            end_date = datetime.now().strftime('%Y%m%d')
            
            stock_codes = self._get_stock_codes()
            
            for i in tqdm(range(0, len(stock_codes), config.TS_BATCH_SIZE), 
                         desc="è‚¡ä¸œæˆ·æ•°"):
                batch_codes = stock_codes[i:i+config.TS_BATCH_SIZE]
                
                for ts_code in batch_codes:
                    try:
                        df = self.pro.stk_holdernumber(
                            ts_code=ts_code,
                            start_date=start_date,
                            end_date=end_date,
                            fields='ts_code,ann_date,end_date,holder_num'
                        )
                        
                        if not df.empty:
                            df['ann_date'] = pd.to_datetime(df['ann_date'], errors='coerce')
                            df['end_date'] = pd.to_datetime(df['end_date'], errors='coerce')
                            
                            db.upsert_dataframe(
                                df, 't_holder_number',
                                unique_cols=['ts_code', 'end_date']
                            )
                            
                    except Exception as e:
                        logger.warning(f"è·å–{ts_code}è‚¡ä¸œæˆ·æ•°å¤±è´¥: {e}")
                        
                    time.sleep(self.rate_limit_delay)
                    
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ä¸œæˆ·æ•°å¤±è´¥: {e}")
            
    def _fetch_share_float(self):
        """è·å–é™å”®è§£ç¦"""
        logger.info("ğŸ”“ è·å–é™å”®è§£ç¦...")
        
        try:
            # è·å–æœªæ¥ä¸€å¹´çš„è§£ç¦æ•°æ®
            start_date = datetime.now().strftime('%Y%m%d')
            end_date = (datetime.now() + timedelta(days=365)).strftime('%Y%m%d')
            
            df = self.pro.share_float(
                start_date=start_date,
                end_date=end_date,
                fields='ts_code,ann_date,float_date,float_share,float_ratio,holder_name,share_type'
            )
            
            if not df.empty:
                # æ•°æ®æ¸…æ´—ï¼šç¡®ä¿ann_dateä¸ä¸ºç©º
                df['ann_date'] = pd.to_datetime(df['ann_date'], errors='coerce')
                df['float_date'] = pd.to_datetime(df['float_date'], errors='coerce')
                
                # è¿‡æ»¤æ‰ann_dateä¸ºç©ºçš„è®°å½•
                df = df.dropna(subset=['ann_date'])
                
                if not df.empty:  # ç¡®ä¿è¿‡æ»¤åè¿˜æœ‰æ•°æ®
                    success_count = db.upsert_dataframe(
                        df, 't_share_float',
                        unique_cols=['ts_code', 'ann_date']
                    )
                    
                    logger.info(f"âœ… é™å”®è§£ç¦æ’å…¥: {success_count} æ¡")
                else:
                    logger.warning("é™å”®è§£ç¦æ•°æ®ann_dateå…¨ä¸ºç©ºï¼Œè·³è¿‡")
                    
        except Exception as e:
            logger.error(f"âŒ è·å–é™å”®è§£ç¦å¤±è´¥: {e}")
            
    def fetch_announcement_data(self, mode='incremental'):
        """è·å–å…¬å‘Šç±»ä¿¡æ¯æ•°æ®"""
        logger.info("ğŸ“¢ å¼€å§‹è·å–å…¬å‘Šç±»ä¿¡æ¯æ•°æ®...")
        
        try:
            # 1. åˆ†çº¢é€è‚¡
            self._fetch_dividend()
            
            # 2. è‚¡ç¥¨å›è´­
            self._fetch_repurchase()
            
            return "å…¬å‘Šç±»ä¿¡æ¯æ•°æ®è·å–å®Œæˆ"
            
        except Exception as e:
            logger.error(f"âŒ å…¬å‘Šç±»ä¿¡æ¯æ•°æ®è·å–å¤±è´¥: {e}")
            raise
            
    def _fetch_dividend(self):
        """è·å–åˆ†çº¢é€è‚¡"""
        logger.info("ğŸ’° è·å–åˆ†çº¢é€è‚¡...")
        
        try:
            # è·å–æœ€è¿‘ä¸‰å¹´çš„åˆ†çº¢æ•°æ®
            start_date = (datetime.now() - timedelta(days=1095)).strftime('%Y%m%d')
            end_date = datetime.now().strftime('%Y%m%d')
            
            df = self.pro.dividend(
                ann_date=start_date,
                end_date=end_date,
                fields='ts_code,end_date,ann_date,div_proc,stk_div,stk_bo_rate,'
                      'stk_co_rate,cash_div,cash_div_tax,record_date,ex_date,pay_date'
            )
            
            if not df.empty:
                df['end_date'] = pd.to_datetime(df['end_date'], errors='coerce')
                df['ann_date'] = pd.to_datetime(df['ann_date'], errors='coerce')
                df['record_date'] = pd.to_datetime(df['record_date'], errors='coerce')
                df['ex_date'] = pd.to_datetime(df['ex_date'], errors='coerce')
                df['pay_date'] = pd.to_datetime(df['pay_date'], errors='coerce')
                
                success_count = db.upsert_dataframe(
                    df, 't_dividend',
                    unique_cols=['ts_code', 'end_date', 'ann_date']
                )
                
                logger.info(f"âœ… åˆ†çº¢é€è‚¡æ’å…¥: {success_count} æ¡")
                
        except Exception as e:
            logger.error(f"âŒ è·å–åˆ†çº¢é€è‚¡å¤±è´¥: {e}")
            
    def _fetch_repurchase(self):
        """è·å–è‚¡ç¥¨å›è´­"""
        logger.info("ğŸ”„ è·å–è‚¡ç¥¨å›è´­...")
        
        try:
            # è·å–æœ€è¿‘ä¸¤å¹´çš„å›è´­æ•°æ®
            start_date = (datetime.now() - timedelta(days=730)).strftime('%Y%m%d')
            end_date = datetime.now().strftime('%Y%m%d')
            
            df = self.pro.repurchase(
                ann_date=start_date,
                end_date=end_date,
                fields='ts_code,ann_date,end_date,proc,exp_date,vol,amount,high_limit,low_limit'
            )
            
            if not df.empty:
                df['ann_date'] = pd.to_datetime(df['ann_date'], errors='coerce')
                df['end_date'] = pd.to_datetime(df['end_date'], errors='coerce')
                df['exp_date'] = pd.to_datetime(df['exp_date'], errors='coerce')
                
                success_count = db.upsert_dataframe(
                    df, 't_repurchase',
                    unique_cols=['ts_code', 'ann_date']
                )
                
                logger.info(f"âœ… è‚¡ç¥¨å›è´­æ’å…¥: {success_count} æ¡")
                
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨å›è´­å¤±è´¥: {e}")
            
    def fetch_market_extension_data(self, mode='incremental'):
        """è·å–è¡Œæƒ…æ‰©å±•æ•°æ®"""
        logger.info("ğŸ“Š å¼€å§‹è·å–è¡Œæƒ…æ‰©å±•æ•°æ®...")
        
        try:
            # 1. åœå¤ç‰Œ
            self._fetch_suspend()
            
            # 2. æ¶¨è·Œåœä»·æ ¼
            self._fetch_limit_price()
            
            # 3. æ¦‚å¿µåˆ†ç±»
            self._fetch_concept()
            
            return "è¡Œæƒ…æ‰©å±•æ•°æ®è·å–å®Œæˆ"
            
        except Exception as e:
            logger.error(f"âŒ è¡Œæƒ…æ‰©å±•æ•°æ®è·å–å¤±è´¥: {e}")
            raise
            
    def _fetch_suspend(self):
        """è·å–åœå¤ç‰Œ"""
        logger.info("â¸ï¸ è·å–åœå¤ç‰Œ...")
        
        try:
            # è·å–æœ€è¿‘ä¸€å¹´çš„åœå¤ç‰Œæ•°æ®
            start_date = (datetime.now() - timedelta(days=365)).strftime('%Y%m%d')
            end_date = datetime.now().strftime('%Y%m%d')
            
            df = self.pro.suspend_d(
                start_date=start_date,
                end_date=end_date,
                fields='ts_code,suspend_date,resume_date,ann_date,suspend_reason,reason_type'
            )
            
            if not df.empty:
                df['suspend_date'] = pd.to_datetime(df['suspend_date'], errors='coerce')
                df['resume_date'] = pd.to_datetime(df['resume_date'], errors='coerce')
                df['ann_date'] = pd.to_datetime(df['ann_date'], errors='coerce')
                
                success_count = db.upsert_dataframe(
                    df, 't_suspend',
                    unique_cols=['ts_code', 'suspend_date']
                )
                
                logger.info(f"âœ… åœå¤ç‰Œæ’å…¥: {success_count} æ¡")
                
        except Exception as e:
            logger.error(f"âŒ è·å–åœå¤ç‰Œå¤±è´¥: {e}")
            
    def _fetch_limit_price(self):
        """è·å–æ¶¨è·Œåœä»·æ ¼"""
        logger.info("ğŸ”º è·å–æ¶¨è·Œåœä»·æ ¼...")
        
        try:
            # è·å–æœ€è¿‘30ä¸ªäº¤æ˜“æ—¥çš„æ¶¨è·Œåœä»·æ ¼
            start_date = (datetime.now() - timedelta(days=60)).strftime('%Y%m%d')
            end_date = datetime.now().strftime('%Y%m%d')
            
            stock_codes = self._get_active_stock_codes(200)  # è·å–æ´»è·ƒè‚¡ç¥¨
            
            for i in tqdm(range(0, len(stock_codes), config.TS_BATCH_SIZE), 
                         desc="æ¶¨è·Œåœä»·æ ¼"):
                batch_codes = stock_codes[i:i+config.TS_BATCH_SIZE]
                
                for ts_code in batch_codes:
                    try:
                        df = self.pro.stk_limit(
                            ts_code=ts_code,
                            start_date=start_date,
                            end_date=end_date,
                            fields='ts_code,trade_date,up_limit,down_limit'
                        )
                        
                        if not df.empty:
                            df['trade_date'] = pd.to_datetime(df['trade_date'], errors='coerce')
                            
                            db.upsert_dataframe(
                                df, 't_limit_price',
                                unique_cols=['ts_code', 'trade_date']
                            )
                            
                    except Exception as e:
                        logger.warning(f"è·å–{ts_code}æ¶¨è·Œåœä»·æ ¼å¤±è´¥: {e}")
                        
                    time.sleep(self.rate_limit_delay)
                    
        except Exception as e:
            logger.error(f"âŒ è·å–æ¶¨è·Œåœä»·æ ¼å¤±è´¥: {e}")
            
    def _fetch_concept(self):
        """è·å–æ¦‚å¿µåˆ†ç±»"""
        logger.info("ğŸ’¡ è·å–æ¦‚å¿µåˆ†ç±»...")
        
        try:
            # 1. è·å–æ¦‚å¿µåˆ†ç±»åˆ—è¡¨
            concept_df = self.pro.concept(
                fields='code,name,src'
            )
            
            if not concept_df.empty:
                db.upsert_dataframe(
                    concept_df, 't_concept',
                    unique_cols=['code']
                )
                
                logger.info(f"âœ… æ¦‚å¿µåˆ†ç±»æ’å…¥: {len(concept_df)} æ¡")
                
            time.sleep(self.rate_limit_delay)
            
            # 2. è·å–æ¦‚å¿µè‚¡æ˜ç»†
            for _, concept in concept_df.iterrows():
                try:
                    detail_df = self.pro.concept_detail(
                        id=concept['code'],
                        fields='id,concept_name,ts_code,name,in_date,out_date'
                    )
                    
                    if not detail_df.empty:
                        detail_df['concept_code'] = concept['code']
                        detail_df['in_date'] = pd.to_datetime(detail_df['in_date'], errors='coerce')
                        detail_df['out_date'] = pd.to_datetime(detail_df['out_date'], errors='coerce')
                        
                        db.upsert_dataframe(
                            detail_df, 't_concept_detail',
                            unique_cols=['concept_code', 'ts_code']
                        )
                        
                except Exception as e:
                    logger.warning(f"è·å–æ¦‚å¿µ{concept['code']}æ˜ç»†å¤±è´¥: {e}")
                    
                time.sleep(self.rate_limit_delay)
                
        except Exception as e:
            logger.error(f"âŒ è·å–æ¦‚å¿µåˆ†ç±»å¤±è´¥: {e}")
            
    def fetch_macro_data(self, mode='incremental'):
        """è·å–å®è§‚ç»æµæ•°æ®"""
        logger.info("ğŸŒ å¼€å§‹è·å–å®è§‚ç»æµæ•°æ®...")
        
        try:
            # 1. æ²ªæ·±æ¸¯é€šèµ„é‡‘æµå‘
            self._fetch_money_flow_hsgt()
            
            # 2. èèµ„èåˆ¸æ˜ç»†
            self._fetch_margin_detail()
            
            # 3. å®è§‚ç»æµæŒ‡æ ‡
            self._fetch_macro_indicators()
            
            return "å®è§‚ç»æµæ•°æ®è·å–å®Œæˆ"
            
        except Exception as e:
            logger.error(f"âŒ å®è§‚ç»æµæ•°æ®è·å–å¤±è´¥: {e}")
            raise
            
    def _fetch_money_flow_hsgt(self):
        """è·å–æ²ªæ·±æ¸¯é€šèµ„é‡‘æµå‘"""
        logger.info("ğŸ”„ è·å–æ²ªæ·±æ¸¯é€šèµ„é‡‘æµå‘...")
        
        try:
            # è·å–æœ€è¿‘ä¸€å¹´çš„æ²ªæ·±æ¸¯é€šæ•°æ®
            start_date = (datetime.now() - timedelta(days=365)).strftime('%Y%m%d')
            end_date = datetime.now().strftime('%Y%m%d')
            
            df = self.pro.moneyflow_hsgt(
                start_date=start_date,
                end_date=end_date,
                fields='trade_date,ggt_ss,ggt_sz,hgt,sgt,north_money,south_money'
            )
            
            if not df.empty:
                df['trade_date'] = pd.to_datetime(df['trade_date'], errors='coerce')
                
                success_count = db.upsert_dataframe(
                    df, 't_money_flow_hsgt',
                    unique_cols=['trade_date']
                )
                
                logger.info(f"âœ… æ²ªæ·±æ¸¯é€šèµ„é‡‘æµå‘æ’å…¥: {success_count} æ¡")
                
        except Exception as e:
            logger.error(f"âŒ è·å–æ²ªæ·±æ¸¯é€šèµ„é‡‘æµå‘å¤±è´¥: {e}")
            
    def _fetch_margin_detail(self):
        """è·å–èèµ„èåˆ¸æ˜ç»†"""
        logger.info("ğŸ“Š è·å–èèµ„èåˆ¸æ˜ç»†...")
        
        try:
            # è·å–æœ€è¿‘ä¸€å¹´çš„èèµ„èåˆ¸æ•°æ®
            start_date = (datetime.now() - timedelta(days=365)).strftime('%Y%m%d')
            end_date = datetime.now().strftime('%Y%m%d')
            
            df = self.pro.margin_detail(
                start_date=start_date,
                end_date=end_date,
                fields='trade_date,ts_code,rzye,rqye,rzmre,rqmcl,rzche,rqchl,rqyl,rzrqye'
            )
            
            if not df.empty:
                df['trade_date'] = pd.to_datetime(df['trade_date'], errors='coerce')
                
                success_count = db.upsert_dataframe(
                    df, 't_margin_detail',
                    unique_cols=['trade_date', 'ts_code']
                )
                
                logger.info(f"âœ… èèµ„èåˆ¸æ˜ç»†æ’å…¥: {success_count} æ¡")
                
        except Exception as e:
            logger.error(f"âŒ è·å–èèµ„èåˆ¸æ˜ç»†å¤±è´¥: {e}")
            
    def _fetch_macro_indicators(self):
        """è·å–å®è§‚ç»æµæŒ‡æ ‡"""
        logger.info("ğŸ“ˆ è·å–å®è§‚ç»æµæŒ‡æ ‡...")
        
        try:
            # å®è§‚æŒ‡æ ‡åˆ—è¡¨
            macro_indicators = [
                ('shibor', 'SHIBORåˆ©ç‡'),
                ('libor', 'LIBORåˆ©ç‡'),
                ('hibor', 'HIBORåˆ©ç‡'),
                ('cpi', 'CPI'),
                ('ppi', 'PPI'),
                ('gdp', 'GDP'),
                ('us_tltyield', 'ç¾å›½å›½å€ºæ”¶ç›Šç‡'),
                ('cn_gdp', 'ä¸­å›½GDP'),
                ('cn_ppi', 'ä¸­å›½PPI'),
                ('cn_cpi', 'ä¸­å›½CPI'),
                ('cn_m', 'ä¸­å›½è´§å¸ä¾›åº”é‡'),
            ]
            
            for indicator_code, indicator_name in macro_indicators:
                try:
                    # è·å–æœ€è¿‘ä¸¤å¹´çš„å®è§‚æ•°æ®
                    start_m = (datetime.now() - timedelta(days=730)).strftime('%Y%m')
                    end_m = datetime.now().strftime('%Y%m')
                    
                    # åŠ¨æ€è°ƒç”¨ä¸åŒçš„å®è§‚æŒ‡æ ‡æ¥å£
                    if hasattr(self.pro, indicator_code):
                        func = getattr(self.pro, indicator_code)
                        df = func(start_m=start_m, end_m=end_m)
                        
                        if not df.empty:
                            # æ ‡å‡†åŒ–æ•°æ®æ ¼å¼
                            df['indicator_name'] = indicator_name
                            df['indicator_code'] = indicator_code
                            
                            # è·å–æ•°å€¼åˆ—
                            value_cols = [col for col in df.columns 
                                        if col not in ['m', 'indicator_name', 'indicator_code']]
                            
                            # è½¬æ¢ä¸ºé•¿æ ¼å¼
                            long_df = pd.melt(df, 
                                            id_vars=['m', 'indicator_name', 'indicator_code'],
                                            value_vars=value_cols,
                                            var_name='sub_indicator',
                                            value_name='value')
                            
                            long_df['m'] = pd.to_datetime(long_df['m'], format='%Y%m', errors='coerce')
                            
                            db.upsert_dataframe(
                                long_df, 't_macro_indicators',
                                unique_cols=['m', 'indicator_code']
                            )
                            
                            logger.info(f"âœ… {indicator_name}æ’å…¥: {len(long_df)} æ¡")
                            
                except Exception as e:
                    logger.warning(f"è·å–{indicator_name}å¤±è´¥: {e}")
                    
                time.sleep(self.rate_limit_delay)
                
        except Exception as e:
            logger.error(f"âŒ è·å–å®è§‚ç»æµæŒ‡æ ‡å¤±è´¥: {e}")
            
    # ===================è¾…åŠ©æ–¹æ³•===================
    
    def _get_stock_codes(self) -> List[str]:
        """è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç """
        try:
            df = self.pro.stock_basic(list_status='L', fields='ts_code')
            return df['ts_code'].tolist()
        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨ä»£ç å¤±è´¥: {e}")
            return []
            
    def _get_active_stock_codes(self, limit: int = 500) -> List[str]:
        """è·å–æ´»è·ƒè‚¡ç¥¨ä»£ç """
        try:
            # å¯ä»¥æ ¹æ®æˆäº¤é¢ã€æ¢æ‰‹ç‡ç­‰ç­›é€‰æ´»è·ƒè‚¡ç¥¨
            df = self.pro.stock_basic(list_status='L', fields='ts_code')
            return df['ts_code'].head(limit).tolist()
        except Exception as e:
            logger.error(f"è·å–æ´»è·ƒè‚¡ç¥¨ä»£ç å¤±è´¥: {e}")
            return []
            
    def _get_recent_periods(self, count: int = 8) -> List[str]:
        """è·å–æœ€è¿‘çš„æŠ¥å‘ŠæœŸ"""
        periods = []
        current_date = datetime.now()
        
        for i in range(count):
            # è®¡ç®—å­£åº¦
            year = current_date.year
            month = current_date.month
            
            if month <= 3:
                quarter = 1
            elif month <= 6:
                quarter = 2
            elif month <= 9:
                quarter = 3
            else:
                quarter = 4
                
            # å‘å‰æ¨ç§»å­£åº¦
            quarter -= i
            while quarter <= 0:
                quarter += 4
                year -= 1
                
            # è½¬æ¢ä¸ºæœŸæœ«æ—¥æœŸ
            if quarter == 1:
                period_end = f"{year}0331"
            elif quarter == 2:
                period_end = f"{year}0630"
            elif quarter == 3:
                period_end = f"{year}0930"
            else:
                period_end = f"{year}1231"
                
            periods.append(period_end)
            
        return periods
        
    def _get_period_by_offset(self, offset=0):
        """æ ¹æ®åç§»é‡è·å–æŠ¥å‘ŠæœŸï¼ˆ0ä¸ºæœ€è¿‘ä¸€æœŸï¼‰"""
        current_date = datetime.now()
        year = current_date.year
        month = current_date.month
        
        if month <= 3:
            quarter = 1
        elif month <= 6:
            quarter = 2
        elif month <= 9:
            quarter = 3
        else:
            quarter = 4
            
        # å‘å‰æ¨ç§»å­£åº¦
        quarter -= offset
        while quarter <= 0:
            quarter += 4
            year -= 1
            
        # è½¬æ¢ä¸ºæœŸæœ«æ—¥æœŸ
        if quarter == 1:
            return f"{year}0331"
        elif quarter == 2:
            return f"{year}0630"
        elif quarter == 3:
            return f"{year}0930"
        else:
            return f"{year}1231"
        
    def _get_stock_name(self, ts_code: str) -> str:
        """è·å–è‚¡ç¥¨åç§°"""
        try:
            df = self.pro.stock_basic(ts_code=ts_code, fields='name')
            return df['name'].iloc[0] if not df.empty else ts_code
        except:
            return ts_code
            
    def _get_index_name(self, index_code: str) -> str:
        """è·å–æŒ‡æ•°åç§°"""
        index_names = {
            '000001.SH': 'ä¸Šè¯æŒ‡æ•°',
            '000300.SH': 'æ²ªæ·±300',
            '000905.SH': 'ä¸­è¯500',
            '399001.SZ': 'æ·±è¯æˆæŒ‡',
            '399006.SZ': 'åˆ›ä¸šæ¿æŒ‡',
            '000016.SH': 'ä¸Šè¯50',
        }
        return index_names.get(index_code, index_code)

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Aè‚¡å…¨ç»´åº¦æ•°æ®è·å–ç³»ç»Ÿ')
    parser.add_argument('--mode', choices=['full', 'incremental'], default='incremental',
                       help='è·å–æ¨¡å¼: full=å…¨é‡è·å–, incremental=å¢é‡æ›´æ–°')
    parser.add_argument('--category', choices=['basic', 'financial', 'money_flow', 
                                              'shareholder', 'announcement', 'market_ext', 'macro', 'all'],
                       default='all', help='æ•°æ®ç±»åˆ«')
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('logs/comprehensive_data_fetch.log', encoding='utf-8')
        ]
    )
    
    fetcher = ComprehensiveDataFetcher()
    
    try:
        if args.category == 'all':
            fetcher.fetch_all_comprehensive_data(args.mode)
        elif args.category == 'basic':
            fetcher.fetch_basic_info_data(args.mode)
        elif args.category == 'financial':
            fetcher.fetch_financial_data(args.mode)
        elif args.category == 'money_flow':
            fetcher.fetch_money_flow_data(args.mode)
        elif args.category == 'shareholder':
            fetcher.fetch_shareholder_data(args.mode)
        elif args.category == 'announcement':
            fetcher.fetch_announcement_data(args.mode)
        elif args.category == 'market_ext':
            fetcher.fetch_market_extension_data(args.mode)
        elif args.category == 'macro':
            fetcher.fetch_macro_data(args.mode)
            
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    main() 