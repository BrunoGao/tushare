"""
TuShareå†å²æ•°æ®æå–å™¨
ç”¨äºç”Ÿæˆå¤§æ¨¡å‹è®­ç»ƒæ•°æ®é›†
"""

import pandas as pd
import tushare as ts
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import numpy as np
import time
import os

class TuShareDataExtractor:
    """TuShareå†å²æ•°æ®æå–å™¨"""
    
    def __init__(self, token: Optional[str] = None):
        """
        åˆå§‹åŒ–TuShareæ•°æ®æå–å™¨
        
        Args:
            token: TuShare Pro API tokenï¼Œå¦‚æœä¸ºNoneå°†å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        """
        self.token = token or os.getenv('TUSHARE_TOKEN')
        if self.token:
            ts.set_token(self.token)
            self.pro = ts.pro_api()
            logging.info("âœ… TuShare Pro APIå·²åˆå§‹åŒ–")
        else:
            logging.warning("âš ï¸ æœªè®¾ç½®TuShare Pro tokenï¼Œå°†ä½¿ç”¨å…è´¹æ¥å£")
            self.pro = None
        
        self.logger = logging.getLogger(__name__)
        
    def get_stock_list(self, exchange: str = None, limit: int = 100) -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨åˆ—è¡¨
        
        Args:
            exchange: äº¤æ˜“æ‰€ä»£ç  (SSE, SZSE)
            limit: è·å–æ•°é‡é™åˆ¶
            
        Returns:
            è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯DataFrame
        """
        try:
            if self.pro:
                # ä½¿ç”¨Pro API
                if exchange:
                    stocks = self.pro.stock_basic(exchange=exchange, fields='ts_code,symbol,name,area,industry,list_date')
                else:
                    stocks = self.pro.stock_basic(fields='ts_code,symbol,name,area,industry,list_date')
            else:
                # ä½¿ç”¨å…è´¹API
                stocks = ts.get_stock_basics()
                stocks.reset_index(inplace=True)
                stocks.rename(columns={'code': 'ts_code', 'name': 'name'}, inplace=True)
            
            if limit:
                stocks = stocks.head(limit)
                
            self.logger.info(f"âœ… è·å–è‚¡ç¥¨åˆ—è¡¨æˆåŠŸ: {len(stocks)}åªè‚¡ç¥¨")
            return stocks
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_stock_daily_data(self, ts_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨æ—¥çº¿æ•°æ®
        
        Args:
            ts_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ YYYYMMDD
            end_date: ç»“æŸæ—¥æœŸ YYYYMMDD
            
        Returns:
            æ—¥çº¿æ•°æ®DataFrame
        """
        max_retries = 3
        retry_delay = 1.0
        
        for attempt in range(max_retries):
            try:
                if self.pro:
                    # ä½¿ç”¨Pro API
                    df = self.pro.daily(ts_code=ts_code, start_date=start_date, end_date=end_date)
                else:
                    # ä½¿ç”¨å…è´¹API - æ ¼å¼åŒ–æ—¥æœŸ
                    formatted_start = f"{start_date[:4]}-{start_date[4:6]}-{start_date[6:]}"
                    formatted_end = f"{end_date[:4]}-{end_date[4:6]}-{end_date[6:]}"
                    code = ts_code.split('.')[0]  # æå–è‚¡ç¥¨ä»£ç 
                    df = ts.get_hist_data(code, start=formatted_start, end=formatted_end)
                    if not df.empty:
                        df.reset_index(inplace=True)
                        df['ts_code'] = ts_code
                        df.rename(columns={'date': 'trade_date'}, inplace=True)
                
                if not df.empty:
                    df['trade_date'] = pd.to_datetime(df['trade_date'])
                    df = df.sort_values('trade_date')
                    
                time.sleep(0.2)  # å¢åŠ å»¶è¿Ÿé¿å…é¢‘ç‡é™åˆ¶
                return df
                
            except Exception as e:
                if attempt < max_retries - 1:
                    self.logger.warning(f"è·å–{ts_code}æ•°æ®å¤±è´¥ (å°è¯•{attempt+1}/{max_retries}): {e}, é‡è¯•ä¸­...")
                    time.sleep(retry_delay * (attempt + 1))
                else:
                    self.logger.error(f"âŒ è·å–{ts_code}æ—¥çº¿æ•°æ®å¤±è´¥: {e}")
                    return pd.DataFrame()
    
    def get_stock_financial_data(self, ts_code: str, periods: List[str] = None) -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨è´¢åŠ¡æ•°æ®
        
        Args:
            ts_code: è‚¡ç¥¨ä»£ç 
            periods: æŠ¥å‘ŠæœŸåˆ—è¡¨
            
        Returns:
            è´¢åŠ¡æ•°æ®DataFrame
        """
        if not self.pro:
            return pd.DataFrame()
            
        try:
            # è·å–åˆ©æ¶¦è¡¨
            income = self.pro.income(ts_code=ts_code, fields='ts_code,ann_date,f_ann_date,end_date,total_revenue,total_cogs,n_income')
            # è·å–èµ„äº§è´Ÿå€ºè¡¨  
            balancesheet = self.pro.balancesheet(ts_code=ts_code, fields='ts_code,ann_date,f_ann_date,end_date,total_assets,total_liab,total_equity')
            # è·å–ç°é‡‘æµé‡è¡¨
            cashflow = self.pro.cashflow(ts_code=ts_code, fields='ts_code,ann_date,f_ann_date,end_date,n_cashflow_act,n_cashflow_inv,n_cashflow_fin')
            
            # åˆå¹¶è´¢åŠ¡æ•°æ®
            financial_data = income
            if not balancesheet.empty:
                financial_data = financial_data.merge(balancesheet, on=['ts_code', 'ann_date', 'end_date'], how='outer')
            if not cashflow.empty:
                financial_data = financial_data.merge(cashflow, on=['ts_code', 'ann_date', 'end_date'], how='outer')
                
            time.sleep(0.2)  # é¿å…é¢‘ç‡é™åˆ¶
            return financial_data
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–{ts_code}è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_market_news(self, start_date: str, end_date: str, limit: int = 1000) -> pd.DataFrame:
        """
        è·å–å¸‚åœºæ–°é—»æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            limit: è·å–æ•°é‡é™åˆ¶
            
        Returns:
            æ–°é—»æ•°æ®DataFrame
        """
        if not self.pro:
            return pd.DataFrame()
            
        try:
            news = self.pro.news(start_date=start_date, end_date=end_date, limit=limit,
                               fields='datetime,title,content,channels,score')
            if not news.empty:
                news['datetime'] = pd.to_datetime(news['datetime'])
                
            time.sleep(0.1)
            return news
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–å¸‚åœºæ–°é—»å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def extract_comprehensive_dataset(self, 
                                    stock_codes: List[str], 
                                    start_date: str, 
                                    end_date: str,
                                    include_financial: bool = True,
                                    include_news: bool = True) -> Dict[str, pd.DataFrame]:
        """
        æå–ç»¼åˆæ•°æ®é›†
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ YYYYMMDD
            end_date: ç»“æŸæ—¥æœŸ YYYYMMDD
            include_financial: æ˜¯å¦åŒ…å«è´¢åŠ¡æ•°æ®
            include_news: æ˜¯å¦åŒ…å«æ–°é—»æ•°æ®
            
        Returns:
            åŒ…å«å„ç±»æ•°æ®çš„å­—å…¸
        """
        dataset = {
            'daily_data': [],
            'financial_data': [],
            'news_data': [],
            'metadata': {
                'extraction_date': datetime.now().isoformat(),
                'date_range': {'start': start_date, 'end': end_date},
                'stock_count': len(stock_codes),
                'data_types': []
            }
        }
        
        self.logger.info(f"ğŸš€ å¼€å§‹æå–{len(stock_codes)}åªè‚¡ç¥¨çš„ç»¼åˆæ•°æ®é›†")
        
        # 1. æå–æ—¥çº¿æ•°æ®
        self.logger.info("ğŸ“Š æå–æ—¥çº¿æ•°æ®...")
        for i, ts_code in enumerate(stock_codes):
            self.logger.info(f"  å¤„ç† {ts_code} ({i+1}/{len(stock_codes)})")
            
            daily_data = self.get_stock_daily_data(ts_code, start_date, end_date)
            if not daily_data.empty:
                dataset['daily_data'].append(daily_data)
                
            # è´¢åŠ¡æ•°æ®
            if include_financial:
                financial_data = self.get_stock_financial_data(ts_code)
                if not financial_data.empty:
                    dataset['financial_data'].append(financial_data)
        
        # 2. æå–å¸‚åœºæ–°é—»
        if include_news:
            self.logger.info("ğŸ“° æå–å¸‚åœºæ–°é—»...")
            news_data = self.get_market_news(start_date, end_date)
            if not news_data.empty:
                dataset['news_data'] = news_data
        
        # 3. åˆå¹¶æ•°æ®
        if dataset['daily_data']:
            dataset['daily_data'] = pd.concat(dataset['daily_data'], ignore_index=True)
            dataset['metadata']['data_types'].append('daily_price')
            
        if dataset['financial_data']:
            dataset['financial_data'] = pd.concat(dataset['financial_data'], ignore_index=True)
            dataset['metadata']['data_types'].append('financial')
            
        if isinstance(dataset['news_data'], pd.DataFrame) and not dataset['news_data'].empty:
            dataset['metadata']['data_types'].append('news')
        
        self.logger.info(f"âœ… æ•°æ®æå–å®Œæˆï¼")
        self.logger.info(f"  æ—¥çº¿æ•°æ®: {len(dataset['daily_data']) if isinstance(dataset['daily_data'], pd.DataFrame) else 0}æ¡")
        self.logger.info(f"  è´¢åŠ¡æ•°æ®: {len(dataset['financial_data']) if isinstance(dataset['financial_data'], pd.DataFrame) else 0}æ¡")
        self.logger.info(f"  æ–°é—»æ•°æ®: {len(dataset['news_data']) if isinstance(dataset['news_data'], pd.DataFrame) else 0}æ¡")
        
        return dataset
    
    def save_dataset(self, dataset: Dict, output_dir: str = "data/tushare_dataset"):
        """
        ä¿å­˜æ•°æ®é›†åˆ°æ–‡ä»¶
        
        Args:
            dataset: æ•°æ®é›†å­—å…¸
            output_dir: è¾“å‡ºç›®å½•
        """
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜å„ç±»æ•°æ®
        if isinstance(dataset['daily_data'], pd.DataFrame) and not dataset['daily_data'].empty:
            daily_path = f"{output_dir}/daily_data_{timestamp}.csv"
            dataset['daily_data'].to_csv(daily_path, index=False, encoding='utf-8')
            self.logger.info(f"âœ… æ—¥çº¿æ•°æ®å·²ä¿å­˜: {daily_path}")
            
        if isinstance(dataset['financial_data'], pd.DataFrame) and not dataset['financial_data'].empty:
            financial_path = f"{output_dir}/financial_data_{timestamp}.csv"
            dataset['financial_data'].to_csv(financial_path, index=False, encoding='utf-8')
            self.logger.info(f"âœ… è´¢åŠ¡æ•°æ®å·²ä¿å­˜: {financial_path}")
            
        if isinstance(dataset['news_data'], pd.DataFrame) and not dataset['news_data'].empty:
            news_path = f"{output_dir}/news_data_{timestamp}.csv"
            dataset['news_data'].to_csv(news_path, index=False, encoding='utf-8')
            self.logger.info(f"âœ… æ–°é—»æ•°æ®å·²ä¿å­˜: {news_path}")
            
        # ä¿å­˜å…ƒæ•°æ®
        metadata_path = f"{output_dir}/metadata_{timestamp}.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(dataset['metadata'], f, ensure_ascii=False, indent=2)
        self.logger.info(f"âœ… å…ƒæ•°æ®å·²ä¿å­˜: {metadata_path}")


def main():
    """æµ‹è¯•æ•°æ®æå–å™¨"""
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # åˆå§‹åŒ–æå–å™¨
    extractor = TuShareDataExtractor()
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    stocks = extractor.get_stock_list(limit=10)  # æµ‹è¯•ç”¨ï¼Œåªå–10åªè‚¡ç¥¨
    if stocks.empty:
        print("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
        return
    
    stock_codes = stocks['ts_code'].tolist() if 'ts_code' in stocks.columns else stocks.index.tolist()
    
    # è®¾ç½®æ—¥æœŸèŒƒå›´ï¼ˆæœ€è¿‘6ä¸ªæœˆï¼‰
    end_date = datetime.now().strftime('%Y%m%d')
    start_date = (datetime.now() - timedelta(days=180)).strftime('%Y%m%d')
    
    print(f"ğŸ“… æå–æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date}")
    print(f"ğŸ“ˆ è‚¡ç¥¨åˆ—è¡¨: {stock_codes[:5]}...")  # æ˜¾ç¤ºå‰5åª
    
    # æå–æ•°æ®é›†
    dataset = extractor.extract_comprehensive_dataset(
        stock_codes=stock_codes,
        start_date=start_date,
        end_date=end_date,
        include_financial=False,  # æµ‹è¯•æ—¶ä¸åŒ…å«è´¢åŠ¡æ•°æ®
        include_news=False       # æµ‹è¯•æ—¶ä¸åŒ…å«æ–°é—»æ•°æ®
    )
    
    # ä¿å­˜æ•°æ®é›†
    extractor.save_dataset(dataset)
    
    print("âœ… æ•°æ®æå–æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main()