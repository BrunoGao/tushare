"""
å¤§æ¨¡å‹è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨
å°†TuShareå†å²æ•°æ®è½¬æ¢ä¸ºé€‚åˆå¤§æ¨¡å‹è®­ç»ƒçš„æ ¼å¼
"""

import pandas as pd
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import numpy as np
import os
from dataclasses import dataclass

@dataclass
class TrainingExample:
    """è®­ç»ƒæ ·æœ¬æ•°æ®ç»“æ„"""
    instruction: str
    input: str
    output: str
    metadata: Dict[str, Any]

class LLMTrainingDataGenerator:
    """å¤§æ¨¡å‹è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # å®šä¹‰å„ç§æç¤ºæ¨¡æ¿
        self.prompt_templates = {
            'stock_analysis': [
                "åˆ†æä»¥ä¸‹è‚¡ç¥¨çš„æŠ€æœ¯æŒ‡æ ‡å’Œä»·æ ¼èµ°åŠ¿ï¼Œå¹¶ç»™å‡ºæŠ•èµ„å»ºè®®ï¼š",
                "æ ¹æ®æä¾›çš„è‚¡ç¥¨æ•°æ®ï¼Œåˆ†æè¯¥è‚¡ç¥¨çš„æŠ•èµ„ä»·å€¼ï¼š",
                "è¯·å¯¹ä»¥ä¸‹è‚¡ç¥¨æ•°æ®è¿›è¡Œä¸“ä¸šåˆ†æï¼š",
                "åŸºäºå†å²æ•°æ®ï¼Œè¯„ä¼°è¿™åªè‚¡ç¥¨çš„æŠ•èµ„æ½œåŠ›ï¼š"
            ],
            'price_prediction': [
                "æ ¹æ®å†å²ä»·æ ¼æ•°æ®ï¼Œé¢„æµ‹è¯¥è‚¡ç¥¨æœªæ¥çš„ä»·æ ¼è¶‹åŠ¿ï¼š",
                "åˆ†æä»·æ ¼èµ°åŠ¿å¹¶é¢„æµ‹çŸ­æœŸå†…çš„ä»·æ ¼å˜åŒ–ï¼š",
                "åŸºäºæŠ€æœ¯åˆ†æï¼Œåˆ¤æ–­è‚¡ç¥¨åç»­èµ°åŠ¿ï¼š",
                "è¯·é¢„æµ‹è¯¥è‚¡ç¥¨åœ¨æœªæ¥å‡ ä¸ªäº¤æ˜“æ—¥çš„è¡¨ç°ï¼š"
            ],
            'market_sentiment': [
                "åˆ†æå¸‚åœºæƒ…ç»ªå¯¹è¯¥è‚¡ç¥¨ä»·æ ¼çš„å½±å“ï¼š",
                "è¯„ä¼°å½“å‰å¸‚åœºç¯å¢ƒä¸‹çš„æŠ•èµ„ç­–ç•¥ï¼š",
                "è§£è¯»å¸‚åœºä¿¡å·å¹¶æä¾›äº¤æ˜“å»ºè®®ï¼š",
                "åˆ†æå¸‚åœºè¶‹åŠ¿å¯¹è¯¥è‚¡ç¥¨çš„æ½œåœ¨å½±å“ï¼š"
            ],
            'risk_assessment': [
                "è¯„ä¼°æŠ•èµ„è¯¥è‚¡ç¥¨çš„é£é™©ç­‰çº§ï¼š",
                "åˆ†æè¯¥è‚¡ç¥¨çš„é£é™©æ”¶ç›Šæ¯”ï¼š",
                "è¯†åˆ«è¯¥è‚¡ç¥¨æŠ•èµ„çš„ä¸»è¦é£é™©å› ç´ ï¼š",
                "æä¾›é£é™©ç®¡ç†å»ºè®®ï¼š"
            ],
            'financial_analysis': [
                "åŸºäºè´¢åŠ¡æ•°æ®åˆ†æå…¬å¸åŸºæœ¬é¢ï¼š",
                "è¯„ä¼°å…¬å¸çš„è´¢åŠ¡å¥åº·çŠ¶å†µï¼š",
                "åˆ†æå…¬å¸çš„ç›ˆåˆ©èƒ½åŠ›å’Œæˆé•¿æ€§ï¼š",
                "è§£è¯»è´¢åŠ¡æŠ¥è¡¨å¹¶ç»™å‡ºæŠ•èµ„å»ºè®®ï¼š"
            ]
        }
        
    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        
        Args:
            df: åŒ…å«OHLCVæ•°æ®çš„DataFrame
            
        Returns:
            æ·»åŠ äº†æŠ€æœ¯æŒ‡æ ‡çš„DataFrame
        """
        if df.empty:
            return df
            
        df = df.copy()
        df = df.sort_values('trade_date')
        
        # ç§»åŠ¨å¹³å‡çº¿
        df['ma5'] = df['close'].rolling(5).mean()
        df['ma20'] = df['close'].rolling(20).mean()
        df['ma60'] = df['close'].rolling(60).mean()
        
        # RSI
        delta = df['close'].diff()
        gain = delta.where(delta > 0, 0).rolling(14).mean()
        loss = (-delta).where(delta < 0, 0).rolling(14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # MACD
        exp1 = df['close'].ewm(span=12).mean()
        exp2 = df['close'].ewm(span=26).mean()
        df['macd'] = exp1 - exp2
        df['signal'] = df['macd'].ewm(span=9).mean()
        df['histogram'] = df['macd'] - df['signal']
        
        # å¸ƒæ—å¸¦
        df['bb_middle'] = df['close'].rolling(20).mean()
        bb_std = df['close'].rolling(20).std()
        df['bb_upper'] = df['bb_middle'] + (bb_std * 2)
        df['bb_lower'] = df['bb_middle'] - (bb_std * 2)
        
        # æ³¢åŠ¨ç‡
        df['volatility'] = df['close'].pct_change().rolling(20).std() * np.sqrt(252)
        
        # ä»·æ ¼å˜åŒ–
        df['price_change'] = df['close'].pct_change()
        df['price_change_5d'] = df['close'].pct_change(5)
        df['price_change_20d'] = df['close'].pct_change(20)
        
        return df
    
    def format_stock_data_for_prompt(self, row: pd.Series, include_future: bool = False) -> str:
        """
        å°†è‚¡ç¥¨æ•°æ®æ ¼å¼åŒ–ä¸ºæç¤ºæ–‡æœ¬
        
        Args:
            row: è‚¡ç¥¨æ•°æ®è¡Œ
            include_future: æ˜¯å¦åŒ…å«æœªæ¥æ•°æ®ï¼ˆç”¨äºç”Ÿæˆç­”æ¡ˆï¼‰
            
        Returns:
            æ ¼å¼åŒ–çš„æ–‡æœ¬
        """
        data_text = f"""è‚¡ç¥¨ä»£ç : {row.get('ts_code', 'N/A')}
äº¤æ˜“æ—¥æœŸ: {row.get('trade_date', 'N/A')}
å¼€ç›˜ä»·: {row.get('open', 0):.2f}
æœ€é«˜ä»·: {row.get('high', 0):.2f}
æœ€ä½ä»·: {row.get('low', 0):.2f}
æ”¶ç›˜ä»·: {row.get('close', 0):.2f}
æˆäº¤é‡: {row.get('vol', 0):,.0f}"""

        # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
        if 'ma5' in row and pd.notna(row['ma5']):
            data_text += f"""

æŠ€æœ¯æŒ‡æ ‡:
5æ—¥å‡çº¿: {row['ma5']:.2f}
20æ—¥å‡çº¿: {row.get('ma20', 0):.2f}
RSI: {row.get('rsi', 0):.2f}
MACD: {row.get('macd', 0):.4f}
æ³¢åŠ¨ç‡: {row.get('volatility', 0):.2f}"""

        # æ·»åŠ ä»·æ ¼å˜åŒ–ä¿¡æ¯
        if 'price_change' in row and pd.notna(row['price_change']):
            data_text += f"""

ä»·æ ¼å˜åŒ–:
æ—¥æ¶¨è·Œå¹…: {row['price_change']*100:.2f}%
5æ—¥æ¶¨è·Œå¹…: {row.get('price_change_5d', 0)*100:.2f}%
20æ—¥æ¶¨è·Œå¹…: {row.get('price_change_20d', 0)*100:.2f}%"""

        return data_text
    
    def generate_investment_advice(self, row: pd.Series) -> str:
        """
        åŸºäºæ•°æ®ç”ŸæˆæŠ•èµ„å»ºè®®
        
        Args:
            row: è‚¡ç¥¨æ•°æ®è¡Œ
            
        Returns:
            æŠ•èµ„å»ºè®®æ–‡æœ¬
        """
        advice_parts = []
        
        # è¶‹åŠ¿åˆ†æ
        if pd.notna(row.get('ma5')) and pd.notna(row.get('ma20')):
            if row['ma5'] > row['ma20']:
                advice_parts.append("æŠ€æœ¯é¢å‘ˆä¸Šå‡è¶‹åŠ¿ï¼ŒçŸ­æœŸå‡çº¿ä½äºé•¿æœŸå‡çº¿ä¹‹ä¸Š")
            else:
                advice_parts.append("æŠ€æœ¯é¢å‘ˆä¸‹é™è¶‹åŠ¿ï¼ŒçŸ­æœŸå‡çº¿ä½äºé•¿æœŸå‡çº¿ä¹‹ä¸‹")
        
        # RSIåˆ†æ
        rsi = row.get('rsi', 50)
        if rsi > 70:
            advice_parts.append("RSIæ˜¾ç¤ºè¶…ä¹°çŠ¶æ€ï¼Œå»ºè®®è°¨æ…æ“ä½œ")
        elif rsi < 30:
            advice_parts.append("RSIæ˜¾ç¤ºè¶…å–çŠ¶æ€ï¼Œå¯èƒ½å­˜åœ¨åå¼¹æœºä¼š")
        else:
            advice_parts.append("RSIå¤„äºæ­£å¸¸åŒºé—´")
        
        # ä»·æ ¼å˜åŒ–åˆ†æ
        price_change = row.get('price_change', 0) * 100
        if abs(price_change) > 5:
            if price_change > 0:
                advice_parts.append(f"å½“æ—¥å¤§å¹…ä¸Šæ¶¨{price_change:.2f}%ï¼Œæ³¨æ„è·åˆ©å›åé£é™©")
            else:
                advice_parts.append(f"å½“æ—¥å¤§å¹…ä¸‹è·Œ{abs(price_change):.2f}%ï¼Œå¯å…³æ³¨æ”¯æ’‘ä½")
        
        # æ³¢åŠ¨ç‡åˆ†æ
        volatility = row.get('volatility', 0)
        if volatility > 0.3:
            advice_parts.append("æ³¢åŠ¨ç‡è¾ƒé«˜ï¼ŒæŠ•èµ„é£é™©ç›¸å¯¹è¾ƒå¤§")
        elif volatility < 0.15:
            advice_parts.append("æ³¢åŠ¨ç‡è¾ƒä½ï¼Œä»·æ ¼ç›¸å¯¹ç¨³å®š")
        
        # ç»¼åˆå»ºè®®
        if not advice_parts:
            advice_parts.append("å»ºè®®ç»“åˆåŸºæœ¬é¢åˆ†æè¿›è¡Œç»¼åˆåˆ¤æ–­")
        
        return "ã€‚".join(advice_parts) + "ã€‚è¯·æ³¨æ„æ§åˆ¶é£é™©ï¼Œç†æ€§æŠ•èµ„ã€‚"
    
    def generate_price_prediction(self, historical_data: pd.DataFrame, target_row_idx: int) -> str:
        """
        ç”Ÿæˆä»·æ ¼é¢„æµ‹ï¼ˆåŸºäºå†å²æ•°æ®ï¼‰
        
        Args:
            historical_data: å†å²æ•°æ®
            target_row_idx: ç›®æ ‡è¡Œç´¢å¼•
            
        Returns:
            ä»·æ ¼é¢„æµ‹æ–‡æœ¬
        """
        if target_row_idx + 5 >= len(historical_data):
            return "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹"
        
        current_price = historical_data.iloc[target_row_idx]['close']
        future_prices = historical_data.iloc[target_row_idx+1:target_row_idx+6]['close']
        
        # è®¡ç®—æœªæ¥å‡ å¤©çš„å®é™…è¡¨ç°
        predictions = []
        for i, future_price in enumerate(future_prices, 1):
            change = (future_price - current_price) / current_price * 100
            if change > 2:
                trend = "ä¸Šæ¶¨"
            elif change < -2:
                trend = "ä¸‹è·Œ"
            else:
                trend = "éœ‡è¡"
            predictions.append(f"ç¬¬{i}æ—¥é¢„æœŸ{trend}ï¼Œå¹…åº¦çº¦{change:.2f}%")
        
        return "åŸºäºæŠ€æœ¯åˆ†æé¢„æµ‹ï¼š" + "ï¼›".join(predictions[:3]) + "ã€‚"
    
    def create_training_examples(self, stock_data: pd.DataFrame, max_examples: int = 1000) -> List[TrainingExample]:
        """
        åˆ›å»ºè®­ç»ƒæ ·æœ¬
        
        Args:
            stock_data: è‚¡ç¥¨æ•°æ®
            max_examples: æœ€å¤§æ ·æœ¬æ•°
            
        Returns:
            è®­ç»ƒæ ·æœ¬åˆ—è¡¨
        """
        examples = []
        
        if stock_data.empty:
            return examples
        
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        stock_data = self.calculate_technical_indicators(stock_data)
        
        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„
        for ts_code, group_data in stock_data.groupby('ts_code'):
            group_data = group_data.sort_values('trade_date').reset_index(drop=True)
            
            # ä¸ºæ¯åªè‚¡ç¥¨ç”Ÿæˆå¤šä¸ªè®­ç»ƒæ ·æœ¬
            sample_indices = np.linspace(20, len(group_data)-10, min(50, len(group_data)-30), dtype=int)
            
            for idx in sample_indices:
                if idx >= len(group_data):
                    continue
                    
                row = group_data.iloc[idx]
                
                # è·³è¿‡æœ‰ç¼ºå¤±å€¼çš„è¡Œ
                if pd.isna(row[['open', 'high', 'low', 'close', 'vol']]).any():
                    continue
                
                # ç”Ÿæˆä¸åŒç±»å‹çš„è®­ç»ƒæ ·æœ¬
                self._generate_analysis_examples(row, group_data, idx, examples)
                self._generate_prediction_examples(row, group_data, idx, examples)
                
                if len(examples) >= max_examples:
                    break
                    
            if len(examples) >= max_examples:
                break
        
        self.logger.info(f"âœ… ç”Ÿæˆè®­ç»ƒæ ·æœ¬: {len(examples)}ä¸ª")
        return examples[:max_examples]
    
    def _generate_analysis_examples(self, row: pd.Series, group_data: pd.DataFrame, idx: int, examples: List[TrainingExample]):
        """ç”Ÿæˆåˆ†æç±»è®­ç»ƒæ ·æœ¬"""
        stock_text = self.format_stock_data_for_prompt(row)
        advice = self.generate_investment_advice(row)
        
        # è‚¡ç¥¨åˆ†ææ ·æœ¬
        analysis_prompt = np.random.choice(self.prompt_templates['stock_analysis'])
        examples.append(TrainingExample(
            instruction=analysis_prompt,
            input=stock_text,
            output=advice,
            metadata={
                'type': 'stock_analysis',
                'ts_code': row.get('ts_code'),
                'trade_date': str(row.get('trade_date'))
            }
        ))
        
        # é£é™©è¯„ä¼°æ ·æœ¬
        risk_prompt = np.random.choice(self.prompt_templates['risk_assessment'])
        risk_assessment = self._generate_risk_assessment(row)
        examples.append(TrainingExample(
            instruction=risk_prompt,
            input=stock_text,
            output=risk_assessment,
            metadata={
                'type': 'risk_assessment',
                'ts_code': row.get('ts_code'),
                'trade_date': str(row.get('trade_date'))
            }
        ))
    
    def _generate_prediction_examples(self, row: pd.Series, group_data: pd.DataFrame, idx: int, examples: List[TrainingExample]):
        """ç”Ÿæˆé¢„æµ‹ç±»è®­ç»ƒæ ·æœ¬"""
        stock_text = self.format_stock_data_for_prompt(row)
        prediction = self.generate_price_prediction(group_data, idx)
        
        prediction_prompt = np.random.choice(self.prompt_templates['price_prediction'])
        examples.append(TrainingExample(
            instruction=prediction_prompt,
            input=stock_text,
            output=prediction,
            metadata={
                'type': 'price_prediction',
                'ts_code': row.get('ts_code'),
                'trade_date': str(row.get('trade_date'))
            }
        ))
    
    def _generate_risk_assessment(self, row: pd.Series) -> str:
        """ç”Ÿæˆé£é™©è¯„ä¼°"""
        risk_factors = []
        risk_level = "ä¸­ç­‰"
        
        # æ³¢åŠ¨ç‡é£é™©
        volatility = row.get('volatility', 0)
        if volatility > 0.4:
            risk_factors.append("é«˜æ³¢åŠ¨ç‡")
            risk_level = "è¾ƒé«˜"
        elif volatility < 0.1:
            risk_factors.append("ä½æ³¢åŠ¨ç‡")
        
        # RSIé£é™©
        rsi = row.get('rsi', 50)
        if rsi > 80:
            risk_factors.append("ä¸¥é‡è¶…ä¹°")
            risk_level = "è¾ƒé«˜"
        elif rsi < 20:
            risk_factors.append("ä¸¥é‡è¶…å–")
        
        # ä»·æ ¼é£é™©
        price_change = abs(row.get('price_change', 0)) * 100
        if price_change > 8:
            risk_factors.append("ä»·æ ¼å‰§çƒˆæ³¢åŠ¨")
            risk_level = "è¾ƒé«˜"
        
        risk_text = f"é£é™©ç­‰çº§ï¼š{risk_level}ã€‚"
        if risk_factors:
            risk_text += f"ä¸»è¦é£é™©å› ç´ ï¼š{', '.join(risk_factors)}ã€‚"
        
        risk_text += "å»ºè®®ï¼šæ ¹æ®ä¸ªäººé£é™©æ‰¿å—èƒ½åŠ›åˆç†é…ç½®ä»“ä½ï¼Œè®¾ç½®æ­¢æŸç‚¹ã€‚"
        
        return risk_text
    
    def save_training_data(self, examples: List[TrainingExample], output_file: str, format: str = 'jsonl'):
        """
        ä¿å­˜è®­ç»ƒæ•°æ®
        
        Args:
            examples: è®­ç»ƒæ ·æœ¬åˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            format: è¾“å‡ºæ ¼å¼ ('jsonl', 'json', 'alpaca')
        """
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        if format == 'jsonl':
            with open(output_file, 'w', encoding='utf-8') as f:
                for example in examples:
                    json_obj = {
                        'instruction': example.instruction,
                        'input': example.input,
                        'output': example.output,
                        'metadata': example.metadata
                    }
                    f.write(json.dumps(json_obj, ensure_ascii=False) + '\n')
                    
        elif format == 'alpaca':
            # Alpacaæ ¼å¼
            alpaca_data = []
            for example in examples:
                alpaca_data.append({
                    'instruction': example.instruction,
                    'input': example.input,
                    'output': example.output
                })
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(alpaca_data, f, ensure_ascii=False, indent=2)
                
        else:  # json
            data = [example.__dict__ for example in examples]
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"âœ… è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
        self.logger.info(f"   æ ¼å¼: {format}, æ ·æœ¬æ•°: {len(examples)}")


def main():
    """æµ‹è¯•è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨"""
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = LLMTrainingDataGenerator()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰çš„æ•°æ®æ–‡ä»¶
    data_dir = "data/tushare_dataset"
    csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv') and 'daily_data' in f] if os.path.exists(data_dir) else []
    
    if csv_files:
        # ä½¿ç”¨æœ€æ–°çš„æ•°æ®æ–‡ä»¶
        latest_file = sorted(csv_files)[-1]
        data_path = os.path.join(data_dir, latest_file)
        print(f"ğŸ“‚ ä½¿ç”¨æ•°æ®æ–‡ä»¶: {data_path}")
        
        # è¯»å–æ•°æ®
        stock_data = pd.read_csv(data_path)
        print(f"ğŸ“Š åŠ è½½æ•°æ®: {len(stock_data)}æ¡è®°å½•")
        
    else:
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•
        print("ğŸ“ ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•...")
        dates = pd.date_range('2024-01-01', '2024-06-30', freq='D')
        stock_data = []
        
        for ts_code in ['000001.SZ', '000002.SZ', '600000.SH']:
            for date in dates:
                if date.weekday() < 5:  # å·¥ä½œæ—¥
                    stock_data.append({
                        'ts_code': ts_code,
                        'trade_date': date,
                        'open': 10 + np.random.normal(0, 0.5),
                        'high': 10.5 + np.random.normal(0, 0.5),
                        'low': 9.5 + np.random.normal(0, 0.5),
                        'close': 10 + np.random.normal(0, 0.5),
                        'vol': np.random.randint(1000000, 10000000)
                    })
        
        stock_data = pd.DataFrame(stock_data)
    
    # ç”Ÿæˆè®­ç»ƒæ ·æœ¬
    examples = generator.create_training_examples(stock_data, max_examples=100)
    
    if examples:
        # ä¿å­˜è®­ç»ƒæ•°æ®
        os.makedirs('data/llm_training', exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜ä¸ºä¸åŒæ ¼å¼
        generator.save_training_data(examples, f'data/llm_training/stock_training_data_{timestamp}.jsonl', 'jsonl')
        generator.save_training_data(examples, f'data/llm_training/stock_training_data_alpaca_{timestamp}.json', 'alpaca')
        
        print(f"\nğŸ“‹ è®­ç»ƒæ•°æ®ç”Ÿæˆå®Œæˆï¼")
        print(f"   æ ·æœ¬æ•°é‡: {len(examples)}")
        print(f"   ç¤ºä¾‹è¾“å‡º:")
        print(f"   æŒ‡ä»¤: {examples[0].instruction}")
        print(f"   è¾“å…¥: {examples[0].input[:200]}...")
        print(f"   è¾“å‡º: {examples[0].output}")
        
    else:
        print("âŒ æœªèƒ½ç”Ÿæˆè®­ç»ƒæ ·æœ¬")


if __name__ == "__main__":
    main()