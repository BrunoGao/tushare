#!/usr/bin/env python3
"""
ç³»ç»Ÿç›‘æ§æ¨¡å—
å®æ—¶ç›‘æ§ç³»ç»Ÿæ€§èƒ½ã€ä¸šåŠ¡æŒ‡æ ‡å’Œå¼‚å¸¸çŠ¶æ€
æ”¯æŒå‘Šè­¦é€šçŸ¥ã€æ€§èƒ½åˆ†æå’Œè‡ªåŠ¨åŒ–è¿ç»´
"""
import psutil
import logging
import time
import json
import threading
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor
import requests
import smtplib
from email.mime.text import MimeText
from email.mime.multipart import MimeMultipart
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import config
from utils.db_helper import db
from utils.redis_cache_manager import cache_manager
from utils.data_health_checker import data_health_checker
from sqlalchemy import text

logger = logging.getLogger(__name__)

@dataclass
class SystemMetrics:
    """ç³»ç»ŸæŒ‡æ ‡æ•°æ®ç±»"""
    timestamp: str
    cpu_percent: float
    memory_percent: float
    memory_used_gb: float
    memory_total_gb: float
    disk_percent: float
    disk_used_gb: float
    disk_total_gb: float
    network_sent_mb: float
    network_recv_mb: float
    process_count: int
    load_average: List[float]

@dataclass
class BusinessMetrics:
    """ä¸šåŠ¡æŒ‡æ ‡æ•°æ®ç±»"""
    timestamp: str
    api_response_time: float
    api_success_rate: float
    websocket_connections: int
    database_connections: int
    cache_hit_rate: float
    data_health_score: float
    recommendation_count: int
    error_count: int

@dataclass
class AlertRule:
    """å‘Šè­¦è§„åˆ™æ•°æ®ç±»"""
    name: str
    metric: str
    operator: str  # '>', '<', '>=', '<=', '==', '!='
    threshold: float
    duration: int  # æŒç»­æ—¶é—´(ç§’)
    severity: str  # 'critical', 'warning', 'info'
    enabled: bool = True
    last_triggered: Optional[str] = None

class SystemMonitor:
    """ç³»ç»Ÿç›‘æ§å™¨"""
    
    def __init__(self):
        self.is_running = False
        self.monitor_thread = None
        self.executor = ThreadPoolExecutor(max_workers=6)
        self.lock = threading.Lock()
        
        # ç›‘æ§é…ç½®
        self.config = {
            'monitor_interval': 30,  # ç›‘æ§é—´éš”(ç§’)
            'metrics_retention_days': 7,  # æŒ‡æ ‡ä¿ç•™å¤©æ•°
            'alert_cooldown': 300,  # å‘Šè­¦å†·å´æ—¶é—´(ç§’)
            'max_retries': 3,  # æœ€å¤§é‡è¯•æ¬¡æ•°
        }
        
        # å‘Šè­¦è§„åˆ™
        self.alert_rules = [
            AlertRule('CPUä½¿ç”¨ç‡è¿‡é«˜', 'cpu_percent', '>', 80.0, 60, 'warning'),
            AlertRule('å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜', 'memory_percent', '>', 85.0, 60, 'warning'),
            AlertRule('ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜', 'disk_percent', '>', 90.0, 300, 'critical'),
            AlertRule('APIå“åº”æ—¶é—´è¿‡é•¿', 'api_response_time', '>', 2000.0, 120, 'warning'),
            AlertRule('APIæˆåŠŸç‡è¿‡ä½', 'api_success_rate', '<', 95.0, 180, 'critical'),
            AlertRule('æ•°æ®å¥åº·è¯„åˆ†è¿‡ä½', 'data_health_score', '<', 70.0, 300, 'warning'),
            AlertRule('ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½', 'cache_hit_rate', '<', 50.0, 300, 'warning'),
        ]
        
        # å‘Šè­¦çŠ¶æ€è·Ÿè¸ª
        self.alert_states = {}
        
        # é€šçŸ¥é…ç½®
        self.notification_config = {
            'email': {
                'enabled': False,
                'smtp_server': 'smtp.gmail.com',
                'smtp_port': 587,
                'username': '',
                'password': '',
                'recipients': []
            },
            'webhook': {
                'enabled': False,
                'url': '',
                'headers': {'Content-Type': 'application/json'}
            }
        }
        
        # æ€§èƒ½åŸºçº¿
        self.performance_baseline = {
            'cpu_percent': 30.0,
            'memory_percent': 60.0,
            'api_response_time': 500.0,
            'cache_hit_rate': 80.0
        }
        
        # åˆå§‹åŒ–æ•°æ®åº“è¡¨
        self._init_database_tables()
    
    def _init_database_tables(self):
        """åˆå§‹åŒ–ç›‘æ§æ•°æ®åº“è¡¨"""
        try:
            with db.engine.connect() as conn:
                # ç³»ç»ŸæŒ‡æ ‡è¡¨
                conn.execute(text("""
                    CREATE TABLE IF NOT EXISTS system_metrics (
                        id BIGINT AUTO_INCREMENT PRIMARY KEY,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        cpu_percent DECIMAL(5,2),
                        memory_percent DECIMAL(5,2),
                        memory_used_gb DECIMAL(8,2),
                        memory_total_gb DECIMAL(8,2),
                        disk_percent DECIMAL(5,2),
                        disk_used_gb DECIMAL(10,2),
                        disk_total_gb DECIMAL(10,2),
                        network_sent_mb DECIMAL(10,2),
                        network_recv_mb DECIMAL(10,2),
                        process_count INT,
                        load_average JSON,
                        INDEX idx_timestamp (timestamp)
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡'
                """))
                
                # ä¸šåŠ¡æŒ‡æ ‡è¡¨
                conn.execute(text("""
                    CREATE TABLE IF NOT EXISTS business_metrics (
                        id BIGINT AUTO_INCREMENT PRIMARY KEY,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        api_response_time DECIMAL(8,2),
                        api_success_rate DECIMAL(5,2),
                        websocket_connections INT,
                        database_connections INT,
                        cache_hit_rate DECIMAL(5,2),
                        data_health_score DECIMAL(5,2),
                        recommendation_count INT,
                        error_count INT,
                        INDEX idx_timestamp (timestamp)
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='ä¸šåŠ¡æ€§èƒ½æŒ‡æ ‡'
                """))
                
                # å‘Šè­¦è®°å½•è¡¨
                conn.execute(text("""
                    CREATE TABLE IF NOT EXISTS alert_records (
                        id BIGINT AUTO_INCREMENT PRIMARY KEY,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        rule_name VARCHAR(100),
                        metric VARCHAR(50),
                        current_value DECIMAL(10,2),
                        threshold_value DECIMAL(10,2),
                        severity VARCHAR(20),
                        message TEXT,
                        resolved_at TIMESTAMP NULL,
                        INDEX idx_timestamp (timestamp),
                        INDEX idx_severity (severity),
                        INDEX idx_rule_name (rule_name)
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='å‘Šè­¦è®°å½•'
                """))
                
                conn.commit()
                logger.info("âœ… ç›‘æ§æ•°æ®åº“è¡¨åˆå§‹åŒ–å®Œæˆ")
                
        except Exception as e:
            logger.error(f"âŒ ç›‘æ§æ•°æ®åº“è¡¨åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def collect_system_metrics(self) -> SystemMetrics:
        """æ”¶é›†ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        try:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # å†…å­˜ä¿¡æ¯
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_used_gb = memory.used / (1024**3)
            memory_total_gb = memory.total / (1024**3)
            
            # ç£ç›˜ä¿¡æ¯
            disk = psutil.disk_usage('/')
            disk_percent = disk.percent
            disk_used_gb = disk.used / (1024**3)
            disk_total_gb = disk.total / (1024**3)
            
            # ç½‘ç»œä¿¡æ¯
            network = psutil.net_io_counters()
            network_sent_mb = network.bytes_sent / (1024**2)
            network_recv_mb = network.bytes_recv / (1024**2)
            
            # è¿›ç¨‹æ•°é‡
            process_count = len(psutil.pids())
            
            # ç³»ç»Ÿè´Ÿè½½
            try:
                load_average = list(psutil.getloadavg())
            except:
                load_average = [0.0, 0.0, 0.0]
            
            return SystemMetrics(
                timestamp=datetime.now().isoformat(),
                cpu_percent=cpu_percent,
                memory_percent=memory_percent,
                memory_used_gb=round(memory_used_gb, 2),
                memory_total_gb=round(memory_total_gb, 2),
                disk_percent=disk_percent,
                disk_used_gb=round(disk_used_gb, 2),
                disk_total_gb=round(disk_total_gb, 2),
                network_sent_mb=round(network_sent_mb, 2),
                network_recv_mb=round(network_recv_mb, 2),
                process_count=process_count,
                load_average=load_average
            )
            
        except Exception as e:
            logger.error(f"ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")
            return None
    
    def collect_business_metrics(self) -> BusinessMetrics:
        """æ”¶é›†ä¸šåŠ¡æ€§èƒ½æŒ‡æ ‡"""
        try:
            # APIå“åº”æ—¶é—´å’ŒæˆåŠŸç‡
            api_metrics = self._test_api_performance()
            
            # WebSocketè¿æ¥æ•°
            websocket_connections = self._get_websocket_connections()
            
            # æ•°æ®åº“è¿æ¥æ•°
            database_connections = self._get_database_connections()
            
            # ç¼“å­˜å‘½ä¸­ç‡
            cache_stats = cache_manager.get_stats()
            cache_hit_rate = cache_stats.get('hit_rate', 0)
            
            # æ•°æ®å¥åº·è¯„åˆ†
            health_data = data_health_checker.check_system_health()
            data_health_score = health_data.get('overall_score', 0)
            
            # æ¨èæ•°é‡
            recommendation_count = self._get_recommendation_count()
            
            # é”™è¯¯æ•°é‡
            error_count = self._get_error_count()
            
            return BusinessMetrics(
                timestamp=datetime.now().isoformat(),
                api_response_time=api_metrics['response_time'],
                api_success_rate=api_metrics['success_rate'],
                websocket_connections=websocket_connections,
                database_connections=database_connections,
                cache_hit_rate=cache_hit_rate,
                data_health_score=data_health_score,
                recommendation_count=recommendation_count,
                error_count=error_count
            )
            
        except Exception as e:
            logger.error(f"ä¸šåŠ¡æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")
            return None
    
    def _test_api_performance(self) -> Dict[str, float]:
        """æµ‹è¯•APIæ€§èƒ½"""
        try:
            # æµ‹è¯•ä¸»è¦APIç«¯ç‚¹
            test_endpoints = [
                'http://localhost:5000/api/health',
                'http://localhost:5000/api/stocks/basic',
                'http://localhost:5000/api/recommendations'
            ]
            
            response_times = []
            success_count = 0
            
            for endpoint in test_endpoints:
                try:
                    start_time = time.time()
                    response = requests.get(endpoint, timeout=5)
                    response_time = (time.time() - start_time) * 1000
                    
                    response_times.append(response_time)
                    if response.status_code == 200:
                        success_count += 1
                        
                except:
                    response_times.append(5000)  # è¶…æ—¶è®°ä¸º5ç§’
            
            avg_response_time = sum(response_times) / len(response_times) if response_times else 0
            success_rate = (success_count / len(test_endpoints)) * 100 if test_endpoints else 0
            
            return {
                'response_time': round(avg_response_time, 2),
                'success_rate': round(success_rate, 2)
            }
            
        except Exception as e:
            logger.warning(f"APIæ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            return {'response_time': 0, 'success_rate': 0}
    
    def _get_websocket_connections(self) -> int:
        """è·å–WebSocketè¿æ¥æ•°"""
        try:
            # è¿™é‡Œåº”è¯¥ä»WebSocketæœåŠ¡å™¨è·å–è¿æ¥æ•°
            # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
            return 0
        except:
            return 0
    
    def _get_database_connections(self) -> int:
        """è·å–æ•°æ®åº“è¿æ¥æ•°"""
        try:
            with db.engine.connect() as conn:
                result = conn.execute(text("SHOW STATUS LIKE 'Threads_connected'")).fetchone()
                return int(result[1]) if result else 0
        except:
            return 0
    
    def _get_recommendation_count(self) -> int:
        """è·å–ä»Šæ—¥æ¨èæ•°é‡"""
        try:
            with db.engine.connect() as conn:
                result = conn.execute(text("""
                    SELECT COUNT(*) FROM recommend_result 
                    WHERE DATE(created_at) = CURDATE()
                """)).scalar()
                return result or 0
        except:
            return 0
    
    def _get_error_count(self) -> int:
        """è·å–ä»Šæ—¥é”™è¯¯æ•°é‡"""
        try:
            # è¿™é‡Œåº”è¯¥ä»æ—¥å¿—ç³»ç»Ÿè·å–é”™è¯¯æ•°é‡
            # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
            return 0
        except:
            return 0
    
    def save_metrics(self, system_metrics: SystemMetrics, business_metrics: BusinessMetrics):
        """ä¿å­˜æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        try:
            with db.engine.connect() as conn:
                # ä¿å­˜ç³»ç»ŸæŒ‡æ ‡
                if system_metrics:
                    conn.execute(text("""
                        INSERT INTO system_metrics 
                        (cpu_percent, memory_percent, memory_used_gb, memory_total_gb,
                         disk_percent, disk_used_gb, disk_total_gb, network_sent_mb,
                         network_recv_mb, process_count, load_average)
                        VALUES (:cpu_percent, :memory_percent, :memory_used_gb, :memory_total_gb,
                                :disk_percent, :disk_used_gb, :disk_total_gb, :network_sent_mb,
                                :network_recv_mb, :process_count, :load_average)
                    """), {
                        **asdict(system_metrics),
                        'load_average': json.dumps(system_metrics.load_average)
                    })
                
                # ä¿å­˜ä¸šåŠ¡æŒ‡æ ‡
                if business_metrics:
                    conn.execute(text("""
                        INSERT INTO business_metrics 
                        (api_response_time, api_success_rate, websocket_connections,
                         database_connections, cache_hit_rate, data_health_score,
                         recommendation_count, error_count)
                        VALUES (:api_response_time, :api_success_rate, :websocket_connections,
                                :database_connections, :cache_hit_rate, :data_health_score,
                                :recommendation_count, :error_count)
                    """), asdict(business_metrics))
                
                conn.commit()
                
        except Exception as e:
            logger.error(f"æŒ‡æ ‡ä¿å­˜å¤±è´¥: {e}")
    
    def check_alerts(self, system_metrics: SystemMetrics, business_metrics: BusinessMetrics):
        """æ£€æŸ¥å‘Šè­¦è§„åˆ™"""
        current_time = datetime.now()
        
        # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡
        all_metrics = {}
        if system_metrics:
            all_metrics.update(asdict(system_metrics))
        if business_metrics:
            all_metrics.update(asdict(business_metrics))
        
        for rule in self.alert_rules:
            if not rule.enabled:
                continue
            
            try:
                metric_value = all_metrics.get(rule.metric)
                if metric_value is None:
                    continue
                
                # æ£€æŸ¥å‘Šè­¦æ¡ä»¶
                triggered = self._evaluate_alert_condition(metric_value, rule)
                
                if triggered:
                    # æ£€æŸ¥æ˜¯å¦åœ¨å†·å´æœŸå†…
                    if self._is_in_cooldown(rule):
                        continue
                    
                    # è§¦å‘å‘Šè­¦
                    self._trigger_alert(rule, metric_value, current_time)
                else:
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦è§£é™¤å‘Šè­¦
                    self._resolve_alert_if_needed(rule, current_time)
                    
            except Exception as e:
                logger.error(f"å‘Šè­¦æ£€æŸ¥å¤±è´¥ {rule.name}: {e}")
    
    def _evaluate_alert_condition(self, value: float, rule: AlertRule) -> bool:
        """è¯„ä¼°å‘Šè­¦æ¡ä»¶"""
        if rule.operator == '>':
            return value > rule.threshold
        elif rule.operator == '<':
            return value < rule.threshold
        elif rule.operator == '>=':
            return value >= rule.threshold
        elif rule.operator == '<=':
            return value <= rule.threshold
        elif rule.operator == '==':
            return value == rule.threshold
        elif rule.operator == '!=':
            return value != rule.threshold
        return False
    
    def _is_in_cooldown(self, rule: AlertRule) -> bool:
        """æ£€æŸ¥æ˜¯å¦åœ¨å‘Šè­¦å†·å´æœŸå†…"""
        if rule.last_triggered:
            last_time = datetime.fromisoformat(rule.last_triggered)
            cooldown_period = timedelta(seconds=self.config['alert_cooldown'])
            return datetime.now() - last_time < cooldown_period
        return False
    
    def _trigger_alert(self, rule: AlertRule, current_value: float, timestamp: datetime):
        """è§¦å‘å‘Šè­¦"""
        try:
            # æ›´æ–°å‘Šè­¦çŠ¶æ€
            rule.last_triggered = timestamp.isoformat()
            self.alert_states[rule.name] = {
                'triggered_at': timestamp.isoformat(),
                'current_value': current_value,
                'resolved': False
            }
            
            # ç”Ÿæˆå‘Šè­¦æ¶ˆæ¯
            message = f"å‘Šè­¦: {rule.name}\n"
            message += f"å½“å‰å€¼: {current_value}\n"
            message += f"é˜ˆå€¼: {rule.threshold}\n"
            message += f"ä¸¥é‡ç¨‹åº¦: {rule.severity}\n"
            message += f"æ—¶é—´: {timestamp.strftime('%Y-%m-%d %H:%M:%S')}"
            
            # è®°å½•å‘Šè­¦åˆ°æ•°æ®åº“
            self._save_alert_record(rule, current_value, message)
            
            # å‘é€é€šçŸ¥
            self._send_notification(rule, message)
            
            logger.warning(f"ğŸš¨ å‘Šè­¦è§¦å‘: {rule.name} - {current_value}")
            
        except Exception as e:
            logger.error(f"å‘Šè­¦è§¦å‘å¤±è´¥: {e}")
    
    def _resolve_alert_if_needed(self, rule: AlertRule, timestamp: datetime):
        """è§£é™¤å‘Šè­¦ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
        if rule.name in self.alert_states and not self.alert_states[rule.name]['resolved']:
            # æ ‡è®°ä¸ºå·²è§£é™¤
            self.alert_states[rule.name]['resolved'] = True
            self.alert_states[rule.name]['resolved_at'] = timestamp.isoformat()
            
            # æ›´æ–°æ•°æ®åº“è®°å½•
            try:
                with db.engine.connect() as conn:
                    conn.execute(text("""
                        UPDATE alert_records 
                        SET resolved_at = NOW() 
                        WHERE rule_name = :rule_name AND resolved_at IS NULL
                    """), {'rule_name': rule.name})
                    conn.commit()
            except Exception as e:
                logger.error(f"å‘Šè­¦è§£é™¤è®°å½•æ›´æ–°å¤±è´¥: {e}")
            
            logger.info(f"âœ… å‘Šè­¦è§£é™¤: {rule.name}")
    
    def _save_alert_record(self, rule: AlertRule, current_value: float, message: str):
        """ä¿å­˜å‘Šè­¦è®°å½•"""
        try:
            with db.engine.connect() as conn:
                conn.execute(text("""
                    INSERT INTO alert_records 
                    (rule_name, metric, current_value, threshold_value, severity, message)
                    VALUES (:rule_name, :metric, :current_value, :threshold_value, :severity, :message)
                """), {
                    'rule_name': rule.name,
                    'metric': rule.metric,
                    'current_value': current_value,
                    'threshold_value': rule.threshold,
                    'severity': rule.severity,
                    'message': message
                })
                conn.commit()
        except Exception as e:
            logger.error(f"å‘Šè­¦è®°å½•ä¿å­˜å¤±è´¥: {e}")
    
    def _send_notification(self, rule: AlertRule, message: str):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        try:
            # é‚®ä»¶é€šçŸ¥
            if self.notification_config['email']['enabled']:
                self._send_email_notification(rule, message)
            
            # Webhooké€šçŸ¥
            if self.notification_config['webhook']['enabled']:
                self._send_webhook_notification(rule, message)
                
        except Exception as e:
            logger.error(f"é€šçŸ¥å‘é€å¤±è´¥: {e}")
    
    def _send_email_notification(self, rule: AlertRule, message: str):
        """å‘é€é‚®ä»¶é€šçŸ¥"""
        try:
            config = self.notification_config['email']
            
            msg = MimeMultipart()
            msg['From'] = config['username']
            msg['To'] = ', '.join(config['recipients'])
            msg['Subject'] = f"[{rule.severity.upper()}] ç³»ç»Ÿå‘Šè­¦: {rule.name}"
            
            msg.attach(MimeText(message, 'plain', 'utf-8'))
            
            server = smtplib.SMTP(config['smtp_server'], config['smtp_port'])
            server.starttls()
            server.login(config['username'], config['password'])
            server.send_message(msg)
            server.quit()
            
            logger.info(f"ğŸ“§ é‚®ä»¶å‘Šè­¦å‘é€æˆåŠŸ: {rule.name}")
            
        except Exception as e:
            logger.error(f"é‚®ä»¶å‘Šè­¦å‘é€å¤±è´¥: {e}")
    
    def _send_webhook_notification(self, rule: AlertRule, message: str):
        """å‘é€Webhooké€šçŸ¥"""
        try:
            config = self.notification_config['webhook']
            
            payload = {
                'rule_name': rule.name,
                'metric': rule.metric,
                'severity': rule.severity,
                'message': message,
                'timestamp': datetime.now().isoformat()
            }
            
            response = requests.post(
                config['url'],
                json=payload,
                headers=config['headers'],
                timeout=10
            )
            
            if response.status_code == 200:
                logger.info(f"ğŸ”— Webhookå‘Šè­¦å‘é€æˆåŠŸ: {rule.name}")
            else:
                logger.error(f"Webhookå‘Šè­¦å‘é€å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            logger.error(f"Webhookå‘Šè­¦å‘é€å¤±è´¥: {e}")
    
    def start_monitoring(self):
        """å¯åŠ¨ç›‘æ§"""
        if self.is_running:
            logger.warning("ç›‘æ§å·²åœ¨è¿è¡Œä¸­")
            return
        
        self.is_running = True
        self.monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitor_thread.start()
        
        logger.info("ğŸ” ç³»ç»Ÿç›‘æ§å·²å¯åŠ¨")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.is_running = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=10)
        
        logger.info("ğŸ›‘ ç³»ç»Ÿç›‘æ§å·²åœæ­¢")
    
    def _monitoring_loop(self):
        """ç›‘æ§ä¸»å¾ªç¯"""
        logger.info(f"ğŸ”„ ç›‘æ§å¾ªç¯å¯åŠ¨ï¼Œé—´éš”: {self.config['monitor_interval']}ç§’")
        
        while self.is_running:
            try:
                # æ”¶é›†æŒ‡æ ‡
                system_metrics = self.collect_system_metrics()
                business_metrics = self.collect_business_metrics()
                
                # ä¿å­˜æŒ‡æ ‡
                self.save_metrics(system_metrics, business_metrics)
                
                # æ£€æŸ¥å‘Šè­¦
                self.check_alerts(system_metrics, business_metrics)
                
                # ç¼“å­˜æœ€æ–°æŒ‡æ ‡
                if system_metrics:
                    cache_manager.set('system_status', 'latest_system_metrics', asdict(system_metrics), 300)
                if business_metrics:
                    cache_manager.set('system_status', 'latest_business_metrics', asdict(business_metrics), 300)
                
                # æ¸…ç†è¿‡æœŸæ•°æ®
                self._cleanup_old_data()
                
                time.sleep(self.config['monitor_interval'])
                
            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")
                time.sleep(10)  # å‡ºé”™åçŸ­æš‚ç­‰å¾…
    
    def _cleanup_old_data(self):
        """æ¸…ç†è¿‡æœŸç›‘æ§æ•°æ®"""
        try:
            retention_days = self.config['metrics_retention_days']
            cutoff_date = datetime.now() - timedelta(days=retention_days)
            
            with db.engine.connect() as conn:
                # æ¸…ç†ç³»ç»ŸæŒ‡æ ‡
                conn.execute(text("""
                    DELETE FROM system_metrics 
                    WHERE timestamp < :cutoff_date
                """), {'cutoff_date': cutoff_date})
                
                # æ¸…ç†ä¸šåŠ¡æŒ‡æ ‡
                conn.execute(text("""
                    DELETE FROM business_metrics 
                    WHERE timestamp < :cutoff_date
                """), {'cutoff_date': cutoff_date})
                
                # æ¸…ç†å·²è§£å†³çš„å‘Šè­¦è®°å½•ï¼ˆä¿ç•™30å¤©ï¼‰
                alert_cutoff = datetime.now() - timedelta(days=30)
                conn.execute(text("""
                    DELETE FROM alert_records 
                    WHERE resolved_at IS NOT NULL AND resolved_at < :cutoff_date
                """), {'cutoff_date': alert_cutoff})
                
                conn.commit()
                
        except Exception as e:
            logger.error(f"æ•°æ®æ¸…ç†å¤±è´¥: {e}")
    
    def get_current_status(self) -> Dict[str, Any]:
        """è·å–å½“å‰ç³»ç»ŸçŠ¶æ€"""
        try:
            # è·å–æœ€æ–°æŒ‡æ ‡
            system_metrics = self.collect_system_metrics()
            business_metrics = self.collect_business_metrics()
            
            # è·å–æ´»è·ƒå‘Šè­¦
            active_alerts = [
                {
                    'name': name,
                    'triggered_at': state['triggered_at'],
                    'current_value': state['current_value']
                }
                for name, state in self.alert_states.items()
                if not state['resolved']
            ]
            
            # è®¡ç®—æ•´ä½“å¥åº·çŠ¶æ€
            health_score = self._calculate_overall_health(system_metrics, business_metrics)
            
            return {
                'timestamp': datetime.now().isoformat(),
                'health_score': health_score,
                'status': 'healthy' if health_score >= 80 else 'warning' if health_score >= 60 else 'critical',
                'system_metrics': asdict(system_metrics) if system_metrics else {},
                'business_metrics': asdict(business_metrics) if business_metrics else {},
                'active_alerts': active_alerts,
                'monitoring_status': 'running' if self.is_running else 'stopped'
            }
            
        except Exception as e:
            logger.error(f"çŠ¶æ€è·å–å¤±è´¥: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'health_score': 0,
                'status': 'error',
                'error': str(e)
            }
    
    def _calculate_overall_health(self, system_metrics: SystemMetrics, business_metrics: BusinessMetrics) -> float:
        """è®¡ç®—æ•´ä½“å¥åº·è¯„åˆ†"""
        try:
            score = 100.0
            
            if system_metrics:
                # ç³»ç»ŸæŒ‡æ ‡æƒé‡ 40%
                if system_metrics.cpu_percent > 80:
                    score -= 15
                elif system_metrics.cpu_percent > 60:
                    score -= 8
                
                if system_metrics.memory_percent > 85:
                    score -= 15
                elif system_metrics.memory_percent > 70:
                    score -= 8
                
                if system_metrics.disk_percent > 90:
                    score -= 10
                elif system_metrics.disk_percent > 80:
                    score -= 5
            
            if business_metrics:
                # ä¸šåŠ¡æŒ‡æ ‡æƒé‡ 60%
                if business_metrics.api_response_time > 2000:
                    score -= 20
                elif business_metrics.api_response_time > 1000:
                    score -= 10
                
                if business_metrics.api_success_rate < 95:
                    score -= 20
                elif business_metrics.api_success_rate < 98:
                    score -= 10
                
                if business_metrics.data_health_score < 70:
                    score -= 15
                elif business_metrics.data_health_score < 85:
                    score -= 8
                
                if business_metrics.cache_hit_rate < 50:
                    score -= 5
            
            return max(0.0, score)
            
        except Exception as e:
            logger.error(f"å¥åº·è¯„åˆ†è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def get_performance_report(self, hours: int = 24) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        try:
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=hours)
            
            with db.engine.connect() as conn:
                # ç³»ç»ŸæŒ‡æ ‡ç»Ÿè®¡
                system_stats = conn.execute(text("""
                    SELECT
                        AVG(cpu_percent) as avg_cpu,
                        MAX(cpu_percent) as max_cpu,
                        AVG(memory_percent) as avg_memory,
                        MAX(memory_percent) as max_memory,
                        AVG(disk_percent) as avg_disk,
                        COUNT(*) as sample_count
                    FROM system_metrics
                    WHERE timestamp BETWEEN :start_time AND :end_time
                """), {'start_time': start_time, 'end_time': end_time}).fetchone()
                
                # ä¸šåŠ¡æŒ‡æ ‡ç»Ÿè®¡
                business_stats = conn.execute(text("""
                    SELECT
                        AVG(api_response_time) as avg_response_time,
                        MAX(api_response_time) as max_response_time,
                        AVG(api_success_rate) as avg_success_rate,
                        MIN(api_success_rate) as min_success_rate,
                        AVG(cache_hit_rate) as avg_cache_hit_rate,
                        AVG(data_health_score) as avg_health_score
                    FROM business_metrics
                    WHERE timestamp BETWEEN :start_time AND :end_time
                """), {'start_time': start_time, 'end_time': end_time}).fetchone()
                
                # å‘Šè­¦ç»Ÿè®¡
                alert_stats = conn.execute(text("""
                    SELECT
                        COUNT(*) as total_alerts,
                        SUM(CASE WHEN severity = 'critical' THEN 1 ELSE 0 END) as critical_alerts,
                        SUM(CASE WHEN severity = 'warning' THEN 1 ELSE 0 END) as warning_alerts
                    FROM alert_records
                    WHERE timestamp BETWEEN :start_time AND :end_time
                """), {'start_time': start_time, 'end_time': end_time}).fetchone()
                
                # ç”ŸæˆæŠ¥å‘Š
                report = {
                    'period': {
                        'start_time': start_time.isoformat(),
                        'end_time': end_time.isoformat(),
                        'duration_hours': hours
                    },
                    'system_performance': {
                        'avg_cpu_percent': round(system_stats.avg_cpu or 0, 2),
                        'max_cpu_percent': round(system_stats.max_cpu or 0, 2),
                        'avg_memory_percent': round(system_stats.avg_memory or 0, 2),
                        'max_memory_percent': round(system_stats.max_memory or 0, 2),
                        'avg_disk_percent': round(system_stats.avg_disk or 0, 2),
                        'sample_count': system_stats.sample_count or 0
                    },
                    'business_performance': {
                        'avg_response_time': round(business_stats.avg_response_time or 0, 2),
                        'max_response_time': round(business_stats.max_response_time or 0, 2),
                        'avg_success_rate': round(business_stats.avg_success_rate or 0, 2),
                        'min_success_rate': round(business_stats.min_success_rate or 0, 2),
                        'avg_cache_hit_rate': round(business_stats.avg_cache_hit_rate or 0, 2),
                        'avg_health_score': round(business_stats.avg_health_score or 0, 2)
                    },
                    'alerts': {
                        'total_alerts': alert_stats.total_alerts or 0,
                        'critical_alerts': alert_stats.critical_alerts or 0,
                        'warning_alerts': alert_stats.warning_alerts or 0
                    },
                    'recommendations': self._generate_performance_recommendations(system_stats, business_stats)
                }
                
                return report
                
        except Exception as e:
            logger.error(f"æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return {
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def _generate_performance_recommendations(self, system_stats, business_stats) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        try:
            # ç³»ç»Ÿæ€§èƒ½å»ºè®®
            if system_stats.avg_cpu and system_stats.avg_cpu > 70:
                recommendations.append("CPUä½¿ç”¨ç‡åé«˜ï¼Œå»ºè®®ä¼˜åŒ–è®¡ç®—å¯†é›†å‹ä»»åŠ¡æˆ–å¢åŠ CPUèµ„æº")
            
            if system_stats.avg_memory and system_stats.avg_memory > 80:
                recommendations.append("å†…å­˜ä½¿ç”¨ç‡åé«˜ï¼Œå»ºè®®ä¼˜åŒ–å†…å­˜ä½¿ç”¨æˆ–å¢åŠ å†…å­˜å®¹é‡")
            
            if system_stats.avg_disk and system_stats.avg_disk > 85:
                recommendations.append("ç£ç›˜ä½¿ç”¨ç‡åé«˜ï¼Œå»ºè®®æ¸…ç†æ— ç”¨æ–‡ä»¶æˆ–æ‰©å®¹ç£ç›˜")
            
            # ä¸šåŠ¡æ€§èƒ½å»ºè®®
            if business_stats.avg_response_time and business_stats.avg_response_time > 1000:
                recommendations.append("APIå“åº”æ—¶é—´åé•¿ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢å’Œç¼“å­˜ç­–ç•¥")
            
            if business_stats.avg_success_rate and business_stats.avg_success_rate < 98:
                recommendations.append("APIæˆåŠŸç‡åä½ï¼Œå»ºè®®æ£€æŸ¥é”™è¯¯æ—¥å¿—å’Œå¼‚å¸¸å¤„ç†")
            
            if business_stats.avg_cache_hit_rate and business_stats.avg_cache_hit_rate < 70:
                recommendations.append("ç¼“å­˜å‘½ä¸­ç‡åä½ï¼Œå»ºè®®ä¼˜åŒ–ç¼“å­˜ç­–ç•¥å’Œé¢„çƒ­æœºåˆ¶")
            
            if business_stats.avg_health_score and business_stats.avg_health_score < 80:
                recommendations.append("æ•°æ®å¥åº·è¯„åˆ†åä½ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡å’Œå®Œæ•´æ€§")
            
            if not recommendations:
                recommendations.append("ç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰é…ç½®")
                
        except Exception as e:
            logger.error(f"æ€§èƒ½å»ºè®®ç”Ÿæˆå¤±è´¥: {e}")
            recommendations.append("æ€§èƒ½å»ºè®®ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›‘æ§æ•°æ®")
        
        return recommendations

# åˆ›å»ºå…¨å±€ç›‘æ§å®ä¾‹
system_monitor = SystemMonitor()

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç³»ç»Ÿç›‘æ§æ¨¡å—')
    parser.add_argument('command', choices=['start', 'stop', 'status', 'report', 'test'],
                       help='æ“ä½œå‘½ä»¤')
    parser.add_argument('--hours', type=int, default=24,
                       help='æŠ¥å‘Šæ—¶é—´èŒƒå›´(å°æ—¶)')
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('logs/system_monitor.log', encoding='utf-8')
        ]
    )
    
    try:
        if args.command == 'start':
            system_monitor.start_monitoring()
            print("âœ… ç³»ç»Ÿç›‘æ§å·²å¯åŠ¨")
            
            # ä¿æŒè¿è¡Œ
            try:
                while True:
                    time.sleep(1)
            except KeyboardInterrupt:
                system_monitor.stop_monitoring()
                print("ğŸ›‘ ç³»ç»Ÿç›‘æ§å·²åœæ­¢")
                
        elif args.command == 'stop':
            system_monitor.stop_monitoring()
            print("ğŸ›‘ ç³»ç»Ÿç›‘æ§å·²åœæ­¢")
            
        elif args.command == 'status':
            status = system_monitor.get_current_status()
            print("ğŸ“Š å½“å‰ç³»ç»ŸçŠ¶æ€:")
            print(json.dumps(status, indent=2, ensure_ascii=False, default=str))
            
        elif args.command == 'report':
            report = system_monitor.get_performance_report(args.hours)
            print(f"ğŸ“ˆ {args.hours}å°æ—¶æ€§èƒ½æŠ¥å‘Š:")
            print(json.dumps(report, indent=2, ensure_ascii=False, default=str))
            
        elif args.command == 'test':
            print("ğŸ§ª æµ‹è¯•ç›‘æ§åŠŸèƒ½...")
            
            # æµ‹è¯•æŒ‡æ ‡æ”¶é›†
            system_metrics = system_monitor.collect_system_metrics()
            business_metrics = system_monitor.collect_business_metrics()
            
            print("ç³»ç»ŸæŒ‡æ ‡:", asdict(system_metrics) if system_metrics else "æ”¶é›†å¤±è´¥")
            print("ä¸šåŠ¡æŒ‡æ ‡:", asdict(business_metrics) if business_metrics else "æ”¶é›†å¤±è´¥")
            
            # æµ‹è¯•å‘Šè­¦æ£€æŸ¥
            system_monitor.check_alerts(system_metrics, business_metrics)
            print("å‘Šè­¦æ£€æŸ¥å®Œæˆ")
            
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    main()