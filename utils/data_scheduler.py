#!/usr/bin/env python3
"""
Aè‚¡æ•°æ®è°ƒåº¦ç®¡ç†ç³»ç»Ÿ - å¢å¼ºç‰ˆ
æ”¯æŒå®šæ—¶ä»»åŠ¡ã€å¢é‡æ›´æ–°ã€æ™ºèƒ½é”™è¯¯é‡è¯•ã€ç›‘æ§å‘Šè­¦ã€æ•…éšœæ¢å¤
"""
import schedule
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Callable, Optional, Any
import threading
import json
import os
import sys
import traceback
import signal
import psutil
from enum import Enum
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor, TimeoutError
import requests
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config
from scripts.fetch_comprehensive_data import ComprehensiveDataFetcher
from utils.db_helper import db
from utils.redis_cache_manager import cache_manager
from sqlalchemy import text

logger = logging.getLogger(__name__)

class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€æšä¸¾"""
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"
    TIMEOUT = "timeout"
    RETRYING = "retrying"
    CANCELLED = "cancelled"
    SKIPPED = "skipped"

class ErrorType(Enum):
    """é”™è¯¯ç±»å‹æšä¸¾"""
    NETWORK_ERROR = "network_error"
    API_LIMIT_ERROR = "api_limit_error"
    DATABASE_ERROR = "database_error"
    TIMEOUT_ERROR = "timeout_error"
    DATA_ERROR = "data_error"
    SYSTEM_ERROR = "system_error"
    UNKNOWN_ERROR = "unknown_error"

@dataclass
class TaskExecution:
    """ä»»åŠ¡æ‰§è¡Œè®°å½•"""
    task_name: str
    start_time: datetime
    end_time: Optional[datetime] = None
    status: TaskStatus = TaskStatus.PENDING
    error_type: Optional[ErrorType] = None
    error_message: str = ""
    retry_count: int = 0
    execution_time: float = 0.0
    records_processed: int = 0
    memory_usage: float = 0.0
    cpu_usage: float = 0.0

@dataclass
class RetryStrategy:
    """é‡è¯•ç­–ç•¥"""
    max_retries: int = 3
    base_delay: int = 60  # åŸºç¡€å»¶è¿Ÿ(ç§’)
    max_delay: int = 3600  # æœ€å¤§å»¶è¿Ÿ(ç§’)
    exponential_backoff: bool = True
    jitter: bool = True  # æ·»åŠ éšæœºæŠ–åŠ¨

class DataScheduler:
    """æ•°æ®è°ƒåº¦ç®¡ç†å™¨"""
    
    def __init__(self):
        self.fetcher = ComprehensiveDataFetcher()
        self.status_file = "logs/scheduler_status.json"
        self.error_log_file = "logs/scheduler_errors.json"
        self.running = False
        self.tasks_status = {}
        self.error_history = []
        self.executor = ThreadPoolExecutor(max_workers=4)
        self.active_tasks = {}  # å½“å‰è¿è¡Œçš„ä»»åŠ¡
        self.task_locks = {}  # ä»»åŠ¡é”ï¼Œé˜²æ­¢é‡å¤æ‰§è¡Œ
        
        # é”™è¯¯åˆ†ç±»å™¨
        self.error_classifier = {
            'connection': ErrorType.NETWORK_ERROR,
            'timeout': ErrorType.TIMEOUT_ERROR,
            'limit': ErrorType.API_LIMIT_ERROR,
            'database': ErrorType.DATABASE_ERROR,
            'data': ErrorType.DATA_ERROR,
            'memory': ErrorType.SYSTEM_ERROR,
            'permission': ErrorType.SYSTEM_ERROR
        }
        
        # æ™ºèƒ½é‡è¯•ç­–ç•¥
        self.retry_strategies = {
            ErrorType.NETWORK_ERROR: RetryStrategy(max_retries=5, base_delay=30),
            ErrorType.API_LIMIT_ERROR: RetryStrategy(max_retries=3, base_delay=300),
            ErrorType.DATABASE_ERROR: RetryStrategy(max_retries=3, base_delay=60),
            ErrorType.TIMEOUT_ERROR: RetryStrategy(max_retries=2, base_delay=120),
            ErrorType.DATA_ERROR: RetryStrategy(max_retries=2, base_delay=60),
            ErrorType.SYSTEM_ERROR: RetryStrategy(max_retries=1, base_delay=300),
            ErrorType.UNKNOWN_ERROR: RetryStrategy(max_retries=2, base_delay=120)
        }
        
        # ä»»åŠ¡é…ç½®
        self.task_config = {
            # åŸºæœ¬ä¿¡æ¯ - æ¯å‘¨æ›´æ–°
            'stock_basic': {
                'frequency': 'weekly',
                'day': 'monday',
                'time': '09:00',
                'function': self.fetcher.fetch_basic_info_data,
                'retry_count': 3,
                'timeout': 3600,  # 1å°æ—¶
                'priority': 1  # ä¼˜å…ˆçº§æœ€é«˜
            },
            
            # è´¢åŠ¡æ•°æ® - å­£åº¦æ›´æ–°ï¼ˆæŠ¥å‘ŠæœŸåï¼‰
            'financial_data': {
                'frequency': 'monthly',
                'day': 15,  # æ¯æœˆ15æ—¥
                'time': '10:00',
                'function': self.fetcher.fetch_financial_data,
                'retry_count': 2,
                'timeout': 7200,  # 2å°æ—¶
                'priority': 2
            },
            
            # èµ„é‡‘æµå‘ - æ¯æ—¥æ›´æ–°
            'money_flow': {
                'frequency': 'daily',
                'time': '18:30',
                'function': self.fetcher.fetch_money_flow_data,
                'retry_count': 3,
                'timeout': 1800,  # 30åˆ†é’Ÿ
                'priority': 3
            },
            
            # è‚¡ä¸œæ•°æ® - å­£åº¦æ›´æ–°
            'shareholder_data': {
                'frequency': 'monthly',
                'day': 20,  # æ¯æœˆ20æ—¥
                'time': '11:00',
                'function': self.fetcher.fetch_shareholder_data,
                'retry_count': 2,
                'timeout': 3600,
                'priority': 4
            },
            
            # å…¬å‘Šæ•°æ® - æ¯æ—¥æ›´æ–°
            'announcement_data': {
                'frequency': 'daily',
                'time': '19:00',
                'function': self.fetcher.fetch_announcement_data,
                'retry_count': 3,
                'timeout': 900,  # 15åˆ†é’Ÿ
                'priority': 5
            },
            
            # è¡Œæƒ…æ‰©å±• - æ¯æ—¥æ›´æ–°
            'market_extension': {
                'frequency': 'daily',
                'time': '19:30',
                'function': self.fetcher.fetch_market_extension_data,
                'retry_count': 3,
                'timeout': 900,
                'priority': 6
            },
            
            # å®è§‚æ•°æ® - æ¯æœˆæ›´æ–°
            'macro_data': {
                'frequency': 'monthly',
                'day': 5,  # æ¯æœˆ5æ—¥
                'time': '12:00',
                'function': self.fetcher.fetch_macro_data,
                'retry_count': 2,
                'timeout': 1800,
                'priority': 7
            }
        }
        
        self.load_status()
        self.load_error_history()
    
    def classify_error(self, error: Exception) -> ErrorType:
        """æ™ºèƒ½é”™è¯¯åˆ†ç±»"""
        error_str = str(error).lower()
        
        # ç½‘ç»œç›¸å…³é”™è¯¯
        if any(keyword in error_str for keyword in ['connection', 'network', 'timeout', 'unreachable']):
            return ErrorType.NETWORK_ERROR
        
        # APIé™åˆ¶é”™è¯¯
        if any(keyword in error_str for keyword in ['limit', 'quota', 'rate', 'throttle']):
            return ErrorType.API_LIMIT_ERROR
        
        # æ•°æ®åº“é”™è¯¯
        if any(keyword in error_str for keyword in ['database', 'mysql', 'sql', 'connection']):
            return ErrorType.DATABASE_ERROR
        
        # è¶…æ—¶é”™è¯¯
        if any(keyword in error_str for keyword in ['timeout', 'timed out']):
            return ErrorType.TIMEOUT_ERROR
        
        # æ•°æ®é”™è¯¯
        if any(keyword in error_str for keyword in ['data', 'format', 'parse', 'invalid']):
            return ErrorType.DATA_ERROR
        
        # ç³»ç»Ÿé”™è¯¯
        if any(keyword in error_str for keyword in ['memory', 'disk', 'permission', 'system']):
            return ErrorType.SYSTEM_ERROR
        
        return ErrorType.UNKNOWN_ERROR
    
    def calculate_retry_delay(self, error_type: ErrorType, attempt: int) -> int:
        """è®¡ç®—é‡è¯•å»¶è¿Ÿæ—¶é—´"""
        strategy = self.retry_strategies.get(error_type, RetryStrategy())
        
        if strategy.exponential_backoff:
            delay = min(strategy.base_delay * (2 ** attempt), strategy.max_delay)
        else:
            delay = strategy.base_delay
        
        # æ·»åŠ éšæœºæŠ–åŠ¨
        if strategy.jitter:
            import random
            jitter = random.uniform(0.8, 1.2)
            delay = int(delay * jitter)
        
        return delay
    
    def should_retry(self, error_type: ErrorType, attempt: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•"""
        strategy = self.retry_strategies.get(error_type, RetryStrategy())
        return attempt < strategy.max_retries
    
    def log_error(self, task_name: str, error: Exception, error_type: ErrorType, attempt: int):
        """è®°å½•é”™è¯¯ä¿¡æ¯"""
        error_record = {
            'timestamp': datetime.now().isoformat(),
            'task_name': task_name,
            'error_type': error_type.value,
            'error_message': str(error),
            'attempt': attempt,
            'traceback': traceback.format_exc()
        }
        
        self.error_history.append(error_record)
        
        # ä¿æŒé”™è¯¯å†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.error_history) > 1000:
            self.error_history = self.error_history[-500:]
        
        self.save_error_history()
    
    def save_error_history(self):
        """ä¿å­˜é”™è¯¯å†å²"""
        try:
            os.makedirs(os.path.dirname(self.error_log_file), exist_ok=True)
            with open(self.error_log_file, 'w', encoding='utf-8') as f:
                json.dump(self.error_history, f, ensure_ascii=False, indent=2, default=str)
        except Exception as e:
            logger.error(f"ä¿å­˜é”™è¯¯å†å²å¤±è´¥: {e}")
    
    def load_error_history(self):
        """åŠ è½½é”™è¯¯å†å²"""
        try:
            if os.path.exists(self.error_log_file):
                with open(self.error_log_file, 'r', encoding='utf-8') as f:
                    self.error_history = json.load(f)
        except Exception as e:
            logger.warning(f"åŠ è½½é”™è¯¯å†å²å¤±è´¥: {e}")
            self.error_history = []
    
    def get_task_lock(self, task_name: str) -> bool:
        """è·å–ä»»åŠ¡é”ï¼Œé˜²æ­¢é‡å¤æ‰§è¡Œ"""
        if task_name in self.task_locks:
            return False
        
        self.task_locks[task_name] = threading.Lock()
        return self.task_locks[task_name].acquire(blocking=False)
    
    def release_task_lock(self, task_name: str):
        """é‡Šæ”¾ä»»åŠ¡é”"""
        if task_name in self.task_locks:
            try:
                self.task_locks[task_name].release()
            except:
                pass
            finally:
                del self.task_locks[task_name]
    
    def monitor_task_resources(self, task_name: str) -> Dict[str, float]:
        """ç›‘æ§ä»»åŠ¡èµ„æºä½¿ç”¨"""
        try:
            process = psutil.Process()
            return {
                'cpu_percent': process.cpu_percent(),
                'memory_mb': process.memory_info().rss / 1024 / 1024,
                'memory_percent': process.memory_percent()
            }
        except:
            return {'cpu_percent': 0, 'memory_mb': 0, 'memory_percent': 0}
        
    def load_status(self):
        """åŠ è½½è°ƒåº¦çŠ¶æ€"""
        try:
            if os.path.exists(self.status_file):
                with open(self.status_file, 'r', encoding='utf-8') as f:
                    self.tasks_status = json.load(f)
        except Exception as e:
            logger.warning(f"åŠ è½½è°ƒåº¦çŠ¶æ€å¤±è´¥: {e}")
            self.tasks_status = {}
            
    def save_status(self):
        """ä¿å­˜è°ƒåº¦çŠ¶æ€"""
        try:
            os.makedirs(os.path.dirname(self.status_file), exist_ok=True)
            with open(self.status_file, 'w', encoding='utf-8') as f:
                json.dump(self.tasks_status, f, ensure_ascii=False, indent=2, default=str)
        except Exception as e:
            logger.error(f"ä¿å­˜è°ƒåº¦çŠ¶æ€å¤±è´¥: {e}")
            
    def setup_schedules(self):
        """è®¾ç½®å®šæ—¶ä»»åŠ¡"""
        logger.info("ğŸ•’ è®¾ç½®å®šæ—¶ä»»åŠ¡è°ƒåº¦...")
        
        for task_name, config in self.task_config.items():
            frequency = config['frequency']
            time_str = config['time']
            
            if frequency == 'daily':
                schedule.every().day.at(time_str).do(
                    self.run_task_safe, task_name
                ).tag(task_name)
                
            elif frequency == 'weekly':
                day = config.get('day', 'monday')
                getattr(schedule.every(), day).at(time_str).do(
                    self.run_task_safe, task_name
                ).tag(task_name)
                
            elif frequency == 'monthly':
                # æœˆåº¦ä»»åŠ¡é€šè¿‡æ¯æ—¥æ£€æŸ¥å®ç°
                schedule.every().day.at(time_str).do(
                    self.check_monthly_task, task_name
                ).tag(f"{task_name}_monthly")
                
            logger.info(f"âœ… ä»»åŠ¡ {task_name} å·²è°ƒåº¦: {frequency} at {time_str}")
            
    def check_monthly_task(self, task_name: str):
        """æ£€æŸ¥æœˆåº¦ä»»åŠ¡æ˜¯å¦éœ€è¦æ‰§è¡Œ"""
        config = self.task_config[task_name]
        target_day = config.get('day', 1)
        
        today = datetime.now()
        if today.day == target_day:
            logger.info(f"ğŸ“… æœˆåº¦ä»»åŠ¡ {task_name} è§¦å‘æ‰§è¡Œ")
            return self.run_task_safe(task_name)
        else:
            logger.debug(f"ğŸ“… æœˆåº¦ä»»åŠ¡ {task_name} éæ‰§è¡Œæ—¥: {today.day} != {target_day}")
            
    def run_task_safe(self, task_name: str):
        """å®‰å…¨æ‰§è¡Œä»»åŠ¡ï¼ˆå¸¦æ™ºèƒ½é”™è¯¯å¤„ç†å’Œé‡è¯•ï¼‰"""
        config = self.task_config.get(task_name)
        if not config:
            logger.error(f"âŒ æœªæ‰¾åˆ°ä»»åŠ¡é…ç½®: {task_name}")
            return
        
        # æ£€æŸ¥ä»»åŠ¡é”ï¼Œé˜²æ­¢é‡å¤æ‰§è¡Œ
        if not self.get_task_lock(task_name):
            logger.warning(f"âš ï¸ ä»»åŠ¡ {task_name} æ­£åœ¨æ‰§è¡Œä¸­ï¼Œè·³è¿‡æœ¬æ¬¡è°ƒåº¦")
            return
        
        try:
            self._execute_task_with_retry(task_name, config)
        finally:
            self.release_task_lock(task_name)
    
    def _execute_task_with_retry(self, task_name: str, config: Dict):
        """å¸¦æ™ºèƒ½é‡è¯•çš„ä»»åŠ¡æ‰§è¡Œ"""
        func = config['function']
        timeout = config.get('timeout', 3600)
        
        execution = TaskExecution(
            task_name=task_name,
            start_time=datetime.now()
        )
        
        attempt = 0
        while True:
            try:
                logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_name} (å°è¯• {attempt + 1})")
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                execution.status = TaskStatus.RUNNING
                execution.retry_count = attempt
                self.active_tasks[task_name] = execution
                self.update_task_status(task_name, TaskStatus.RUNNING.value,
                                      f"æ‰§è¡Œä¸­ (å°è¯• {attempt + 1})")
                
                # ç›‘æ§èµ„æºä½¿ç”¨
                start_resources = self.monitor_task_resources(task_name)
                start_time = time.time()
                
                # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œä»»åŠ¡ä»¥æ”¯æŒè¶…æ—¶å’Œå–æ¶ˆ
                future = self.executor.submit(func, 'incremental')
                
                try:
                    result = future.result(timeout=timeout)
                    execution_time = time.time() - start_time
                    
                    # æ›´æ–°æ‰§è¡Œè®°å½•
                    execution.end_time = datetime.now()
                    execution.status = TaskStatus.SUCCESS
                    execution.execution_time = execution_time
                    
                    # è®¡ç®—èµ„æºä½¿ç”¨
                    end_resources = self.monitor_task_resources(task_name)
                    execution.memory_usage = end_resources['memory_mb']
                    execution.cpu_usage = end_resources['cpu_percent']
                    
                    logger.info(f"âœ… ä»»åŠ¡ {task_name} æ‰§è¡ŒæˆåŠŸ (è€—æ—¶: {execution_time:.2f}ç§’)")
                    self.update_task_status(task_name, TaskStatus.SUCCESS.value,
                                          f"æ‰§è¡ŒæˆåŠŸ (è€—æ—¶: {execution_time:.2f}ç§’)")
                    self.log_task_completion(task_name, execution)
                    
                    # ç¼“å­˜æˆåŠŸçŠ¶æ€
                    cache_manager.set('scheduler', f'last_success_{task_name}',
                                    execution.end_time.isoformat(), 3600)
                    
                    return
                    
                except TimeoutError:
                    future.cancel()
                    error = TimeoutError(f"ä»»åŠ¡æ‰§è¡Œè¶…æ—¶ ({timeout}ç§’)")
                    error_type = ErrorType.TIMEOUT_ERROR
                    
                except Exception as e:
                    error = e
                    error_type = self.classify_error(e)
                
            except Exception as e:
                error = e
                error_type = self.classify_error(e)
            
            # å¤„ç†é”™è¯¯
            execution.error_type = error_type
            execution.error_message = str(error)
            execution.end_time = datetime.now()
            execution.status = TaskStatus.FAILED
            
            # è®°å½•é”™è¯¯
            self.log_error(task_name, error, error_type, attempt)
            logger.error(f"âŒ ä»»åŠ¡ {task_name} æ‰§è¡Œå¤±è´¥ (å°è¯• {attempt + 1}): {error}")
            
            # åˆ¤æ–­æ˜¯å¦é‡è¯•
            if self.should_retry(error_type, attempt):
                attempt += 1
                execution.status = TaskStatus.RETRYING
                
                # è®¡ç®—é‡è¯•å»¶è¿Ÿ
                delay = self.calculate_retry_delay(error_type, attempt)
                
                logger.info(f"â³ {delay}ç§’åé‡è¯• (é”™è¯¯ç±»å‹: {error_type.value})")
                self.update_task_status(task_name, TaskStatus.RETRYING.value,
                                      f"ç­‰å¾…é‡è¯• (å»¶è¿Ÿ: {delay}ç§’)")
                
                time.sleep(delay)
            else:
                # é‡è¯•æ¬¡æ•°ç”¨å°½ï¼Œä»»åŠ¡å¤±è´¥
                logger.error(f"âŒ ä»»åŠ¡ {task_name} æœ€ç»ˆå¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                self.update_task_status(task_name, TaskStatus.FAILED.value,
                                      f"æœ€ç»ˆå¤±è´¥: {error}")
                self.log_task_failure(task_name, error, execution)
                break
        
        # æ¸…ç†æ´»è·ƒä»»åŠ¡è®°å½•
        if task_name in self.active_tasks:
            del self.active_tasks[task_name]
                    
    def update_task_status(self, task_name: str, status: str, message: str = ""):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        self.tasks_status[task_name] = {
            'status': status,
            'message': message,
            'last_update': datetime.now().isoformat(),
            'last_run': datetime.now().isoformat() if status in ['running', 'success'] else 
                       self.tasks_status.get(task_name, {}).get('last_run')
        }
        self.save_status()
        
    def log_task_completion(self, task_name: str, execution: TaskExecution):
        """è®°å½•ä»»åŠ¡å®Œæˆæ—¥å¿—"""
        try:
            with db.engine.connect() as conn:
                # åˆ›å»ºä»»åŠ¡æ‰§è¡Œè®°å½•è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                conn.execute(text("""
                    CREATE TABLE IF NOT EXISTS task_execution_log (
                        id BIGINT AUTO_INCREMENT PRIMARY KEY,
                        task_name VARCHAR(100),
                        start_time TIMESTAMP,
                        end_time TIMESTAMP,
                        status VARCHAR(20),
                        execution_time DECIMAL(10,3),
                        retry_count INT,
                        memory_usage DECIMAL(10,2),
                        cpu_usage DECIMAL(5,2),
                        records_processed INT,
                        error_type VARCHAR(50),
                        error_message TEXT,
                        INDEX idx_task_name (task_name),
                        INDEX idx_start_time (start_time),
                        INDEX idx_status (status)
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='ä»»åŠ¡æ‰§è¡Œè®°å½•'
                """))
                
                # æ’å…¥æ‰§è¡Œè®°å½•
                conn.execute(text("""
                    INSERT INTO task_execution_log
                    (task_name, start_time, end_time, status, execution_time, retry_count,
                     memory_usage, cpu_usage, records_processed, error_type, error_message)
                    VALUES (:task_name, :start_time, :end_time, :status, :execution_time, :retry_count,
                            :memory_usage, :cpu_usage, :records_processed, :error_type, :error_message)
                """), {
                    'task_name': execution.task_name,
                    'start_time': execution.start_time,
                    'end_time': execution.end_time,
                    'status': execution.status.value,
                    'execution_time': execution.execution_time,
                    'retry_count': execution.retry_count,
                    'memory_usage': execution.memory_usage,
                    'cpu_usage': execution.cpu_usage,
                    'records_processed': execution.records_processed,
                    'error_type': execution.error_type.value if execution.error_type else None,
                    'error_message': execution.error_message
                })
                
                # å…¼å®¹æ—§çš„ç³»ç»Ÿæ—¥å¿—
                conn.execute(text("""
                    INSERT INTO system_log (operation_type, operation_detail, success_count, error_count)
                    VALUES (:operation_type, :operation_detail, :success_count, :error_count)
                """), {
                    'operation_type': f'scheduler_{task_name}',
                    'operation_detail': f'å®šæ—¶ä»»åŠ¡ {task_name} æ‰§è¡ŒæˆåŠŸ (è€—æ—¶: {execution.execution_time:.2f}ç§’)',
                    'success_count': 1,
                    'error_count': 0
                })
                
                conn.commit()
        except Exception as e:
            logger.warning(f"è®°å½•ä»»åŠ¡å®Œæˆæ—¥å¿—å¤±è´¥: {e}")
            
    def log_task_failure(self, task_name: str, error: Exception, execution: TaskExecution):
        """è®°å½•ä»»åŠ¡å¤±è´¥æ—¥å¿—"""
        try:
            with db.engine.connect() as conn:
                # æ’å…¥æ‰§è¡Œè®°å½•
                conn.execute(text("""
                    INSERT INTO task_execution_log
                    (task_name, start_time, end_time, status, execution_time, retry_count,
                     memory_usage, cpu_usage, records_processed, error_type, error_message)
                    VALUES (:task_name, :start_time, :end_time, :status, :execution_time, :retry_count,
                            :memory_usage, :cpu_usage, :records_processed, :error_type, :error_message)
                """), {
                    'task_name': execution.task_name,
                    'start_time': execution.start_time,
                    'end_time': execution.end_time,
                    'status': execution.status.value,
                    'execution_time': execution.execution_time,
                    'retry_count': execution.retry_count,
                    'memory_usage': execution.memory_usage,
                    'cpu_usage': execution.cpu_usage,
                    'records_processed': execution.records_processed,
                    'error_type': execution.error_type.value if execution.error_type else None,
                    'error_message': execution.error_message
                })
                
                # å…¼å®¹æ—§çš„ç³»ç»Ÿæ—¥å¿—
                conn.execute(text("""
                    INSERT INTO system_log (operation_type, operation_detail, success_count, error_count)
                    VALUES (:operation_type, :operation_detail, :success_count, :error_count)
                """), {
                    'operation_type': f'scheduler_{task_name}',
                    'operation_detail': f'å®šæ—¶ä»»åŠ¡ {task_name} æ‰§è¡Œå¤±è´¥: {str(error)}',
                    'success_count': 0,
                    'error_count': 1
                })
                
                conn.commit()
        except Exception as e:
            logger.warning(f"è®°å½•ä»»åŠ¡å¤±è´¥æ—¥å¿—å¤±è´¥: {e}")
            
    def run_task_manually(self, task_name: str, mode: str = 'incremental'):
        """æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡"""
        logger.info(f"ğŸ”§ æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡: {task_name} (æ¨¡å¼: {mode})")
        
        config = self.task_config.get(task_name)
        if not config:
            logger.error(f"âŒ æœªæ‰¾åˆ°ä»»åŠ¡é…ç½®: {task_name}")
            return False
            
        try:
            func = config['function']
            result = func(mode)
            logger.info(f"âœ… æ‰‹åŠ¨ä»»åŠ¡ {task_name} æ‰§è¡ŒæˆåŠŸ: {result}")
            self.update_task_status(task_name, 'manual_success', f"æ‰‹åŠ¨æ‰§è¡ŒæˆåŠŸ: {result}")
            return True
        except Exception as e:
            logger.error(f"âŒ æ‰‹åŠ¨ä»»åŠ¡ {task_name} æ‰§è¡Œå¤±è´¥: {e}")
            self.update_task_status(task_name, 'manual_error', f"æ‰‹åŠ¨æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False
            
    def get_status_report(self) -> Dict:
        """è·å–è°ƒåº¦çŠ¶æ€æŠ¥å‘Š"""
        report = {
            'scheduler_running': self.running,
            'total_tasks': len(self.task_config),
            'tasks_status': self.tasks_status,
            'next_runs': {},
            'health_check': self.health_check()
        }
        
        # è·å–ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
        for job in schedule.jobs:
            task_name = list(job.tags)[0] if job.tags else 'unknown'
            report['next_runs'][task_name] = job.next_run.isoformat() if job.next_run else None
            
        return report
        
    def health_check(self) -> Dict:
        """å¥åº·æ£€æŸ¥"""
        health = {
            'database_connected': False,
            'tushare_connected': False,
            'disk_space_sufficient': False,
            'last_successful_tasks': {}
        }
        
        try:
            # æ•°æ®åº“è¿æ¥æ£€æŸ¥
            with db.engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            health['database_connected'] = True
        except:
            health['database_connected'] = False
            
        try:
            # TuShareè¿æ¥æ£€æŸ¥
            self.fetcher.pro.trade_cal(start_date='20240101', end_date='20240101')
            health['tushare_connected'] = True
        except:
            health['tushare_connected'] = False
            
        try:
            # ç£ç›˜ç©ºé—´æ£€æŸ¥
            import shutil
            _, _, free = shutil.disk_usage('.')
            health['disk_space_sufficient'] = free > 1024 * 1024 * 1024  # 1GB
        except:
            health['disk_space_sufficient'] = False
            
        # æœ€è¿‘æˆåŠŸä»»åŠ¡
        for task_name, status in self.tasks_status.items():
            if status.get('status') == 'success':
                health['last_successful_tasks'][task_name] = status.get('last_run')
                
        return health
        
    def start_scheduler(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        logger.info("ğŸš€ å¯åŠ¨æ•°æ®è°ƒåº¦å™¨...")
        
        self.setup_schedules()
        self.running = True
        
        logger.info(f"ğŸ“‹ å·²æ³¨å†Œ {len(self.task_config)} ä¸ªå®šæ—¶ä»»åŠ¡")
        logger.info("â° è°ƒåº¦å™¨è¿è¡Œä¸­ï¼ŒæŒ‰ Ctrl+C åœæ­¢...")
        
        try:
            while self.running:
                schedule.run_pending()
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ æ¥æ”¶åˆ°åœæ­¢ä¿¡å·...")
        finally:
            self.stop_scheduler()
            
    def stop_scheduler(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        logger.info("ğŸ›‘ åœæ­¢æ•°æ®è°ƒåº¦å™¨...")
        self.running = False
        schedule.clear()
        self.save_status()
        logger.info("âœ… è°ƒåº¦å™¨å·²åœæ­¢")
        
    def print_schedule_info(self):
        """æ‰“å°è°ƒåº¦ä¿¡æ¯"""
        logger.info("ğŸ“… å®šæ—¶ä»»åŠ¡è°ƒåº¦ä¿¡æ¯:")
        logger.info("-" * 80)
        
        for task_name, config in self.task_config.items():
            frequency = config['frequency']
            time_str = config['time']
            priority = config['priority']
            
            status_info = self.tasks_status.get(task_name, {})
            last_run = status_info.get('last_run', 'ä»æœªæ‰§è¡Œ')
            last_status = status_info.get('status', 'unknown')
            
            logger.info(f"ä»»åŠ¡: {task_name}")
            logger.info(f"  é¢‘ç‡: {frequency} at {time_str}")
            logger.info(f"  ä¼˜å…ˆçº§: {priority}")
            logger.info(f"  ä¸Šæ¬¡æ‰§è¡Œ: {last_run}")
            logger.info(f"  æœ€æ–°çŠ¶æ€: {last_status}")
            logger.info("")

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
scheduler = DataScheduler()

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Aè‚¡æ•°æ®è°ƒåº¦ç®¡ç†ç³»ç»Ÿ')
    parser.add_argument('command', choices=['start', 'status', 'run', 'health'], 
                       help='æ“ä½œå‘½ä»¤')
    parser.add_argument('--task', help='ä»»åŠ¡åç§°ï¼ˆç”¨äºrunå‘½ä»¤ï¼‰')
    parser.add_argument('--mode', choices=['full', 'incremental'], default='incremental',
                       help='æ‰§è¡Œæ¨¡å¼ï¼ˆç”¨äºrunå‘½ä»¤ï¼‰')
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('logs/scheduler.log', encoding='utf-8')
        ]
    )
    
    try:
        if args.command == 'start':
            scheduler.start_scheduler()
            
        elif args.command == 'status':
            report = scheduler.get_status_report()
            print(json.dumps(report, indent=2, ensure_ascii=False, default=str))
            
        elif args.command == 'run':
            if not args.task:
                logger.error("âŒ è¯·æŒ‡å®šä»»åŠ¡åç§° --task")
                return
                
            if args.task not in scheduler.task_config:
                logger.error(f"âŒ æœªçŸ¥ä»»åŠ¡: {args.task}")
                logger.info(f"å¯ç”¨ä»»åŠ¡: {list(scheduler.task_config.keys())}")
                return
                
            success = scheduler.run_task_manually(args.task, args.mode)
            if success:
                logger.info("âœ… æ‰‹åŠ¨ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ")
            else:
                logger.error("âŒ æ‰‹åŠ¨ä»»åŠ¡æ‰§è¡Œå¤±è´¥")
                
        elif args.command == 'health':
            health = scheduler.health_check()
            print("ğŸ¥ ç³»ç»Ÿå¥åº·æ£€æŸ¥:")
            for key, value in health.items():
                status = "âœ…" if value else "âŒ"
                print(f"  {key}: {status} {value}")
                
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    main() 