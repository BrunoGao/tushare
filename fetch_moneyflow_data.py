#!/usr/bin/env python3
"""
èµ„é‡‘æµå‘æ•°æ®æŠ“å–è„šæœ¬
åŒ…æ‹¬ä¸ªè‚¡èµ„é‡‘æµã€æ¿å—èµ„é‡‘æµã€æ²ªæ·±æ¸¯é€šèµ„é‡‘æµã€èèµ„èåˆ¸ç­‰æ•°æ®
"""

import os
import sys
import time
import json
import pandas as pd
import pymysql
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import tushare as ts
import threading

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from config import Config

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/moneyflow_data_fetch.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MoneyflowDataFetcher:
    """èµ„é‡‘æµå‘æ•°æ®æŠ“å–å™¨"""
    
    def __init__(self):
        self.ts_pro = ts.pro_api(Config.TS_TOKEN)
        self.db_config = {
            'host': Config.DB_HOST,
            'port': Config.DB_PORT,
            'user': Config.DB_USER,
            'password': Config.DB_PASSWORD,
            'database': Config.DB_NAME,
            'charset': 'utf8mb4'
        }
        self.progress_file = 'logs/moneyflow_fetch_progress.json'
        self.stats = {
            'start_time': datetime.now().isoformat(),
            'processed_tables': 0,
            'total_records': 0,
            'failed_operations': [],
            'processed_dates': []
        }
        self.lock = threading.Lock()
        
    def get_db_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        return pymysql.connect(**self.db_config)
    
    def create_tables(self):
        """åˆ›å»ºæ‰€éœ€çš„æ•°æ®è¡¨"""
        tables_sql = {
            'stock_moneyflow': """
                CREATE TABLE IF NOT EXISTS stock_moneyflow (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    ts_code VARCHAR(20) NOT NULL COMMENT 'è‚¡ç¥¨ä»£ç ',
                    trade_date DATE NOT NULL COMMENT 'äº¤æ˜“æ—¥æœŸ',
                    buy_sm_amount DECIMAL(20,2) COMMENT 'å°å•ä¹°å…¥é‡‘é¢(ä¸‡å…ƒ)',
                    buy_sm_vol INT COMMENT 'å°å•ä¹°å…¥é‡(æ‰‹)',
                    sell_sm_amount DECIMAL(20,2) COMMENT 'å°å•å–å‡ºé‡‘é¢(ä¸‡å…ƒ)',
                    sell_sm_vol INT COMMENT 'å°å•å–å‡ºé‡(æ‰‹)',
                    buy_md_amount DECIMAL(20,2) COMMENT 'ä¸­å•ä¹°å…¥é‡‘é¢(ä¸‡å…ƒ)',
                    buy_md_vol INT COMMENT 'ä¸­å•ä¹°å…¥é‡(æ‰‹)',
                    sell_md_amount DECIMAL(20,2) COMMENT 'ä¸­å•å–å‡ºé‡‘é¢(ä¸‡å…ƒ)',
                    sell_md_vol INT COMMENT 'ä¸­å•å–å‡ºé‡(æ‰‹)',
                    buy_lg_amount DECIMAL(20,2) COMMENT 'å¤§å•ä¹°å…¥é‡‘é¢(ä¸‡å…ƒ)',
                    buy_lg_vol INT COMMENT 'å¤§å•ä¹°å…¥é‡(æ‰‹)',
                    sell_lg_amount DECIMAL(20,2) COMMENT 'å¤§å•å–å‡ºé‡‘é¢(ä¸‡å…ƒ)',
                    sell_lg_vol INT COMMENT 'å¤§å•å–å‡ºé‡(æ‰‹)',
                    buy_elg_amount DECIMAL(20,2) COMMENT 'ç‰¹å¤§å•ä¹°å…¥é‡‘é¢(ä¸‡å…ƒ)',
                    buy_elg_vol INT COMMENT 'ç‰¹å¤§å•ä¹°å…¥é‡(æ‰‹)',
                    sell_elg_amount DECIMAL(20,2) COMMENT 'ç‰¹å¤§å•å–å‡ºé‡‘é¢(ä¸‡å…ƒ)',
                    sell_elg_vol INT COMMENT 'ç‰¹å¤§å•å–å‡ºé‡(æ‰‹)',
                    net_mf_amount DECIMAL(20,2) COMMENT 'å‡€æµå…¥é‡‘é¢(ä¸‡å…ƒ)',
                    net_mf_vol INT COMMENT 'å‡€æµå…¥é‡(æ‰‹)',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE KEY uk_code_date (ts_code, trade_date),
                    INDEX idx_trade_date (trade_date),
                    INDEX idx_ts_code (ts_code),
                    INDEX idx_net_mf (net_mf_amount)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='ä¸ªè‚¡èµ„é‡‘æµå‘è¡¨'
            """,
            
            'sector_moneyflow': """
                CREATE TABLE IF NOT EXISTS sector_moneyflow (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    trade_date DATE NOT NULL COMMENT 'äº¤æ˜“æ—¥æœŸ',
                    sector_name VARCHAR(100) NOT NULL COMMENT 'æ¿å—åç§°',
                    sector_code VARCHAR(20) COMMENT 'æ¿å—ä»£ç ',
                    buy_amount DECIMAL(20,2) COMMENT 'ä¹°å…¥é‡‘é¢(ä¸‡å…ƒ)',
                    sell_amount DECIMAL(20,2) COMMENT 'å–å‡ºé‡‘é¢(ä¸‡å…ƒ)',
                    net_amount DECIMAL(20,2) COMMENT 'å‡€æµå…¥é‡‘é¢(ä¸‡å…ƒ)',
                    buy_vol INT COMMENT 'ä¹°å…¥é‡(æ‰‹)',
                    sell_vol INT COMMENT 'å–å‡ºé‡(æ‰‹)',
                    net_vol INT COMMENT 'å‡€æµå…¥é‡(æ‰‹)',
                    stocks_count INT COMMENT 'æˆåˆ†è‚¡æ•°é‡',
                    rise_count INT COMMENT 'ä¸Šæ¶¨å®¶æ•°',
                    fall_count INT COMMENT 'ä¸‹è·Œå®¶æ•°',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE KEY uk_sector_date (sector_name, trade_date),
                    INDEX idx_trade_date (trade_date),
                    INDEX idx_sector (sector_name),
                    INDEX idx_net_amount (net_amount)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='æ¿å—èµ„é‡‘æµå‘è¡¨'
            """,
            
            'hsgt_flow': """
                CREATE TABLE IF NOT EXISTS hsgt_flow (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    trade_date DATE NOT NULL COMMENT 'äº¤æ˜“æ—¥æœŸ',
                    ggt_ss DECIMAL(20,2) COMMENT 'æ¸¯è‚¡é€šï¼ˆä¸Šæµ·ï¼‰å½“æ—¥æˆäº¤é‡‘é¢(ä¸‡å…ƒ)',
                    ggt_sz DECIMAL(20,2) COMMENT 'æ¸¯è‚¡é€šï¼ˆæ·±åœ³ï¼‰å½“æ—¥æˆäº¤é‡‘é¢(ä¸‡å…ƒ)',
                    hgt DECIMAL(20,2) COMMENT 'æ²ªè‚¡é€šå½“æ—¥æˆäº¤é‡‘é¢(ä¸‡å…ƒ)',
                    sgt DECIMAL(20,2) COMMENT 'æ·±è‚¡é€šå½“æ—¥æˆäº¤é‡‘é¢(ä¸‡å…ƒ)',
                    north_money DECIMAL(20,2) COMMENT 'åŒ—å‘èµ„é‡‘æˆäº¤é‡‘é¢(ä¸‡å…ƒ)',
                    south_money DECIMAL(20,2) COMMENT 'å—å‘èµ„é‡‘æˆäº¤é‡‘é¢(ä¸‡å…ƒ)',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE KEY uk_trade_date (trade_date),
                    INDEX idx_north_money (north_money),
                    INDEX idx_south_money (south_money)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='æ²ªæ·±æ¸¯é€šèµ„é‡‘æµå‘è¡¨'
            """,
            
            'margin_detail': """
                CREATE TABLE IF NOT EXISTS margin_detail (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    trade_date DATE NOT NULL COMMENT 'äº¤æ˜“æ—¥æœŸ',
                    ts_code VARCHAR(20) NOT NULL COMMENT 'è‚¡ç¥¨ä»£ç ',
                    name VARCHAR(100) COMMENT 'è‚¡ç¥¨åç§°',
                    rzye DECIMAL(20,2) COMMENT 'èèµ„ä½™é¢(ä¸‡å…ƒ)',
                    rzmre DECIMAL(20,2) COMMENT 'èèµ„ä¹°å…¥é¢(ä¸‡å…ƒ)',
                    rzche DECIMAL(20,2) COMMENT 'èèµ„å¿è¿˜é¢(ä¸‡å…ƒ)',
                    rqye DECIMAL(20,2) COMMENT 'èåˆ¸ä½™é¢(ä¸‡å…ƒ)',
                    rqmcl INT COMMENT 'èåˆ¸å–å‡ºé‡(è‚¡)',
                    rzrqye DECIMAL(20,2) COMMENT 'èèµ„èåˆ¸ä½™é¢(ä¸‡å…ƒ)',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE KEY uk_code_date (ts_code, trade_date),
                    INDEX idx_trade_date (trade_date),
                    INDEX idx_ts_code (ts_code),
                    INDEX idx_rzrqye (rzrqye)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='èèµ„èåˆ¸æ˜ç»†è¡¨'
            """
        }
        
        conn = self.get_db_connection()
        try:
            with conn.cursor() as cursor:
                for table_name, sql in tables_sql.items():
                    cursor.execute(sql)
                    logger.info(f"âœ… åˆ›å»º/æ£€æŸ¥è¡¨: {table_name}")
                conn.commit()
                logger.info("ğŸ¯ æ‰€æœ‰èµ„é‡‘æµç›¸å…³è¡¨åˆ›å»ºå®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºè¡¨å¤±è´¥: {e}")
            raise
        finally:
            conn.close()
    
    def get_stock_list(self) -> List[str]:
        """è·å–è‚¡ç¥¨åˆ—è¡¨"""
        try:
            conn = self.get_db_connection()
            with conn.cursor() as cursor:
                cursor.execute("SELECT ts_code FROM stock_basic WHERE ts_code IS NOT NULL")
                results = cursor.fetchall()
                return [row[0] for row in results]
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return []
        finally:
            conn.close()
    
    def fetch_stock_moneyflow_batch(self, date_str: str, stock_codes: List[str]) -> int:
        """æ‰¹é‡æŠ“å–ä¸ªè‚¡èµ„é‡‘æµæ•°æ®"""
        logger.info(f"ğŸ“Š æŠ“å–æ—¥æœŸ {date_str} çš„ä¸ªè‚¡èµ„é‡‘æµæ•°æ®, è‚¡ç¥¨æ•°: {len(stock_codes)}")
        
        success_count = 0
        conn = self.get_db_connection()
        
        try:
            insert_sql = """
                INSERT IGNORE INTO stock_moneyflow 
                (ts_code, trade_date, buy_sm_amount, buy_sm_vol, sell_sm_amount, sell_sm_vol,
                 buy_md_amount, buy_md_vol, sell_md_amount, sell_md_vol,
                 buy_lg_amount, buy_lg_vol, sell_lg_amount, sell_lg_vol,
                 buy_elg_amount, buy_elg_vol, sell_elg_amount, sell_elg_vol,
                 net_mf_amount, net_mf_vol)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            
            # åˆ†æ‰¹å¤„ç†è‚¡ç¥¨
            batch_size = 100
            for i in range(0, len(stock_codes), batch_size):
                batch_codes = stock_codes[i:i+batch_size]
                
                try:
                    # è·å–èµ„é‡‘æµæ•°æ®
                    df = self.ts_pro.moneyflow(
                        trade_date=date_str,
                        start_date=date_str,
                        end_date=date_str
                    )
                    
                    if not df.empty:
                        # è¿‡æ»¤å‡ºå½“å‰æ‰¹æ¬¡çš„è‚¡ç¥¨
                        batch_df = df[df['ts_code'].isin(batch_codes)]
                        
                        records = []
                        for _, row in batch_df.iterrows():
                            records.append((
                                row.get('ts_code'),
                                date_str,
                                row.get('buy_sm_amount'),
                                row.get('buy_sm_vol'),
                                row.get('sell_sm_amount'),
                                row.get('sell_sm_vol'),
                                row.get('buy_md_amount'),
                                row.get('buy_md_vol'),
                                row.get('sell_md_amount'),
                                row.get('sell_md_vol'),
                                row.get('buy_lg_amount'),
                                row.get('buy_lg_vol'),
                                row.get('sell_lg_amount'),
                                row.get('sell_lg_vol'),
                                row.get('buy_elg_amount'),
                                row.get('buy_elg_vol'),
                                row.get('sell_elg_amount'),
                                row.get('sell_elg_vol'),
                                row.get('net_mf_amount'),
                                row.get('net_mf_vol')
                            ))
                        
                        if records:
                            with conn.cursor() as cursor:
                                cursor.executemany(insert_sql, records)
                                conn.commit()
                                success_count += len(records)
                    
                    # APIé™é¢‘
                    time.sleep(0.5)
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ æ‰¹æ¬¡ {i//batch_size + 1} æŠ“å–å¤±è´¥: {e}")
                    continue
            
            with self.lock:
                self.stats['total_records'] += success_count
            
            logger.info(f"âœ… {date_str} ä¸ªè‚¡èµ„é‡‘æµæ•°æ®æŠ“å–å®Œæˆ: {success_count}æ¡è®°å½•")
            return success_count
            
        except Exception as e:
            logger.error(f"âŒ æŠ“å– {date_str} ä¸ªè‚¡èµ„é‡‘æµæ•°æ®å¤±è´¥: {e}")
            return 0
        finally:
            conn.close()
    
    def fetch_hsgt_flow(self, start_date: str, end_date: str) -> int:
        """æŠ“å–æ²ªæ·±æ¸¯é€šèµ„é‡‘æµæ•°æ®"""
        logger.info(f"ğŸš€ æŠ“å–æ²ªæ·±æ¸¯é€šèµ„é‡‘æµæ•°æ®: {start_date} ~ {end_date}")
        
        try:
            # è·å–æ²ªæ·±æ¸¯é€šèµ„é‡‘æµ
            df = self.ts_pro.hsgt_top10(
                trade_date='',
                start_date=start_date,
                end_date=end_date,
                market_type='1'  # 1-æ²ªå¸‚ 2-æ·±å¸‚ 3-æ¸¯è‚¡é€š(æ²ª) 4-æ¸¯è‚¡é€š(æ·±)
            )
            
            if df.empty:
                logger.warning("âš ï¸ æœªè·å–åˆ°æ²ªæ·±æ¸¯é€šèµ„é‡‘æµæ•°æ®")
                return 0
            
            conn = self.get_db_connection()
            try:
                insert_sql = """
                    INSERT IGNORE INTO hsgt_flow 
                    (trade_date, ggt_ss, ggt_sz, hgt, sgt, north_money, south_money)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                """
                
                # æŒ‰æ—¥æœŸæ±‡æ€»æ•°æ®
                daily_flow = df.groupby('trade_date').agg({
                    'buy_amount': 'sum',
                    'sell_amount': 'sum'
                }).reset_index()
                
                records = []
                for _, row in daily_flow.iterrows():
                    records.append((
                        row['trade_date'],
                        0,  # ggt_ss - éœ€è¦ä»å…¶ä»–æ¥å£è·å–
                        0,  # ggt_sz - éœ€è¦ä»å…¶ä»–æ¥å£è·å–
                        row.get('buy_amount', 0),  # hgtè¿‘ä¼¼
                        0,  # sgt - éœ€è¦ä»å…¶ä»–æ¥å£è·å–
                        row.get('buy_amount', 0),  # north_money
                        row.get('sell_amount', 0)   # south_money
                    ))
                
                with conn.cursor() as cursor:
                    cursor.executemany(insert_sql, records)
                    conn.commit()
                    
                record_count = len(records)
                self.stats['total_records'] += record_count
                logger.info(f"âœ… æ²ªæ·±æ¸¯é€šèµ„é‡‘æµæ•°æ®æŠ“å–å®Œæˆ: {record_count}æ¡è®°å½•")
                return record_count
                
            except Exception as e:
                logger.error(f"âŒ æ²ªæ·±æ¸¯é€šèµ„é‡‘æµæ•°æ®æ’å…¥å¤±è´¥: {e}")
                conn.rollback()
                return 0
            finally:
                conn.close()
                
        except Exception as e:
            logger.error(f"âŒ æŠ“å–æ²ªæ·±æ¸¯é€šèµ„é‡‘æµæ•°æ®å¤±è´¥: {e}")
            self.stats['failed_operations'].append({
                'operation': 'fetch_hsgt_flow',
                'error': str(e),
                'time': datetime.now().isoformat()
            })
            return 0
    
    def fetch_margin_detail(self, trade_date: str) -> int:
        """æŠ“å–èèµ„èåˆ¸æ•°æ®"""
        logger.info(f"ğŸš€ æŠ“å–èèµ„èåˆ¸æ•°æ®: {trade_date}")
        
        try:
            # è·å–èèµ„èåˆ¸æ•°æ®
            df = self.ts_pro.margin(trade_date=trade_date)
            
            if df.empty:
                logger.warning(f"âš ï¸ {trade_date} æœªè·å–åˆ°èèµ„èåˆ¸æ•°æ®")
                return 0
            
            conn = self.get_db_connection()
            try:
                insert_sql = """
                    INSERT IGNORE INTO margin_detail 
                    (trade_date, ts_code, name, rzye, rzmre, rzche, rqye, rqmcl, rzrqye)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                """
                
                records = []
                for _, row in df.iterrows():
                    records.append((
                        trade_date,
                        row.get('ts_code'),
                        row.get('name'),
                        row.get('rzye'),
                        row.get('rzmre'),
                        row.get('rzche'),
                        row.get('rqye'),
                        row.get('rqmcl'),
                        row.get('rzrqye')
                    ))
                
                with conn.cursor() as cursor:
                    cursor.executemany(insert_sql, records)
                    conn.commit()
                    
                record_count = len(records)
                self.stats['total_records'] += record_count
                logger.info(f"âœ… {trade_date} èèµ„èåˆ¸æ•°æ®æŠ“å–å®Œæˆ: {record_count}æ¡è®°å½•")
                return record_count
                
            except Exception as e:
                logger.error(f"âŒ {trade_date} èèµ„èåˆ¸æ•°æ®æ’å…¥å¤±è´¥: {e}")
                conn.rollback()
                return 0
            finally:
                conn.close()
                
        except Exception as e:
            logger.error(f"âŒ æŠ“å– {trade_date} èèµ„èåˆ¸æ•°æ®å¤±è´¥: {e}")
            self.stats['failed_operations'].append({
                'operation': f'fetch_margin_detail_{trade_date}',
                'error': str(e),
                'time': datetime.now().isoformat()
            })
            return 0
    
    def get_trade_dates(self, start_date: str, end_date: str) -> List[str]:
        """è·å–äº¤æ˜“æ—¥æœŸåˆ—è¡¨"""
        try:
            df = self.ts_pro.trade_cal(
                exchange='SSE',
                start_date=start_date,
                end_date=end_date,
                is_open='1'
            )
            return df['cal_date'].tolist()
        except Exception as e:
            logger.error(f"âŒ è·å–äº¤æ˜“æ—¥æœŸå¤±è´¥: {e}")
            return []
    
    def save_progress(self):
        """ä¿å­˜è¿›åº¦"""
        try:
            os.makedirs('logs', exist_ok=True)
            with open(self.progress_file, 'w') as f:
                json.dump(self.stats, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è¿›åº¦å¤±è´¥: {e}")
    
    def run(self, start_date: str = None, end_date: str = None):
        """æ‰§è¡Œèµ„é‡‘æµæ•°æ®æŠ“å–"""
        logger.info("ğŸ¯ å¼€å§‹èµ„é‡‘æµæ•°æ®æŠ“å–ä»»åŠ¡...")
        
        # é»˜è®¤æŠ“å–æœ€è¿‘30å¤©çš„æ•°æ®
        if not start_date:
            start_date = (datetime.now() - timedelta(days=30)).strftime('%Y%m%d')
        if not end_date:
            end_date = datetime.now().strftime('%Y%m%d')
        
        logger.info(f"ğŸ“… æŠ“å–æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
        
        try:
            # åˆ›å»ºæ•°æ®è¡¨
            self.create_tables()
            
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            stock_codes = self.get_stock_list()
            logger.info(f"ğŸ“Š è·å–åˆ° {len(stock_codes)} åªè‚¡ç¥¨")
            
            # è·å–äº¤æ˜“æ—¥æœŸ
            trade_dates = self.get_trade_dates(start_date, end_date)
            logger.info(f"ğŸ“… è·å–åˆ° {len(trade_dates)} ä¸ªäº¤æ˜“æ—¥")
            
            # å¹¶å‘æŠ“å–æ•°æ®
            with ThreadPoolExecutor(max_workers=3) as executor:
                futures = []
                
                # æäº¤ä¸ªè‚¡èµ„é‡‘æµä»»åŠ¡
                for trade_date in trade_dates[-10:]:  # æœ€è¿‘10ä¸ªäº¤æ˜“æ—¥
                    future = executor.submit(
                        self.fetch_stock_moneyflow_batch,
                        trade_date,
                        stock_codes
                    )
                    futures.append(future)
                
                # æäº¤èèµ„èåˆ¸ä»»åŠ¡
                for trade_date in trade_dates[-5:]:  # æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥
                    future = executor.submit(
                        self.fetch_margin_detail,
                        trade_date
                    )
                    futures.append(future)
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                for future in as_completed(futures):
                    try:
                        result = future.result()
                        self.save_progress()
                    except Exception as e:
                        logger.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            
            # æŠ“å–æ²ªæ·±æ¸¯é€šèµ„é‡‘æµ
            self.fetch_hsgt_flow(start_date, end_date)
            
            # æœ€ç»ˆç»Ÿè®¡
            self.stats['end_time'] = datetime.now().isoformat()
            self.stats['duration'] = (datetime.now() - datetime.fromisoformat(self.stats['start_time'])).total_seconds()
            
            logger.info("ğŸ‰ èµ„é‡‘æµæ•°æ®æŠ“å–ä»»åŠ¡å®Œæˆ!")
            logger.info(f"ğŸ“Š å¤„ç†è¡¨æ•°: {self.stats['processed_tables']}")
            logger.info(f"ğŸ“ˆ æ€»è®°å½•æ•°: {self.stats['total_records']:,}")
            logger.info(f"â±ï¸ è€—æ—¶: {self.stats['duration']:.2f}ç§’")
            
            if self.stats['failed_operations']:
                logger.warning(f"âš ï¸ å¤±è´¥æ“ä½œæ•°: {len(self.stats['failed_operations'])}")
            
            self.save_progress()
            
        except Exception as e:
            logger.error(f"âŒ èµ„é‡‘æµæ•°æ®æŠ“å–ä»»åŠ¡å¤±è´¥: {e}")
            self.stats['error'] = str(e)
            self.save_progress()
            raise

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='èµ„é‡‘æµæ•°æ®æŠ“å–')
    parser.add_argument('--start-date', help='å¼€å§‹æ—¥æœŸ (YYYYMMDD)')
    parser.add_argument('--end-date', help='ç»“æŸæ—¥æœŸ (YYYYMMDD)')
    
    args = parser.parse_args()
    
    try:
        fetcher = MoneyflowDataFetcher()
        fetcher.run(args.start_date, args.end_date)
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return 1
    return 0

if __name__ == "__main__":
    exit(main())