#!/usr/bin/env python3
"""
ljwx-stock è®­ç»ƒç®¡ç†Webç•Œé¢
æä¾›å¯è§†åŒ–çš„è®­ç»ƒè¿‡ç¨‹ç®¡ç†ã€æ•°æ®é€‰æ‹©å’Œæ¨¡å‹ç›‘æ§åŠŸèƒ½
"""

from flask import Flask, render_template, request, jsonify, send_file
from flask_socketio import SocketIO, emit
import os
import sys
import json
import logging
import threading
import time
from datetime import datetime, timedelta
import pandas as pd
import subprocess
from typing import Dict, List, Optional
import uuid

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from llm.tushare_data_extractor import TuShareDataExtractor
from llm.llm_training_data_generator import LLMTrainingDataGenerator
from comprehensive_training import ComprehensiveTrainer

# ç­–ç•¥ç›¸å…³å¯¼å…¥
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'strategy'))
from strategy_models import Strategy, StrategyDatabase, STRATEGY_TEMPLATES, StrategyType
from strategy_engine import BacktestEngine

# æ¨¡å‹è¯„ä¼°ç›¸å…³å¯¼å…¥
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'model_evaluation'))
from evaluation_framework import ModelEvaluator

# æ¨èå›æµ‹ç›¸å…³å¯¼å…¥
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'recommendation_backtest'))
from model_recommender import ModelRecommender
from recommendation_tracker import RecommendationTracker

app = Flask(__name__)
app.config['SECRET_KEY'] = 'ljwx-stock-training-interface'
socketio = SocketIO(app, cors_allowed_origins="*")

# å…¨å±€çŠ¶æ€
training_status = {
    'is_running': False,
    'current_task': '',
    'progress': 0,
    'logs': [],
    'session_id': None
}

class TrainingManager:
    """è®­ç»ƒç®¡ç†å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.setup_logging()
        
        # æ•°æ®ç›®å½•
        self.data_dir = os.path.join(os.path.dirname(__file__), '..', 'data')
        self.training_dir = os.path.join(self.data_dir, 'llm_training')
        self.models_dir = os.path.join(self.data_dir, 'models')
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.training_dir, exist_ok=True)
        os.makedirs(self.models_dir, exist_ok=True)
        
        # è®­ç»ƒå™¨å®ä¾‹
        self.extractor = None
        self.generator = None
        self.trainer = None
        
        # ç­–ç•¥ç®¡ç†å™¨
        self.strategy_db = StrategyDatabase()
        self.backtest_engine = BacktestEngine()
        
        # æ¨¡å‹è¯„ä¼°å™¨
        self.model_evaluator = ModelEvaluator()
        
        # æ¨èç³»ç»Ÿ
        self.recommendation_tracker = RecommendationTracker()
        self.model_recommender = None  # å»¶è¿Ÿåˆå§‹åŒ–
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
    
    def emit_log(self, message: str, level: str = 'info'):
        """å‘é€æ—¥å¿—åˆ°å‰ç«¯"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'level': level,
            'message': message
        }
        training_status['logs'].append(log_entry)
        if len(training_status['logs']) > 1000:  # é™åˆ¶æ—¥å¿—æ•°é‡
            training_status['logs'] = training_status['logs'][-1000:]
        
        socketio.emit('log_update', log_entry)
        self.logger.info(message)
    
    def emit_progress(self, progress: int, task: str):
        """å‘é€è¿›åº¦æ›´æ–°"""
        training_status['progress'] = progress
        training_status['current_task'] = task
        socketio.emit('progress_update', {
            'progress': progress,
            'task': task
        })
    
    def get_tushare_data_info(self, token: str = None) -> Dict:
        """è·å–TuShareæ•°æ®ä¿¡æ¯"""
        try:
            if not self.extractor:
                self.extractor = TuShareDataExtractor(token)
            
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            stocks_df = self.extractor.get_stock_list(limit=100)
            
            return {
                'status': 'success',
                'stock_count': len(stocks_df),
                'sample_stocks': stocks_df.head(10).to_dict('records') if not stocks_df.empty else [],
                'has_pro_access': token is not None
            }
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
    
    def get_training_data_info(self) -> Dict:
        """è·å–è®­ç»ƒæ•°æ®ä¿¡æ¯"""
        try:
            training_files = []
            
            for filename in os.listdir(self.training_dir):
                if filename.endswith('.jsonl'):
                    file_path = os.path.join(self.training_dir, filename)
                    file_size = os.path.getsize(file_path)
                    
                    # è®¡ç®—æ ·æœ¬æ•°é‡
                    sample_count = 0
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            sample_count = sum(1 for line in f if line.strip())
                    except:
                        sample_count = 0
                    
                    training_files.append({
                        'filename': filename,
                        'size': file_size,
                        'sample_count': sample_count,
                        'created': datetime.fromtimestamp(os.path.getctime(file_path)).isoformat()
                    })
            
            return {
                'status': 'success',
                'files': sorted(training_files, key=lambda x: x['created'], reverse=True)
            }
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
    
    def get_models_info(self) -> Dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        try:
            # è·å–Ollamaæ¨¡å‹åˆ—è¡¨
            result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
            
            models = []
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')[1:]  # è·³è¿‡æ ‡é¢˜è¡Œ
                for line in lines:
                    if 'ljwx' in line.lower():
                        parts = line.split()
                        if len(parts) >= 3:
                            models.append({
                                'name': parts[0],
                                'id': parts[1],
                                'size': parts[2],
                                'modified': ' '.join(parts[3:]) if len(parts) > 3 else ''
                            })
            
            return {
                'status': 'success',
                'models': models
            }
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
    
    def start_data_generation(self, config: Dict):
        """å¼€å§‹æ•°æ®ç”Ÿæˆ"""
        def generate_data():
            try:
                training_status['is_running'] = True
                training_status['session_id'] = str(uuid.uuid4())
                
                self.emit_log("ğŸš€ å¼€å§‹æ•°æ®ç”Ÿæˆä»»åŠ¡")
                self.emit_progress(0, "åˆå§‹åŒ–æ•°æ®æå–å™¨")
                
                # åˆå§‹åŒ–ç»„ä»¶
                token = config.get('tushare_token')
                self.extractor = TuShareDataExtractor(token)
                self.generator = LLMTrainingDataGenerator()
                
                self.emit_progress(10, "è·å–è‚¡ç¥¨åˆ—è¡¨")
                
                # è·å–è‚¡ç¥¨ä»£ç 
                stock_count = config.get('stock_count', 100)
                stocks_df = self.extractor.get_stock_list(limit=stock_count)
                
                if stocks_df.empty:
                    raise Exception("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
                
                stock_codes = stocks_df['ts_code'].tolist() if 'ts_code' in stocks_df.columns else []
                if not stock_codes:
                    stock_codes = [f"{code}.SZ" if code.startswith(('0', '3')) else f"{code}.SH" 
                                 for code in stocks_df['code'].tolist()]
                
                self.emit_log(f"ğŸ“Š è·å–åˆ° {len(stock_codes)} åªè‚¡ç¥¨")
                self.emit_progress(20, "æå–å†å²æ•°æ®")
                
                # è·å–å†å²æ•°æ®
                days_back = config.get('days_back', 365)
                end_date = datetime.now().strftime('%Y%m%d')
                start_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y%m%d')
                
                dataset = self.extractor.extract_comprehensive_dataset(
                    stock_codes=stock_codes[:stock_count],
                    start_date=start_date,
                    end_date=end_date,
                    include_financial=False,
                    include_news=False
                )
                
                if 'daily_data' not in dataset or dataset['daily_data'].empty:
                    raise Exception("æ— æ³•è·å–å†å²æ•°æ®")
                
                daily_data = dataset['daily_data']
                self.emit_log(f"ğŸ“ˆ è·å–åˆ° {len(daily_data)} æ¡å†å²æ•°æ®")
                self.emit_progress(60, "ç”Ÿæˆè®­ç»ƒæ ·æœ¬")
                
                # ç”Ÿæˆè®­ç»ƒæ•°æ®
                max_examples = config.get('max_examples', 1000)
                training_examples = self.generator.create_training_examples(
                    daily_data, max_examples=max_examples
                )
                
                # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                training_data = []
                for example in training_examples:
                    if hasattr(example, '__dict__'):
                        example_dict = {
                            'instruction': example.instruction,
                            'input': example.input,
                            'output': example.output,
                            'metadata': example.metadata
                        }
                    else:
                        example_dict = example
                    training_data.append(example_dict)
                
                self.emit_progress(80, "ä¿å­˜è®­ç»ƒæ•°æ®")
                
                # ä¿å­˜è®­ç»ƒæ•°æ®
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"web_generated_training_data_{timestamp}.jsonl"
                filepath = os.path.join(self.training_dir, filename)
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    for data in training_data:
                        f.write(json.dumps(data, ensure_ascii=False) + '\n')
                
                self.emit_progress(100, "æ•°æ®ç”Ÿæˆå®Œæˆ")
                self.emit_log(f"âœ… è®­ç»ƒæ•°æ®ç”Ÿæˆå®Œæˆï¼š{len(training_data)} ä¸ªæ ·æœ¬")
                self.emit_log(f"ğŸ“ æ–‡ä»¶ä¿å­˜ï¼š{filename}")
                
                socketio.emit('task_completed', {
                    'type': 'data_generation',
                    'filename': filename,
                    'sample_count': len(training_data)
                })
                
            except Exception as e:
                self.emit_log(f"âŒ æ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}", 'error')
                socketio.emit('task_failed', {
                    'type': 'data_generation',
                    'error': str(e)
                })
            finally:
                training_status['is_running'] = False
        
        thread = threading.Thread(target=generate_data)
        thread.daemon = True
        thread.start()
    
    def start_model_training(self, config: Dict):
        """å¼€å§‹æ¨¡å‹è®­ç»ƒ"""
        def train_model():
            try:
                training_status['is_running'] = True
                training_status['session_id'] = str(uuid.uuid4())
                
                self.emit_log("ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒä»»åŠ¡")
                self.emit_progress(0, "å‡†å¤‡è®­ç»ƒæ•°æ®")
                
                # åŠ è½½è®­ç»ƒæ•°æ®
                training_file = config.get('training_file')
                if not training_file:
                    raise Exception("æœªé€‰æ‹©è®­ç»ƒæ–‡ä»¶")
                
                training_path = os.path.join(self.training_dir, training_file)
                if not os.path.exists(training_path):
                    raise Exception(f"è®­ç»ƒæ–‡ä»¶ä¸å­˜åœ¨: {training_file}")
                
                # è¯»å–è®­ç»ƒæ•°æ®
                training_data = []
                with open(training_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            training_data.append(json.loads(line.strip()))
                
                self.emit_log(f"ğŸ“Š åŠ è½½è®­ç»ƒæ•°æ®: {len(training_data)} ä¸ªæ ·æœ¬")
                self.emit_progress(20, "åˆ›å»ºæ¨¡å‹")
                
                # å‡†å¤‡æ¨¡å‹é…ç½®
                base_model = config.get('base_model', 'ljwx-stock')
                model_name = config.get('model_name', f"ljwx-stock-web-{datetime.now().strftime('%Y%m%d_%H%M')}")
                sample_count = min(len(training_data), config.get('sample_count', 200))
                
                # æ„å»ºç³»ç»Ÿæç¤ºè¯
                system_prompt = """ä½ æ˜¯ljwx-stockï¼Œä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨æŠ•èµ„åˆ†æåŠ©æ‰‹ã€‚åŸºäºå¤§é‡Aè‚¡å¸‚åœºå†å²æ•°æ®è®­ç»ƒï¼Œå…·å¤‡ä»¥ä¸‹ä¸“ä¸šèƒ½åŠ›ï¼š

ğŸ¯ **æ ¸å¿ƒä¼˜åŠ¿**
- åŸºäºçœŸå®å†å²æ•°æ®çš„æ·±åº¦å­¦ä¹ 
- å¤šç»´åº¦æŠ€æœ¯åˆ†æå’Œé£é™©è¯„ä¼°èƒ½åŠ›
- ä¸“ä¸šçš„æŠ•èµ„å†³ç­–æ”¯æŒ

ğŸ“Š **åˆ†æèƒ½åŠ›**
1. **æŠ€æœ¯æŒ‡æ ‡åˆ†æ**ï¼šç²¾é€šKçº¿ã€å‡çº¿ã€RSIã€MACDã€å¸ƒæ—å¸¦ç­‰æŠ€æœ¯æŒ‡æ ‡
2. **è¶‹åŠ¿åˆ¤æ–­**ï¼šåŸºäºå†å²æ¨¡å¼è¯†åˆ«ä»·æ ¼è¶‹åŠ¿å’Œè½¬æŠ˜ç‚¹
3. **é£é™©è¯„ä¼°**ï¼šå¤šå±‚æ¬¡é£é™©å› ç´ åˆ†æå’Œç­‰çº§è¯„å®š
4. **æˆäº¤é‡åˆ†æ**ï¼šç†è§£é‡ä»·å…³ç³»å’Œå¸‚åœºå‚ä¸åº¦
5. **æ”¯æ’‘é˜»åŠ›**ï¼šå‡†ç¡®è¯†åˆ«å…³é”®ä»·æ ¼æ°´å¹³

ğŸ’¡ **æœåŠ¡ç‰¹è‰²**
- åŸºäºçœŸå®å¸‚åœºæ•°æ®çš„ä¸“ä¸šåˆ†æ
- å®¢è§‚ç†æ€§çš„æŠ•èµ„å»ºè®®
- æ˜ç¡®çš„é£é™©æç¤ºå’Œæ“ä½œæŒ‡å¯¼

âš ï¸ **é£é™©æç¤º**ï¼šæ‰€æœ‰åˆ†æåŸºäºå†å²æ•°æ®ï¼ŒæŠ•èµ„æœ‰é£é™©ï¼Œè¯·è°¨æ…å†³ç­–ã€‚"""

                self.emit_progress(40, "æ„å»ºModelfile")
                
                # åˆ›å»ºModelfile
                import tempfile
                import random
                
                modelfile_content = f"""FROM {base_model}
SYSTEM "{system_prompt}"
PARAMETER temperature {config.get('temperature', 0.7)}
PARAMETER top_p {config.get('top_p', 0.9)}
PARAMETER top_k {config.get('top_k', 40)}
PARAMETER repeat_penalty {config.get('repeat_penalty', 1.1)}
PARAMETER num_predict {config.get('num_predict', 1024)}

"""
                
                # æ·»åŠ è®­ç»ƒæ ·æœ¬
                selected_samples = random.sample(training_data, sample_count)
                
                for i, example in enumerate(selected_samples):
                    instruction = example.get('instruction', '')
                    input_text = example.get('input', '')
                    output_text = example.get('output', '')
                    
                    user_message = f"{instruction}\n\n{input_text}" if input_text else instruction
                    
                    # æ¸…ç†æ–‡æœ¬
                    user_message = user_message.replace('"', "'").replace('\n', '\\n')
                    output_text = output_text.replace('"', "'").replace('\n', '\\n')
                    
                    modelfile_content += f'MESSAGE user "{user_message}"\n'
                    modelfile_content += f'MESSAGE assistant "{output_text}"\n\n'
                    
                    if (i + 1) % 50 == 0:
                        progress = 40 + int((i + 1) / sample_count * 40)
                        self.emit_progress(progress, f"æ·»åŠ è®­ç»ƒæ ·æœ¬ {i+1}/{sample_count}")
                
                self.emit_progress(80, "æ‰§è¡Œæ¨¡å‹è®­ç»ƒ")
                
                # åˆ›å»ºä¸´æ—¶Modelfileå¹¶è®­ç»ƒ
                with tempfile.NamedTemporaryFile(mode='w', suffix='.modelfile', delete=False) as f:
                    f.write(modelfile_content)
                    modelfile_path = f.name
                
                try:
                    self.emit_log(f"ğŸ¤– åˆ›å»ºæ¨¡å‹: {model_name}")
                    
                    result = subprocess.run(
                        ['ollama', 'create', model_name, '-f', modelfile_path],
                        capture_output=True,
                        text=True,
                        timeout=1800  # 30åˆ†é’Ÿè¶…æ—¶
                    )
                    
                    if result.returncode == 0:
                        self.emit_progress(95, "æµ‹è¯•æ¨¡å‹")
                        self.emit_log(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ: {model_name}")
                        
                        # ç®€å•æµ‹è¯•
                        test_result = subprocess.run(
                            ['ollama', 'run', model_name],
                            input="æµ‹è¯•æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ",
                            capture_output=True,
                            text=True,
                            timeout=30
                        )
                        
                        if test_result.returncode == 0:
                            self.emit_log("âœ… æ¨¡å‹æµ‹è¯•é€šè¿‡")
                        else:
                            self.emit_log("âš ï¸ æ¨¡å‹æµ‹è¯•å¼‚å¸¸", 'warning')
                        
                        self.emit_progress(100, "è®­ç»ƒå®Œæˆ")
                        
                        socketio.emit('task_completed', {
                            'type': 'model_training',
                            'model_name': model_name,
                            'sample_count': sample_count
                        })
                    else:
                        raise Exception(f"æ¨¡å‹åˆ›å»ºå¤±è´¥: {result.stderr}")
                        
                finally:
                    os.unlink(modelfile_path)
                
            except Exception as e:
                self.emit_log(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}", 'error')
                socketio.emit('task_failed', {
                    'type': 'model_training',
                    'error': str(e)
                })
            finally:
                training_status['is_running'] = False
        
        thread = threading.Thread(target=train_model)
        thread.daemon = True
        thread.start()
    
    def run_strategy_backtest(self, strategy_id: str, config: Dict):
        """è¿è¡Œç­–ç•¥å›æµ‹"""
        def backtest():
            try:
                training_status['is_running'] = True
                training_status['session_id'] = str(uuid.uuid4())
                
                self.emit_log("ğŸš€ å¼€å§‹ç­–ç•¥å›æµ‹")
                self.emit_progress(0, "åŠ è½½ç­–ç•¥")
                
                # è·å–ç­–ç•¥
                strategy = self.strategy_db.get_strategy(strategy_id)
                if not strategy:
                    raise Exception(f"ç­–ç•¥ä¸å­˜åœ¨: {strategy_id}")
                
                self.emit_progress(20, "è·å–å†å²æ•°æ®")
                
                # è·å–å›æµ‹æ•°æ®
                token = config.get('tushare_token')
                if not self.extractor:
                    self.extractor = TuShareDataExtractor(token)
                
                stock_code = config.get('stock_code', '000001.SZ')
                start_date = config.get('start_date')
                end_date = config.get('end_date')
                
                # è·å–è‚¡ç¥¨æ•°æ®
                df = self.extractor.get_stock_daily_data(stock_code, start_date, end_date)
                if df.empty:
                    raise Exception("æ— æ³•è·å–è‚¡ç¥¨æ•°æ®")
                
                # è®¾ç½®ç´¢å¼•ä¸ºæ—¥æœŸ
                if 'trade_date' in df.columns:
                    df['trade_date'] = pd.to_datetime(df['trade_date'])
                    df.set_index('trade_date', inplace=True)
                
                self.emit_progress(50, "æ‰§è¡Œå›æµ‹")
                
                # è¿è¡Œå›æµ‹
                result = self.backtest_engine.run_backtest(df, strategy, start_date, end_date)
                
                self.emit_progress(80, "ä¿å­˜ç»“æœ")
                
                # ä¿å­˜å›æµ‹ç»“æœ
                result_id = self.strategy_db.save_backtest_result(result)
                
                self.emit_progress(100, "å›æµ‹å®Œæˆ")
                self.emit_log(f"âœ… ç­–ç•¥å›æµ‹å®Œæˆ")
                self.emit_log(f"ğŸ“Š æ€»æ”¶ç›Šç‡: {result.total_return:.2%}")
                self.emit_log(f"ğŸ“ˆ å¤æ™®æ¯”ç‡: {result.sharpe_ratio:.2f}")
                self.emit_log(f"ğŸ“‰ æœ€å¤§å›æ’¤: {result.max_drawdown:.2%}")
                
                socketio.emit('backtest_completed', {
                    'strategy_id': strategy_id,
                    'result_id': result_id,
                    'summary': {
                        'total_return': result.total_return,
                        'annual_return': result.annual_return,
                        'max_drawdown': result.max_drawdown,
                        'sharpe_ratio': result.sharpe_ratio,
                        'win_rate': result.win_rate,
                        'total_trades': result.total_trades
                    }
                })
                
            except Exception as e:
                self.emit_log(f"âŒ ç­–ç•¥å›æµ‹å¤±è´¥: {str(e)}", 'error')
                socketio.emit('task_failed', {
                    'type': 'strategy_backtest',
                    'error': str(e)
                })
            finally:
                training_status['is_running'] = False
        
        thread = threading.Thread(target=backtest)
        thread.daemon = True
        thread.start()
    
    def run_model_evaluation(self, model_name: str, config: Dict):
        """è¿è¡Œæ¨¡å‹è¯„ä¼°"""
        def evaluate():
            try:
                training_status['is_running'] = True
                training_status['session_id'] = str(uuid.uuid4())
                
                self.emit_log(f"ğŸš€ å¼€å§‹è¯„ä¼°æ¨¡å‹: {model_name}")
                self.emit_progress(0, "åˆå§‹åŒ–è¯„ä¼°å™¨")
                
                # è·å–æµ‹è¯•ç”¨ä¾‹
                category = config.get('category')
                difficulty = config.get('difficulty')
                test_cases = self.model_evaluator.get_test_cases(category=category, difficulty=difficulty)
                
                if not test_cases:
                    raise Exception("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æµ‹è¯•ç”¨ä¾‹")
                
                self.emit_log(f"ğŸ“‹ åŠ è½½æµ‹è¯•ç”¨ä¾‹: {len(test_cases)}ä¸ª")
                self.emit_progress(10, f"å¼€å§‹è¯„ä¼° {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
                
                # è¿è¡Œè¯„ä¼°
                timeout = config.get('timeout', 30)
                metrics = self.model_evaluator.evaluate_model(model_name, test_cases, timeout)
                
                self.emit_progress(90, "åˆ†æè¯„ä¼°ç»“æœ")
                
                # è®¡ç®—è¯¦ç»†ç»Ÿè®¡
                summary = {
                    'model_name': model_name,
                    'total_tests': metrics.total_tests,
                    'success_rate': metrics.success_rate,
                    'avg_overall_score': metrics.avg_overall_score,
                    'avg_response_time': metrics.avg_response_time,
                    'category_scores': metrics.category_scores,
                    'difficulty_scores': metrics.difficulty_scores,
                    'evaluation_date': metrics.evaluation_date
                }
                
                self.emit_progress(100, "è¯„ä¼°å®Œæˆ")
                self.emit_log(f"âœ… æ¨¡å‹è¯„ä¼°å®Œæˆ")
                self.emit_log(f"ğŸ“Š æ€»ä½“åˆ†æ•°: {metrics.avg_overall_score:.2f}")
                self.emit_log(f"ğŸ“ˆ æˆåŠŸç‡: {metrics.success_rate:.2%}")
                self.emit_log(f"â±ï¸ å¹³å‡å“åº”æ—¶é—´: {metrics.avg_response_time:.2f}ç§’")
                
                socketio.emit('evaluation_completed', {
                    'model_name': model_name,
                    'summary': summary,
                    'detailed_results': [
                        {
                            'test_case_id': r.test_case_id,
                            'overall_score': r.overall_score,
                            'response_time': r.response_time,
                            'error_message': r.error_message
                        } for r in metrics.test_results[:10]  # åªè¿”å›å‰10ä¸ªç»“æœ
                    ]
                })
                
            except Exception as e:
                self.emit_log(f"âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥: {str(e)}", 'error')
                socketio.emit('task_failed', {
                    'type': 'model_evaluation',
                    'error': str(e)
                })
            finally:
                training_status['is_running'] = False
        
        thread = threading.Thread(target=evaluate)
        thread.daemon = True
        thread.start()
    
    def run_recommendation_generation(self, model_name: str, config: Dict):
        """è¿è¡Œæ¨èç”Ÿæˆ"""
        def generate():
            try:
                training_status['is_running'] = True
                training_status['session_id'] = str(uuid.uuid4())
                
                self.emit_log(f"ğŸš€ å¼€å§‹ç”Ÿæˆè‚¡ç¥¨æ¨è: {model_name}")
                self.emit_progress(0, "åˆå§‹åŒ–æ¨èç³»ç»Ÿ")
                
                # åˆå§‹åŒ–æ¨èå™¨
                if not self.model_recommender:
                    tushare_token = config.get('tushare_token')
                    self.model_recommender = ModelRecommender(model_name, tushare_token)
                
                self.emit_progress(20, "è·å–è‚¡ç¥¨å€™é€‰åˆ—è¡¨")
                
                # ç”Ÿæˆæ¨è
                num_stocks = config.get('num_stocks', 5)
                analysis_type = config.get('analysis_type', 'comprehensive_analysis')
                
                if config.get('use_daily_mode', True):
                    # æ¯æ—¥æ¨èæ¨¡å¼
                    recommendations = self.model_recommender.generate_daily_recommendations(num_stocks)
                else:
                    # æŒ‡å®šè‚¡ç¥¨æ¨¡å¼
                    stock_codes = config.get('stock_codes', [])
                    recommendations = self.model_recommender.generate_stock_recommendations(
                        stock_codes, analysis_type, num_stocks
                    )
                
                self.emit_progress(80, "ä¿å­˜æ¨èç»“æœ")
                
                # è·å–æ¨èè¯¦æƒ…
                recommendation_details = []
                for rec_id in recommendations:
                    rec = self.recommendation_tracker.get_recommendation_by_id(rec_id)
                    if rec:
                        recommendation_details.append({
                            'id': rec.id,
                            'stock_code': rec.stock_code,
                            'stock_name': rec.stock_name,
                            'recommendation_type': rec.recommendation_type,
                            'confidence_score': rec.confidence_score,
                            'target_price': rec.target_price,
                            'recommend_price': rec.recommend_price
                        })
                
                self.emit_progress(100, "æ¨èç”Ÿæˆå®Œæˆ")
                self.emit_log(f"âœ… ç”Ÿæˆæ¨èå®Œæˆ: {len(recommendations)} ä¸ª")
                
                socketio.emit('recommendation_generated', {
                    'model_name': model_name,
                    'total_recommendations': len(recommendations),
                    'recommendations': recommendation_details
                })
                
            except Exception as e:
                self.emit_log(f"âŒ æ¨èç”Ÿæˆå¤±è´¥: {str(e)}", 'error')
                socketio.emit('task_failed', {
                    'type': 'recommendation_generation',
                    'error': str(e)
                })
            finally:
                training_status['is_running'] = False
        
        thread = threading.Thread(target=generate)
        thread.daemon = True
        thread.start()
    
    def run_recommendation_validation(self, model_name: str = None):
        """è¿è¡Œæ¨èéªŒè¯"""
        def validate():
            try:
                training_status['is_running'] = True
                training_status['session_id'] = str(uuid.uuid4())
                
                self.emit_log("ğŸ” å¼€å§‹éªŒè¯æ¨èç»“æœ")
                self.emit_progress(0, "æ£€æŸ¥å¾…éªŒè¯æ¨è")
                
                # æ‰§è¡ŒéªŒè¯
                validation_result = self.recommendation_tracker.validate_recommendations(model_name)
                
                self.emit_progress(100, "éªŒè¯å®Œæˆ")
                self.emit_log(f"âœ… éªŒè¯å®Œæˆ: {validation_result} æ¡æ¨è")
                
                socketio.emit('validation_completed', {
                    'validated_count': validation_result,
                    'model_name': model_name or 'all'
                })
                
            except Exception as e:
                self.emit_log(f"âŒ æ¨èéªŒè¯å¤±è´¥: {str(e)}", 'error')
                socketio.emit('task_failed', {
                    'type': 'recommendation_validation',
                    'error': str(e)
                })
            finally:
                training_status['is_running'] = False
        
        thread = threading.Thread(target=validate)
        thread.daemon = True
        thread.start()

# åˆ›å»ºè®­ç»ƒç®¡ç†å™¨å®ä¾‹
training_manager = TrainingManager()

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')

@app.route('/api/status')
def get_status():
    """è·å–è®­ç»ƒçŠ¶æ€"""
    return jsonify(training_status)

@app.route('/api/tushare-info')
def get_tushare_info():
    """è·å–TuShareæ•°æ®ä¿¡æ¯"""
    token = request.args.get('token')
    return jsonify(training_manager.get_tushare_data_info(token))

@app.route('/api/training-data-info')
def get_training_data_info():
    """è·å–è®­ç»ƒæ•°æ®ä¿¡æ¯"""
    return jsonify(training_manager.get_training_data_info())

@app.route('/api/models-info')
def get_models_info():
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    return jsonify(training_manager.get_models_info())

@app.route('/api/generate-data', methods=['POST'])
def generate_data():
    """ç”Ÿæˆè®­ç»ƒæ•°æ®"""
    if training_status['is_running']:
        return jsonify({'error': 'è®­ç»ƒä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­'}), 400
    
    config = request.json
    training_manager.start_data_generation(config)
    return jsonify({'status': 'started'})

@app.route('/api/train-model', methods=['POST'])
def train_model():
    """è®­ç»ƒæ¨¡å‹"""
    if training_status['is_running']:
        return jsonify({'error': 'è®­ç»ƒä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­'}), 400
    
    config = request.json
    training_manager.start_model_training(config)
    return jsonify({'status': 'started'})

@app.route('/api/stop-training', methods=['POST'])
def stop_training():
    """åœæ­¢è®­ç»ƒ"""
    training_status['is_running'] = False
    return jsonify({'status': 'stopped'})

@app.route('/api/clear-logs', methods=['POST'])
def clear_logs():
    """æ¸…é™¤æ—¥å¿—"""
    training_status['logs'] = []
    return jsonify({'status': 'cleared'})

# ================== ç­–ç•¥ç®¡ç†API ==================

@app.route('/api/strategies')
def list_strategies():
    """è·å–ç­–ç•¥åˆ—è¡¨"""
    user_id = request.args.get('user_id', 'default')
    strategy_type = request.args.get('type')
    public_only = request.args.get('public') == 'true'
    
    strategies = training_manager.strategy_db.list_strategies(
        user_id=user_id, 
        strategy_type=strategy_type, 
        public_only=public_only
    )
    
    strategy_list = []
    for strategy in strategies:
        strategy_dict = {
            'id': strategy.id,
            'name': strategy.name,
            'description': strategy.description,
            'strategy_type': strategy.strategy_type,
            'user_id': strategy.user_id,
            'created_at': strategy.created_at,
            'updated_at': strategy.updated_at,
            'is_public': strategy.is_public,
            'tags': strategy.tags,
            'buy_rules_count': len(strategy.buy_rules) if strategy.buy_rules else 0,
            'sell_rules_count': len(strategy.sell_rules) if strategy.sell_rules else 0
        }
        strategy_list.append(strategy_dict)
    
    return jsonify({'strategies': strategy_list})

@app.route('/api/strategies/<strategy_id>')
def get_strategy(strategy_id):
    """è·å–å•ä¸ªç­–ç•¥"""
    strategy = training_manager.strategy_db.get_strategy(strategy_id)
    if not strategy:
        return jsonify({'error': 'ç­–ç•¥ä¸å­˜åœ¨'}), 404
    
    from dataclasses import asdict
    return jsonify({'strategy': asdict(strategy)})

@app.route('/api/strategies', methods=['POST'])
def create_strategy():
    """åˆ›å»ºç­–ç•¥"""
    try:
        data = request.json
        
        # åˆ›å»ºç­–ç•¥å¯¹è±¡
        strategy = Strategy(
            name=data.get('name', ''),
            description=data.get('description', ''),
            strategy_type=data.get('strategy_type', StrategyType.TECHNICAL.value),
            user_id=data.get('user_id', 'default'),
            initial_capital=data.get('initial_capital', 100000.0),
            commission=data.get('commission', 0.0003),
            slippage=data.get('slippage', 0.0001),
            is_public=data.get('is_public', False),
            tags=data.get('tags', [])
        )
        
        # å¤„ç†ä¹°å…¥è§„åˆ™
        if 'buy_rules' in data and data['buy_rules']:
            from strategy_models import StrategyRule, TradingCondition
            buy_rules = []
            for rule_data in data['buy_rules']:
                conditions = []
                for cond_data in rule_data.get('conditions', []):
                    conditions.append(TradingCondition(**cond_data))
                
                rule = StrategyRule(
                    name=rule_data.get('name', ''),
                    conditions=conditions,
                    logic_operator=rule_data.get('logic_operator', 'AND'),
                    signal_type=rule_data.get('signal_type', 'buy'),
                    weight=rule_data.get('weight', 1.0)
                )
                buy_rules.append(rule)
            strategy.buy_rules = buy_rules
        
        # å¤„ç†å–å‡ºè§„åˆ™
        if 'sell_rules' in data and data['sell_rules']:
            from strategy_models import StrategyRule, TradingCondition
            sell_rules = []
            for rule_data in data['sell_rules']:
                conditions = []
                for cond_data in rule_data.get('conditions', []):
                    conditions.append(TradingCondition(**cond_data))
                
                rule = StrategyRule(
                    name=rule_data.get('name', ''),
                    conditions=conditions,
                    logic_operator=rule_data.get('logic_operator', 'AND'),
                    signal_type=rule_data.get('signal_type', 'sell'),
                    weight=rule_data.get('weight', 1.0)
                )
                sell_rules.append(rule)
            strategy.sell_rules = sell_rules
        
        # å¤„ç†é£é™©ç®¡ç†
        if 'risk_management' in data:
            from strategy_models import RiskManagement
            strategy.risk_management = RiskManagement(**data['risk_management'])
        
        # ä¿å­˜ç­–ç•¥
        strategy_id = training_manager.strategy_db.save_strategy(strategy)
        
        return jsonify({'strategy_id': strategy_id, 'status': 'created'})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 400

@app.route('/api/strategies/<strategy_id>', methods=['PUT'])
def update_strategy(strategy_id):
    """æ›´æ–°ç­–ç•¥"""
    try:
        strategy = training_manager.strategy_db.get_strategy(strategy_id)
        if not strategy:
            return jsonify({'error': 'ç­–ç•¥ä¸å­˜åœ¨'}), 404
        
        data = request.json
        
        # æ›´æ–°åŸºæœ¬ä¿¡æ¯
        if 'name' in data:
            strategy.name = data['name']
        if 'description' in data:
            strategy.description = data['description']
        if 'strategy_type' in data:
            strategy.strategy_type = data['strategy_type']
        if 'is_public' in data:
            strategy.is_public = data['is_public']
        if 'tags' in data:
            strategy.tags = data['tags']
        
        # æ›´æ–°è§„åˆ™å’Œé£é™©ç®¡ç†ç±»ä¼¼åˆ›å»ºé€»è¾‘...
        
        # ä¿å­˜æ›´æ–°
        training_manager.strategy_db.save_strategy(strategy)
        
        return jsonify({'status': 'updated'})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 400

@app.route('/api/strategies/<strategy_id>', methods=['DELETE'])
def delete_strategy(strategy_id):
    """åˆ é™¤ç­–ç•¥"""
    success = training_manager.strategy_db.delete_strategy(strategy_id)
    if success:
        return jsonify({'status': 'deleted'})
    else:
        return jsonify({'error': 'ç­–ç•¥ä¸å­˜åœ¨'}), 404

@app.route('/api/strategy-templates')
def get_strategy_templates():
    """è·å–ç­–ç•¥æ¨¡æ¿"""
    return jsonify({'templates': STRATEGY_TEMPLATES})

@app.route('/api/strategies/<strategy_id>/backtest', methods=['POST'])
def run_backtest(strategy_id):
    """è¿è¡Œç­–ç•¥å›æµ‹"""
    if training_status['is_running']:
        return jsonify({'error': 'ä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­'}), 400
    
    config = request.json
    config['strategy_id'] = strategy_id
    
    training_manager.run_strategy_backtest(strategy_id, config)
    return jsonify({'status': 'started'})

@app.route('/api/strategies/<strategy_id>/backtest-results')
def get_backtest_results(strategy_id):
    """è·å–å›æµ‹ç»“æœ"""
    results = training_manager.strategy_db.get_backtest_results(strategy_id)
    
    result_list = []
    for result in results:
        from dataclasses import asdict
        result_dict = asdict(result)
        # ç®€åŒ–è¿”å›æ•°æ®ï¼Œé¿å…è¿‡å¤§çš„æ•°ç»„
        if 'equity_curve' in result_dict and len(result_dict['equity_curve']) > 100:
            # é‡‡æ ·æ˜¾ç¤ºå…³é”®ç‚¹
            curve = result_dict['equity_curve']
            step = len(curve) // 100
            result_dict['equity_curve'] = curve[::step]
        
        result_list.append(result_dict)
    
    return jsonify({'results': result_list})

# ================== æ¨¡å‹è¯„ä¼°API ==================

@app.route('/api/evaluation/test-cases')
def get_test_cases():
    """è·å–æµ‹è¯•ç”¨ä¾‹"""
    category = request.args.get('category')
    difficulty = request.args.get('difficulty')
    
    test_cases = training_manager.model_evaluator.get_test_cases(category=category, difficulty=difficulty)
    
    test_case_list = []
    for test_case in test_cases:
        from dataclasses import asdict
        test_case_dict = asdict(test_case)
        test_case_list.append(test_case_dict)
    
    return jsonify({'test_cases': test_case_list})

@app.route('/api/evaluation/start', methods=['POST'])
def start_model_evaluation():
    """å¼€å§‹æ¨¡å‹è¯„ä¼°"""
    if training_status['is_running']:
        return jsonify({'error': 'ä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­'}), 400
    
    data = request.json
    model_name = data.get('model_name')
    if not model_name:
        return jsonify({'error': 'æœªæŒ‡å®šæ¨¡å‹åç§°'}), 400
    
    config = {
        'category': data.get('category'),
        'difficulty': data.get('difficulty'),
        'timeout': data.get('timeout', 30)
    }
    
    training_manager.run_model_evaluation(model_name, config)
    return jsonify({'status': 'started'})

@app.route('/api/evaluation/results/<model_name>')
def get_evaluation_results(model_name):
    """è·å–è¯„ä¼°ç»“æœ"""
    try:
        history = training_manager.model_evaluator.get_model_performance_history(model_name)
        
        results = []
        for metrics in history:
            from dataclasses import asdict
            metrics_dict = asdict(metrics)
            # ç®€åŒ–æ•°æ®ï¼Œç§»é™¤è¯¦ç»†æµ‹è¯•ç»“æœ
            metrics_dict.pop('test_results', None)
            results.append(metrics_dict)
        
        return jsonify({'results': results})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/evaluation/compare', methods=['POST'])
def compare_models():
    """æ¯”è¾ƒæ¨¡å‹æ€§èƒ½"""
    data = request.json
    model_names = data.get('model_names', [])
    
    if len(model_names) < 2:
        return jsonify({'error': 'è‡³å°‘éœ€è¦ä¸¤ä¸ªæ¨¡å‹è¿›è¡Œæ¯”è¾ƒ'}), 400
    
    try:
        comparison_data = training_manager.model_evaluator.compare_models(model_names)
        return jsonify({'comparison': comparison_data})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/evaluation/categories')
def get_evaluation_categories():
    """è·å–è¯„ä¼°ç±»åˆ«"""
    categories = [
        {'value': '', 'label': 'å…¨éƒ¨ç±»åˆ«'},
        {'value': 'æŠ€æœ¯åˆ†æ', 'label': 'æŠ€æœ¯åˆ†æ'},
        {'value': 'é£é™©è¯„ä¼°', 'label': 'é£é™©è¯„ä¼°'},
        {'value': 'å¸‚åœºæƒ…ç»ª', 'label': 'å¸‚åœºæƒ…ç»ª'},
        {'value': 'æŠ•èµ„ç­–ç•¥', 'label': 'æŠ•èµ„ç­–ç•¥'},
        {'value': 'åŸºæœ¬é¢åˆ†æ', 'label': 'åŸºæœ¬é¢åˆ†æ'},
        {'value': 'è¾¹ç•Œæµ‹è¯•', 'label': 'è¾¹ç•Œæµ‹è¯•'}
    ]
    
    difficulties = [
        {'value': '', 'label': 'å…¨éƒ¨éš¾åº¦'},
        {'value': 'easy', 'label': 'ç®€å•'},
        {'value': 'medium', 'label': 'ä¸­ç­‰'},
        {'value': 'hard', 'label': 'å›°éš¾'}
    ]
    
    return jsonify({
        'categories': categories,
        'difficulties': difficulties
    })

# ================== æ¨èå›æµ‹API ==================

@app.route('/api/recommendations/generate', methods=['POST'])
def generate_recommendations():
    """ç”Ÿæˆè‚¡ç¥¨æ¨è"""
    if training_status['is_running']:
        return jsonify({'error': 'ä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­'}), 400
    
    data = request.json
    model_name = data.get('model_name', 'ljwx-stock')
    
    config = {
        'num_stocks': data.get('num_stocks', 5),
        'analysis_type': data.get('analysis_type', 'comprehensive_analysis'),
        'use_daily_mode': data.get('use_daily_mode', True),
        'stock_codes': data.get('stock_codes', []),
        'tushare_token': data.get('tushare_token', '')
    }
    
    training_manager.run_recommendation_generation(model_name, config)
    return jsonify({'status': 'started'})

@app.route('/api/recommendations/validate', methods=['POST'])
def validate_recommendations():
    """éªŒè¯æ¨èç»“æœ"""
    if training_status['is_running']:
        return jsonify({'error': 'ä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­'}), 400
    
    data = request.json
    model_name = data.get('model_name')
    
    training_manager.run_recommendation_validation(model_name)
    return jsonify({'status': 'started'})

@app.route('/api/recommendations/<model_name>')
def get_model_recommendations(model_name):
    """è·å–æ¨¡å‹æ¨èåˆ—è¡¨"""
    try:
        limit = request.args.get('limit', 50, type=int)
        recommendations = training_manager.recommendation_tracker.get_model_recommendations(model_name, limit)
        
        recommendation_list = []
        for rec in recommendations:
            from dataclasses import asdict
            rec_dict = asdict(rec)
            recommendation_list.append(rec_dict)
        
        return jsonify({'recommendations': recommendation_list})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/recommendations/<rec_id>/detail')
def get_recommendation_detail(rec_id):
    """è·å–æ¨èè¯¦æƒ…"""
    try:
        rec = training_manager.recommendation_tracker.get_recommendation_by_id(rec_id)
        if rec:
            from dataclasses import asdict
            return jsonify({'recommendation': asdict(rec)})
        else:
            return jsonify({'error': 'æ¨èä¸å­˜åœ¨'}), 404
            
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/recommendations/backtest/<model_name>')
def get_backtest_report(model_name):
    """è·å–å›æµ‹æŠ¥å‘Š"""
    try:
        start_date = request.args.get('start_date')
        end_date = request.args.get('end_date')
        
        metrics = training_manager.recommendation_tracker.generate_backtest_report(
            model_name, start_date, end_date
        )
        
        from dataclasses import asdict
        # ç®€åŒ–æ•°æ®ï¼Œé¿å…è¿”å›è¿‡å¤§çš„æ¨èåˆ—è¡¨
        metrics_dict = asdict(metrics)
        metrics_dict['recommendations'] = metrics_dict['recommendations'][:10]  # åªè¿”å›å‰10ä¸ª
        
        return jsonify({'metrics': metrics_dict})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/recommendations/performance/<model_name>')
def get_model_performance(model_name):
    """è·å–æ¨¡å‹æ€§èƒ½æ‘˜è¦"""
    try:
        days = request.args.get('days', 30, type=int)
        
        # åˆå§‹åŒ–æ¨èå™¨ä»¥è·å–æ€§èƒ½æ•°æ®
        if not training_manager.model_recommender:
            training_manager.model_recommender = ModelRecommender(model_name)
        
        performance = training_manager.model_recommender.get_model_performance_summary(days)
        
        return jsonify({'performance': performance})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/recommendations/statistics')
def get_recommendation_statistics():
    """è·å–æ¨èç»Ÿè®¡ä¿¡æ¯"""
    try:
        with sqlite3.connect(training_manager.recommendation_tracker.db_path) as conn:
            # æ€»ä½“ç»Ÿè®¡
            cursor = conn.execute('''
                SELECT 
                    COUNT(*) as total,
                    COUNT(CASE WHEN result = 'hit' THEN 1 END) as hits,
                    COUNT(CASE WHEN result = 'miss' THEN 1 END) as misses,
                    COUNT(CASE WHEN result = 'pending' THEN 1 END) as pending,
                    AVG(confidence_score) as avg_confidence,
                    AVG(actual_return) as avg_return
                FROM recommendations
            ''')
            
            total_stats = cursor.fetchone()
            
            # æŒ‰æ¨¡å‹ç»Ÿè®¡
            cursor = conn.execute('''
                SELECT 
                    model_name,
                    COUNT(*) as total,
                    COUNT(CASE WHEN result = 'hit' THEN 1 END) as hits,
                    COUNT(CASE WHEN result = 'miss' THEN 1 END) as misses,
                    AVG(confidence_score) as avg_confidence
                FROM recommendations
                GROUP BY model_name
                ORDER BY total DESC
            ''')
            
            model_stats = cursor.fetchall()
            
            # æŒ‰ç±»å‹ç»Ÿè®¡
            cursor = conn.execute('''
                SELECT 
                    recommendation_type,
                    COUNT(*) as total,
                    COUNT(CASE WHEN result = 'hit' THEN 1 END) as hits,
                    AVG(actual_return) as avg_return
                FROM recommendations
                WHERE result != 'pending'
                GROUP BY recommendation_type
            ''')
            
            type_stats = cursor.fetchall()
            
            return jsonify({
                'total_statistics': {
                    'total_recommendations': total_stats[0],
                    'total_hits': total_stats[1] or 0,
                    'total_misses': total_stats[2] or 0,
                    'pending_recommendations': total_stats[3] or 0,
                    'overall_hit_rate': (total_stats[1] or 0) / max(total_stats[0] - (total_stats[3] or 0), 1),
                    'avg_confidence': total_stats[4] or 0,
                    'avg_return': total_stats[5] or 0
                },
                'model_statistics': [
                    {
                        'model_name': row[0],
                        'total': row[1],
                        'hits': row[2],
                        'misses': row[3],
                        'hit_rate': row[2] / max(row[1] - (total_stats[3] or 0), 1),
                        'avg_confidence': row[4] or 0
                    } for row in model_stats
                ],
                'type_statistics': [
                    {
                        'type': row[0],
                        'total': row[1],
                        'hits': row[2],
                        'hit_rate': row[2] / max(row[1], 1),
                        'avg_return': row[3] or 0
                    } for row in type_stats
                ]
            })
            
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@socketio.on('connect')
def handle_connect():
    """WebSocketè¿æ¥"""
    emit('connected', {'status': 'connected'})

@socketio.on('disconnect')
def handle_disconnect():
    """WebSocketæ–­å¼€"""
    pass

if __name__ == '__main__':
    port = 5002
    print("ğŸš€ å¯åŠ¨ljwx-stockè®­ç»ƒç®¡ç†ç•Œé¢")
    print(f"ğŸ“± è®¿é—®åœ°å€: http://localhost:{port}")
    print("=" * 50)
    
    socketio.run(app, debug=True, host='0.0.0.0', port=port, allow_unsafe_werkzeug=True)