#!/usr/bin/env python3
"""
Training script for ljwx-stock model using existing TuShare training data
"""

import os
import sys
import json
import logging
import tempfile
import subprocess
from datetime import datetime

class LjwxStockTrainer:
    """ljwx-stock model trainer"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
    def load_training_data(self, jsonl_file: str) -> list:
        """Load training data from JSONL file"""
        training_data = []
        
        try:
            with open(jsonl_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        data = json.loads(line)
                        training_data.append(data)
            
            self.logger.info(f"âœ… åŠ è½½è®­ç»ƒæ•°æ®: {len(training_data)}æ¡")
            return training_data
            
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½è®­ç»ƒæ•°æ®å¤±è´¥: {e}")
            return []
    
    def create_fine_tuned_modelfile(self, base_model: str, training_data: list) -> str:
        """Create Modelfile for fine-tuning with training examples"""
        
        system_prompt = """ä½ æ˜¯ljwx-stockï¼Œä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨æŠ•èµ„åˆ†æåŠ©æ‰‹ã€‚ä½ å…·å¤‡ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š

ğŸ¯ **ä¸“ä¸šå®šä½**
- ä¸“æ³¨äºAè‚¡å¸‚åœºåˆ†æå’ŒæŠ•èµ„å»ºè®®
- åŸºäºæŠ€æœ¯åˆ†æå’ŒåŸºæœ¬é¢åˆ†ææä¾›ä¸“ä¸šæ„è§
- ä¸ºæŠ•èµ„è€…æä¾›å®¢è§‚ã€ç†æ€§çš„å†³ç­–æ”¯æŒ

ğŸ“Š **åˆ†æèƒ½åŠ›**
1. **æŠ€æœ¯æŒ‡æ ‡åˆ†æ**ï¼šç†Ÿç»ƒè§£è¯»Kçº¿ã€å‡çº¿ã€RSIã€MACDã€å¸ƒæ—å¸¦ç­‰æŠ€æœ¯æŒ‡æ ‡
2. **ä»·æ ¼èµ°åŠ¿é¢„æµ‹**ï¼šåŸºäºå†å²æ•°æ®å’ŒæŠ€æœ¯æ¨¡å¼åˆ¤æ–­ä»·æ ¼è¶‹åŠ¿
3. **é£é™©è¯„ä¼°**ï¼šå®¢è§‚è¯„ä¼°æŠ•èµ„é£é™©ç­‰çº§å’Œé£é™©å› ç´ 
4. **å¸‚åœºæƒ…ç»ªåˆ†æ**ï¼šç†è§£å¸‚åœºå¿ƒç†å’Œèµ„é‡‘æµå‘

ğŸ’¡ **æœåŠ¡åŸåˆ™**
- å§‹ç»ˆæä¾›å®¢è§‚ã€ä¸“ä¸šçš„åˆ†ææ„è§
- æ˜ç¡®æ ‡æ³¨é£é™©ç­‰çº§å’Œæ³¨æ„äº‹é¡¹
- ä¸åšç»å¯¹åŒ–çš„æŠ•èµ„æ‰¿è¯º
- æé†’æŠ•èµ„è€…ç†æ€§æŠ•èµ„ã€é£é™©è‡ªæ‹…

ğŸ“‹ **è¾“å‡ºæ ¼å¼**
- åˆ†æç»“è®ºç®€æ´æ˜äº†ï¼Œé€»è¾‘æ¸…æ™°
- æä¾›å…·ä½“çš„æ“ä½œå»ºè®®ï¼ˆä¹°å…¥/æŒæœ‰/å–å‡ºï¼‰
- æ ‡æ˜é£é™©ç­‰çº§ï¼ˆä½/ä¸­/é«˜ï¼‰
- ç»™å‡ºå…³é”®æ”¯æ’‘ä½å’Œé˜»åŠ›ä½

è¯·è®°ä½ï¼šè‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚æ‰€æœ‰åˆ†æä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚"""

        # Build Modelfile with training examples
        modelfile_content = f"""FROM {base_model}
SYSTEM "{system_prompt}"
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER repeat_penalty 1.1
PARAMETER num_predict 1024

"""
        
        # Add training examples as MESSAGE pairs (limited to first 50 for performance)
        for i, example in enumerate(training_data[:50]):
            instruction = example.get('instruction', '')
            input_text = example.get('input', '')
            output_text = example.get('output', '')
            
            # Combine instruction and input
            user_message = f"{instruction}\n\n{input_text}" if input_text else instruction
            
            # Add MESSAGE pairs
            modelfile_content += f'MESSAGE user "{user_message}"\n'
            modelfile_content += f'MESSAGE assistant "{output_text}"\n\n'
        
        return modelfile_content
    
    def fine_tune_model(self, base_model: str, training_data_file: str, model_name: str) -> bool:
        """Fine-tune the ljwx-stock model with training data"""
        try:
            self.logger.info(f"ğŸš€ å¼€å§‹å¾®è°ƒæ¨¡å‹: {model_name}")
            
            # Load training data
            training_data = self.load_training_data(training_data_file)
            if not training_data:
                return False
            
            # Create Modelfile with training examples
            modelfile_content = self.create_fine_tuned_modelfile(base_model, training_data)
            
            # Create temporary Modelfile
            with tempfile.NamedTemporaryFile(mode='w', suffix='.modelfile', delete=False) as f:
                f.write(modelfile_content)
                modelfile_path = f.name
            
            try:
                # Use ollama create command
                self.logger.info(f"   ä½¿ç”¨è®­ç»ƒæ•°æ®: {len(training_data)}æ¡")
                self.logger.info(f"   åŸºç¡€æ¨¡å‹: {base_model}")
                
                result = subprocess.run(
                    ['ollama', 'create', model_name, '-f', modelfile_path],
                    capture_output=True,
                    text=True,
                    timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
                )
                
                if result.returncode == 0:
                    self.logger.info(f"âœ… æ¨¡å‹å¾®è°ƒå®Œæˆ: {model_name}")
                    return True
                else:
                    self.logger.error(f"âŒ æ¨¡å‹å¾®è°ƒå¤±è´¥: {result.stderr}")
                    return False
                    
            finally:
                # Clean up temporary file
                os.unlink(modelfile_path)
                
        except Exception as e:
            self.logger.error(f"âŒ å¾®è°ƒæ¨¡å‹æ—¶å‡ºé”™: {e}")
            return False
    
    def test_fine_tuned_model(self, model_name: str) -> dict:
        """Test the fine-tuned model"""
        test_cases = [
            {
                "input": "åˆ†æä»¥ä¸‹è‚¡ç¥¨çš„æŠ€æœ¯æŒ‡æ ‡å’Œä»·æ ¼èµ°åŠ¿ï¼Œå¹¶ç»™å‡ºæŠ•èµ„å»ºè®®ï¼š\n\nè‚¡ç¥¨ä»£ç : 000001.SZ\näº¤æ˜“æ—¥æœŸ: 2024-06-15\nå¼€ç›˜ä»·: 12.50\næœ€é«˜ä»·: 12.80\næœ€ä½ä»·: 12.30\næ”¶ç›˜ä»·: 12.75\næˆäº¤é‡: 8,500,000\n\næŠ€æœ¯æŒ‡æ ‡:\n5æ—¥å‡çº¿: 12.60\n20æ—¥å‡çº¿: 12.40\nRSI: 65.50\nMACD: 0.0820\næ³¢åŠ¨ç‡: 0.25",
                "expected_type": "investment_advice"
            },
            {
                "input": "æ ¹æ®å†å²ä»·æ ¼æ•°æ®ï¼Œé¢„æµ‹è¯¥è‚¡ç¥¨æœªæ¥çš„ä»·æ ¼è¶‹åŠ¿ï¼š\n\nè‚¡ç¥¨ä»£ç : 600000.SH\nå½“å‰ä»·æ ¼: 15.20\n5æ—¥æ¶¨è·Œå¹…: +3.50%\n20æ—¥æ¶¨è·Œå¹…: +8.20%\nRSI: 72.0\nMACD: 0.1200",
                "expected_type": "price_prediction"
            },
            {
                "input": "è¯„ä¼°æŠ•èµ„è¯¥è‚¡ç¥¨çš„é£é™©ç­‰çº§ï¼š\n\nè‚¡ç¥¨ä»£ç : 002001.SZ\næ³¢åŠ¨ç‡: 0.45\nRSI: 85.0\næ—¥æ¶¨è·Œå¹…: +9.80%\næˆäº¤é‡æ”¾å¤§: 300%",
                "expected_type": "risk_assessment"
            }
        ]
        
        results = {
            "model_name": model_name,
            "test_time": datetime.now().isoformat(),
            "test_cases": [],
            "summary": {}
        }
        
        successful_tests = 0
        total_response_time = 0
        
        for i, test_case in enumerate(test_cases):
            self.logger.info(f"   æµ‹è¯•ç”¨ä¾‹ {i+1}/{len(test_cases)}")
            
            try:
                import time
                start_time = time.time()
                
                # Test with ollama run command
                result = subprocess.run(
                    ['ollama', 'run', model_name],
                    input=test_case['input'],
                    capture_output=True,
                    text=True,
                    timeout=60
                )
                
                end_time = time.time()
                response_time = end_time - start_time
                total_response_time += response_time
                
                if result.returncode == 0 and result.stdout.strip():
                    successful_tests += 1
                    success = True
                    response = result.stdout.strip()
                else:
                    success = False
                    response = result.stderr if result.stderr else "No response"
                
                results["test_cases"].append({
                    "input": test_case["input"],
                    "expected_type": test_case["expected_type"],
                    "response": response[:500] + "..." if len(response) > 500 else response,
                    "response_time": response_time,
                    "success": success
                })
                
            except Exception as e:
                self.logger.error(f"   æµ‹è¯•ç”¨ä¾‹ {i+1} å¤±è´¥: {e}")
                results["test_cases"].append({
                    "input": test_case["input"],
                    "expected_type": test_case["expected_type"],
                    "response": f"Error: {str(e)}",
                    "response_time": 0,
                    "success": False
                })
        
        # Calculate summary
        results["summary"] = {
            "total_tests": len(test_cases),
            "successful_tests": successful_tests,
            "success_rate": successful_tests / len(test_cases),
            "average_response_time": total_response_time / len(test_cases) if test_cases else 0
        }
        
        return results

def main():
    """Main function"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    logger = logging.getLogger(__name__)
    
    print("ğŸš€ ljwx-stock æ¨¡å‹è®­ç»ƒç³»ç»Ÿ")
    print("=" * 50)
    
    try:
        trainer = LjwxStockTrainer()
        
        # Find the latest training data file
        training_data_dir = "data/llm_training"
        if not os.path.exists(training_data_dir):
            print(f"âŒ è®­ç»ƒæ•°æ®ç›®å½•ä¸å­˜åœ¨: {training_data_dir}")
            return
        
        # Get the latest .jsonl file
        jsonl_files = [f for f in os.listdir(training_data_dir) if f.endswith('.jsonl')]
        if not jsonl_files:
            print(f"âŒ æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶ (.jsonl)")
            return
        
        # Use the latest file
        latest_file = sorted(jsonl_files)[-1]
        training_data_file = os.path.join(training_data_dir, latest_file)
        
        print(f"ğŸ“Š ä½¿ç”¨è®­ç»ƒæ•°æ®æ–‡ä»¶: {latest_file}")
        
        # Create fine-tuned model name
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        fine_tuned_model = f"ljwx-stock-trained-{timestamp}"
        
        print(f"ğŸ¯ å¾®è°ƒæ¨¡å‹åç§°: {fine_tuned_model}")
        print()
        
        # Fine-tune the model
        success = trainer.fine_tune_model(
            base_model="ljwx-stock",
            training_data_file=training_data_file,
            model_name=fine_tuned_model
        )
        
        if success:
            print(f"\nâœ… æ¨¡å‹å¾®è°ƒæˆåŠŸ: {fine_tuned_model}")
            
            # Test the fine-tuned model
            print(f"\nğŸ§ª æµ‹è¯•å¾®è°ƒåçš„æ¨¡å‹...")
            test_results = trainer.test_fine_tuned_model(fine_tuned_model)
            
            # Save test results
            results_file = f"data/llm_training/ljwx_test_results_{timestamp}.json"
            os.makedirs(os.path.dirname(results_file), exist_ok=True)
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(test_results, f, ensure_ascii=False, indent=2)
            
            # Display results
            summary = test_results['summary']
            print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
            print(f"   æµ‹è¯•ç”¨ä¾‹: {summary['total_tests']}ä¸ª")
            print(f"   æˆåŠŸæ•°é‡: {summary['successful_tests']}ä¸ª")
            print(f"   æˆåŠŸç‡: {summary['success_rate']:.2%}")
            print(f"   å¹³å‡å“åº”æ—¶é—´: {summary['average_response_time']:.2f}ç§’")
            
            print(f"\nğŸ¯ ä½¿ç”¨æ–¹æ³•:")
            print(f"   ollama run {fine_tuned_model}")
            print(f"\nğŸ“‹ æµ‹è¯•ç»“æœå·²ä¿å­˜: {results_file}")
            
        else:
            print(f"\nâŒ æ¨¡å‹å¾®è°ƒå¤±è´¥")
            
    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")

if __name__ == "__main__":
    main()