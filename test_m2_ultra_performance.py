#!/usr/bin/env python3
"""
M2 Ultraæ€§èƒ½æµ‹è¯•å’ŒåŸºå‡†æµ‹è¯•è„šæœ¬
æµ‹è¯•ä¼˜åŒ–åçš„AIè®­ç»ƒç³»ç»Ÿåœ¨M2 Ultraä¸Šçš„æ€§èƒ½è¡¨ç°
"""

import time
import numpy as np
import pandas as pd
from datetime import datetime
import logging
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils.m2_ultra_config import M2UltraConfig, get_optimal_config
from utils.performance_monitor import M2UltraPerformanceMonitor
from ai.unified_trainer import unified_trainer

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/m2_ultra_benchmark.log')
    ]
)
logger = logging.getLogger(__name__)

def cpu_intensive_task(n):
    """CPUå¯†é›†å‹ä»»åŠ¡ - ç§»åˆ°æ¨¡å—çº§åˆ«ä»¥æ”¯æŒmultiprocessing pickling"""
    return sum(i*i for i in range(n))

class M2UltraBenchmark:
    """M2 UltraåŸºå‡†æµ‹è¯•"""
    
    def __init__(self):
        self.config = M2UltraConfig()
        self.monitor = M2UltraPerformanceMonitor(log_interval=0.5)
        self.results = {}
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        os.makedirs('logs', exist_ok=True)
        
        logger.info("ğŸš€ M2 UltraåŸºå‡†æµ‹è¯•åˆå§‹åŒ–å®Œæˆ")
        
    def run_all_benchmarks(self):
        """è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•"""
        logger.info("å¼€å§‹è¿è¡ŒM2 UltraåŸºå‡†æµ‹è¯•å¥—ä»¶")
        
        # æ‰“å°ç³»ç»Ÿä¿¡æ¯
        self.config.print_system_info()
        
        # å¯åŠ¨æ€§èƒ½ç›‘æ§
        self.monitor.start_monitoring()
        
        try:
            # æµ‹è¯•1: é…ç½®åŠ è½½æ€§èƒ½
            self.test_config_loading()
            
            # æµ‹è¯•2: æ•°æ®å¤„ç†æ€§èƒ½
            self.test_data_processing()
            
            # æµ‹è¯•3: æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒæ€§èƒ½
            self.test_ml_training()
            
            # æµ‹è¯•4: å†…å­˜åˆ©ç”¨ç‡æµ‹è¯•
            self.test_memory_utilization()
            
            # æµ‹è¯•5: å¹¶è¡Œå¤„ç†æ€§èƒ½
            self.test_parallel_processing()
            
            # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            self.generate_performance_report()
            
        finally:
            self.monitor.stop_monitoring()
    
    def test_config_loading(self):
        """æµ‹è¯•é…ç½®åŠ è½½æ€§èƒ½"""
        logger.info("ğŸ“‹ æµ‹è¯•1: é…ç½®åŠ è½½æ€§èƒ½")
        
        start_time = time.time()
        
        # æµ‹è¯•å„ç§é…ç½®åŠ è½½
        configs = {}
        task_types = ['data_processing', 'traditional_ml', 'deep_learning', 'model_optimization']
        
        for task_type in task_types:
            config_start = time.time()
            configs[task_type] = get_optimal_config(task_type)
            config_time = time.time() - config_start
            logger.info(f"  {task_type}é…ç½®åŠ è½½: {config_time*1000:.2f}ms")
        
        # æµ‹è¯•ä¸“ç”¨é…ç½®
        xgb_config = self.config.get_xgboost_config()
        lgb_config = self.config.get_lightgbm_config()
        pytorch_config = self.config.get_pytorch_config()
        
        total_time = time.time() - start_time
        
        self.results['config_loading'] = {
            'total_time_ms': total_time * 1000,
            'configs_loaded': len(configs) + 3,
            'avg_time_per_config_ms': (total_time * 1000) / (len(configs) + 3),
            'is_m2_ultra': self.config.is_m2_ultra
        }
        
        logger.info(f"âœ… é…ç½®åŠ è½½æµ‹è¯•å®Œæˆ: {total_time*1000:.2f}ms")
    
    def test_data_processing(self):
        """æµ‹è¯•æ•°æ®å¤„ç†æ€§èƒ½"""
        logger.info("ğŸ“Š æµ‹è¯•2: æ•°æ®å¤„ç†æ€§èƒ½")
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        data_sizes = [1000, 5000, 10000, 50000]
        processing_results = {}
        
        for size in data_sizes:
            logger.info(f"  æµ‹è¯•æ•°æ®å¤§å°: {size}")
            
            # ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®
            start_time = time.time()
            
            test_data = pd.DataFrame({
                'close': np.random.randn(size) * 100 + 1000,
                'volume': np.random.randint(1000, 100000, size),
                'high': np.random.randn(size) * 100 + 1020,
                'low': np.random.randn(size) * 100 + 980,
                'open': np.random.randn(size) * 100 + 1000,
            })
            
            # æ•°æ®å¤„ç†æ“ä½œ
            processed_data = self._process_test_data(test_data)
            
            processing_time = time.time() - start_time
            throughput = size / processing_time
            
            processing_results[size] = {
                'processing_time_ms': processing_time * 1000,
                'throughput_rows_per_sec': throughput,
                'memory_usage_mb': test_data.memory_usage(deep=True).sum() / (1024**2)
            }
            
            logger.info(f"    å¤„ç†æ—¶é—´: {processing_time*1000:.2f}ms, ååé‡: {throughput:.0f} rows/sec")
        
        self.results['data_processing'] = processing_results
        logger.info("âœ… æ•°æ®å¤„ç†æ€§èƒ½æµ‹è¯•å®Œæˆ")
    
    def _process_test_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†æµ‹è¯•æ•°æ®"""
        # æ¨¡æ‹ŸçœŸå®çš„æ•°æ®å¤„ç†æ“ä½œ
        data['returns'] = data['close'].pct_change()
        data['ma5'] = data['close'].rolling(5).mean()
        data['ma20'] = data['close'].rolling(20).mean()
        data['volatility'] = data['returns'].rolling(20).std()
        data['rsi'] = self._calculate_rsi(data['close'])
        
        return data.fillna(0)
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—RSIæŒ‡æ ‡"""
        delta = prices.diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        
        avg_gain = gain.rolling(period).mean()
        avg_loss = loss.rolling(period).mean()
        
        rs = avg_gain / avg_loss
        rsi = 100 - (100 / (1 + rs))
        
        return rsi
    
    def test_ml_training(self):
        """æµ‹è¯•æœºå™¨å­¦ä¹ è®­ç»ƒæ€§èƒ½"""
        logger.info("ğŸ¤– æµ‹è¯•3: æœºå™¨å­¦ä¹ è®­ç»ƒæ€§èƒ½")
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®é›†
        sample_sizes = [1000, 5000, 10000]
        feature_counts = [50, 100, 200]
        
        ml_results = {}
        
        for n_samples in sample_sizes:
            for n_features in feature_counts:
                test_key = f"{n_samples}x{n_features}"
                logger.info(f"  æµ‹è¯•: {test_key} (samples x features)")
                
                # ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
                X = np.random.randn(n_samples, n_features)
                y = np.random.randint(0, 3, n_samples)  # 3åˆ†ç±»
                
                # æµ‹è¯•è®­ç»ƒæ—¶é—´
                start_time = time.time()
                
                # ä½¿ç”¨sklearnæ¨¡å‹å¿«é€Ÿæµ‹è¯•
                from sklearn.ensemble import RandomForestClassifier
                from sklearn.model_selection import cross_val_score
                
                # è·å–M2ä¼˜åŒ–é…ç½®
                ml_config = get_optimal_config('traditional_ml')
                n_jobs = ml_config.get('sklearn_jobs', -1)
                
                # è®­ç»ƒéšæœºæ£®æ—
                rf = RandomForestClassifier(
                    n_estimators=50,
                    n_jobs=n_jobs,
                    random_state=42
                )
                
                # äº¤å‰éªŒè¯
                scores = cross_val_score(rf, X, y, cv=3, n_jobs=n_jobs)
                
                training_time = time.time() - start_time
                
                ml_results[test_key] = {
                    'training_time_ms': training_time * 1000,
                    'samples_per_second': n_samples / training_time,
                    'cv_score_mean': scores.mean(),
                    'cv_score_std': scores.std(),
                    'n_jobs_used': n_jobs
                }
                
                logger.info(f"    è®­ç»ƒæ—¶é—´: {training_time*1000:.2f}ms, "
                           f"CVåˆ†æ•°: {scores.mean():.3f}Â±{scores.std():.3f}")
        
        self.results['ml_training'] = ml_results
        logger.info("âœ… æœºå™¨å­¦ä¹ è®­ç»ƒæ€§èƒ½æµ‹è¯•å®Œæˆ")
    
    def test_memory_utilization(self):
        """æµ‹è¯•å†…å­˜åˆ©ç”¨ç‡"""
        logger.info("ğŸ’¾ æµ‹è¯•4: å†…å­˜åˆ©ç”¨ç‡æµ‹è¯•")
        
        # è·å–å†…å­˜é…ç½®
        memory_config = self.config.get_memory_config()
        current_metrics = self.monitor.get_current_metrics()
        
        memory_info = current_metrics.get('memory', {})
        
        memory_results = {
            'total_memory_gb': memory_info.get('total_gb', 0),
            'available_memory_gb': memory_info.get('available_gb', 0),
            'used_memory_gb': memory_info.get('used_gb', 0),
            'memory_usage_percent': memory_info.get('usage_percent', 0),
            'cache_size_gb': memory_config.get('cache_size_gb', 0),
            'max_memory_usage_allowed': memory_config.get('max_memory_usage', 0),
            'memory_optimization_enabled': memory_config.get('enable_memory_mapping', False)
        }
        
        # å†…å­˜åˆ©ç”¨ç‡è¯„ä¼°
        available_ratio = memory_results['available_memory_gb'] / memory_results['total_memory_gb']
        utilization_efficiency = 1 - available_ratio
        
        memory_results['utilization_efficiency'] = utilization_efficiency
        memory_results['memory_optimization_score'] = min(100, utilization_efficiency * 100)
        
        self.results['memory_utilization'] = memory_results
        
        logger.info(f"  æ€»å†…å­˜: {memory_results['total_memory_gb']:.1f}GB")
        logger.info(f"  å¯ç”¨å†…å­˜: {memory_results['available_memory_gb']:.1f}GB")
        logger.info(f"  å†…å­˜åˆ©ç”¨ç‡: {memory_results['memory_usage_percent']:.1f}%")
        logger.info(f"  ä¼˜åŒ–åˆ†æ•°: {memory_results['memory_optimization_score']:.1f}/100")
        logger.info("âœ… å†…å­˜åˆ©ç”¨ç‡æµ‹è¯•å®Œæˆ")
    
    def test_parallel_processing(self):
        """æµ‹è¯•å¹¶è¡Œå¤„ç†æ€§èƒ½"""
        logger.info("âš¡ æµ‹è¯•5: å¹¶è¡Œå¤„ç†æ€§èƒ½")
        
        from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
        import multiprocessing as mp
        
        # è·å–å¹¶è¡Œé…ç½®
        parallel_config = self.config.get_parallel_config()
        max_workers = parallel_config.get('max_workers', 4)
        
        task_sizes = [10000, 50000, 100000]
        parallel_results = {}
        
        for task_size in task_sizes:
            logger.info(f"  æµ‹è¯•ä»»åŠ¡å¤§å°: {task_size}")
            
            # ä¸²è¡Œæ‰§è¡Œ
            start_time = time.time()
            serial_results = [cpu_intensive_task(task_size) for _ in range(8)]
            serial_time = time.time() - start_time
            
            # å¹¶è¡Œæ‰§è¡Œ (è¿›ç¨‹æ± )
            start_time = time.time()
            with ProcessPoolExecutor(max_workers=max_workers) as executor:
                parallel_results_proc = list(executor.map(cpu_intensive_task, [task_size] * 8))
            parallel_time_proc = time.time() - start_time
            
            # å¹¶è¡Œæ‰§è¡Œ (çº¿ç¨‹æ± )
            start_time = time.time()
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                parallel_results_thread = list(executor.map(cpu_intensive_task, [task_size] * 8))
            parallel_time_thread = time.time() - start_time
            
            speedup_proc = serial_time / parallel_time_proc
            speedup_thread = serial_time / parallel_time_thread
            
            parallel_results[task_size] = {
                'serial_time_ms': serial_time * 1000,
                'parallel_time_proc_ms': parallel_time_proc * 1000,
                'parallel_time_thread_ms': parallel_time_thread * 1000,
                'speedup_process': speedup_proc,
                'speedup_thread': speedup_thread,
                'max_workers_used': max_workers,
                'efficiency_process': speedup_proc / max_workers,
                'efficiency_thread': speedup_thread / max_workers
            }
            
            logger.info(f"    è¿›ç¨‹æ± åŠ é€Ÿæ¯”: {speedup_proc:.2f}x, æ•ˆç‡: {speedup_proc/max_workers:.2f}")
            logger.info(f"    çº¿ç¨‹æ± åŠ é€Ÿæ¯”: {speedup_thread:.2f}x, æ•ˆç‡: {speedup_thread/max_workers:.2f}")
        
        self.results['parallel_processing'] = parallel_results
        logger.info("âœ… å¹¶è¡Œå¤„ç†æ€§èƒ½æµ‹è¯•å®Œæˆ")
    
    def generate_performance_report(self):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š")
        
        # è·å–æ•ˆç‡æŠ¥å‘Š
        efficiency_report = self.monitor.get_m2_ultra_efficiency_report()
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report = {
            'benchmark_info': {
                'timestamp': datetime.now().isoformat(),
                'system_info': {
                    'is_m2_ultra': self.config.is_m2_ultra,
                    'cpu_cores': self.config.cpu_count,
                    'available_memory_gb': self.config.available_memory,
                },
                'test_duration_minutes': 10  # ä¼°ç®—
            },
            'performance_results': self.results,
            'efficiency_report': efficiency_report,
            'recommendations': self._generate_recommendations()
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = f"logs/m2_ultra_benchmark_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        import json
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # æ‰“å°æ‘˜è¦
        self._print_performance_summary(report)
        
        logger.info(f"âœ… æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    
    def _generate_recommendations(self) -> list:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if self.config.is_m2_ultra:
            recommendations.extend([
                "M2 Ultraå·²å¯ç”¨ï¼Œæ€§èƒ½ä¼˜åŒ–é…ç½®ç”Ÿæ•ˆ",
                "å»ºè®®ä½¿ç”¨MPSè¿›è¡Œæ·±åº¦å­¦ä¹ åŠ é€Ÿ",
                "å……åˆ†åˆ©ç”¨192GBå¤§å†…å­˜ä¼˜åŠ¿"
            ])
        else:
            recommendations.extend([
                "å½“å‰ç³»ç»Ÿä¸æ˜¯M2 Ultraï¼Œä½¿ç”¨é€šç”¨ä¼˜åŒ–é…ç½®",
                "è€ƒè™‘å‡çº§åˆ°Apple Siliconè·å¾—æ›´å¥½æ€§èƒ½",
                "åœ¨å½“å‰ç¡¬ä»¶ä¸Šå·²åº”ç”¨æœ€ä¼˜é…ç½®"
            ])
        
        # åŸºäºæµ‹è¯•ç»“æœçš„å»ºè®®
        if 'parallel_processing' in self.results:
            avg_efficiency = np.mean([
                result.get('efficiency_process', 0) 
                for result in self.results['parallel_processing'].values()
            ])
            
            if avg_efficiency < 0.5:
                recommendations.append("å¹¶è¡Œæ•ˆç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥ä»»åŠ¡ç²’åº¦å’Œè´Ÿè½½å‡è¡¡")
            elif avg_efficiency > 0.8:
                recommendations.append("å¹¶è¡Œæ•ˆç‡å¾ˆé«˜ï¼Œå½“å‰é…ç½®æ•ˆæœè‰¯å¥½")
        
        return recommendations
    
    def _print_performance_summary(self, report: dict):
        """æ‰“å°æ€§èƒ½æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ† M2 Ultra æ€§èƒ½æµ‹è¯•æŠ¥å‘Šæ‘˜è¦")
        print("="*60)
        
        system_info = report['benchmark_info']['system_info']
        print(f"ç³»ç»Ÿç±»å‹: {'M2 Ultra' if system_info['is_m2_ultra'] else 'å…¶ä»–'}")
        print(f"CPUæ ¸å¿ƒ: {system_info['cpu_cores']}")
        print(f"å¯ç”¨å†…å­˜: {system_info['available_memory_gb']:.1f} GB")
        
        # æ€§èƒ½äº®ç‚¹
        if 'ml_training' in self.results:
            ml_results = self.results['ml_training']
            best_throughput = max([r.get('samples_per_second', 0) for r in ml_results.values()])
            print(f"æœ€å¤§è®­ç»ƒååé‡: {best_throughput:.0f} samples/sec")
        
        if 'parallel_processing' in self.results:
            parallel_results = self.results['parallel_processing']
            best_speedup = max([r.get('speedup_process', 0) for r in parallel_results.values()])
            print(f"æœ€å¤§å¹¶è¡ŒåŠ é€Ÿæ¯”: {best_speedup:.2f}x")
        
        # æ•ˆç‡æŠ¥å‘Š
        efficiency_report = report.get('efficiency_report', {})
        if efficiency_report:
            overall_eff = efficiency_report.get('overall_efficiency', 0)
            print(f"æ•´ä½“æ•ˆç‡åˆ†æ•°: {overall_eff:.1f}%")
        
        # å»ºè®®
        recommendations = report.get('recommendations', [])
        if recommendations:
            print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            for i, rec in enumerate(recommendations[:5], 1):
                print(f"  {i}. {rec}")
        
        print("="*60)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨M2 Ultraæ€§èƒ½åŸºå‡†æµ‹è¯•")
    
    try:
        benchmark = M2UltraBenchmark()
        benchmark.run_all_benchmarks()
        
        print("\nâœ… æ‰€æœ‰åŸºå‡†æµ‹è¯•å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    main()