#!/usr/bin/env python3
"""
å¿«é€Ÿæ•°æ®åŒæ­¥å·¥å…· - ç«‹å³è·å–æœ€æ–°è‚¡ç¥¨æ•°æ®
"""

import sys
import os
import logging
from datetime import datetime, timedelta
import pandas as pd
import tushare as ts
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import config
from database.db_manager import DatabaseManager

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class QuickDataSync:
    """å¿«é€Ÿæ•°æ®åŒæ­¥"""
    
    def __init__(self):
        self.db = DatabaseManager()
        self.ts_api = ts.pro_api(config.TS_TOKEN)
        
    def sync_latest_data(self, days: int = 30):
        """åŒæ­¥æœ€æ–°æ•°æ®"""
        logger.info(f"ğŸš€ å¼€å§‹åŒæ­¥æœ€è¿‘ {days} å¤©çš„è‚¡ç¥¨æ•°æ®")
        
        # 1. æ›´æ–°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        self._update_stock_basic()
        
        # 2. è·å–è‚¡ç¥¨åˆ—è¡¨
        stocks = self._get_stock_list()
        logger.info(f"ğŸ“Š è·å–åˆ° {len(stocks)} åªè‚¡ç¥¨")
        
        # 3. å¹¶è¡Œæ›´æ–°æ—¥çº¿æ•°æ®
        self._parallel_update_daily_data(stocks, days)
        
        logger.info("âœ… æ•°æ®åŒæ­¥å®Œæˆ")
    
    def _update_stock_basic(self):
        """æ›´æ–°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        logger.info("ğŸ“‹ æ›´æ–°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
        
        try:
            # è·å–Aè‚¡åŸºæœ¬ä¿¡æ¯
            stock_basic = self.ts_api.stock_basic(exchange='', list_status='L')
            
            if not stock_basic.empty:
                # æ¸…ç©ºæ—§æ•°æ®å¹¶æ’å…¥æ–°æ•°æ®
                self.db.execute_sql("TRUNCATE TABLE stock_basic")
                self.db.insert_dataframe('stock_basic', stock_basic)
                logger.info(f"âœ… è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æ›´æ–°å®Œæˆ: {len(stock_basic)} æ¡")
            else:
                logger.warning("âš ï¸ æœªè·å–åˆ°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
                
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
    
    def _get_stock_list(self) -> list:
        """è·å–è‚¡ç¥¨åˆ—è¡¨"""
        try:
            sql = """
            SELECT ts_code, name, industry, list_date 
            FROM stock_basic 
            WHERE list_status = 'L' 
            AND ts_code LIKE '%.SZ' OR ts_code LIKE '%.SH'
            ORDER BY ts_code
            """
            df = self.db.fetch_data(sql)
            return df['ts_code'].tolist() if not df.empty else []
        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def _parallel_update_daily_data(self, stocks: list, days: int):
        """å¹¶è¡Œæ›´æ–°æ—¥çº¿æ•°æ®"""
        logger.info(f"ğŸ”„ å¼€å§‹å¹¶è¡Œæ›´æ–° {len(stocks)} åªè‚¡ç¥¨çš„æ—¥çº¿æ•°æ®")
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=days)).strftime('%Y%m%d')
        
        # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…APIé™åˆ¶
        batch_size = config.TS_BATCH_SIZE
        total_updated = 0
        
        for i in range(0, len(stocks), batch_size):
            batch = stocks[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(stocks) + batch_size - 1) // batch_size
            
            logger.info(f"ğŸ“¦ å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch)} åªè‚¡ç¥¨)")
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
            with ThreadPoolExecutor(max_workers=config.TS_THREAD_COUNT) as executor:
                future_to_stock = {
                    executor.submit(self._update_single_stock, ts_code, start_date, end_date): ts_code 
                    for ts_code in batch
                }
                
                batch_success = 0
                for future in as_completed(future_to_stock):
                    ts_code = future_to_stock[future]
                    try:
                        success = future.result(timeout=30)
                        if success:
                            batch_success += 1
                    except Exception as e:
                        logger.error(f"âŒ æ›´æ–° {ts_code} å¤±è´¥: {e}")
                
                total_updated += batch_success
                logger.info(f"âœ… æ‰¹æ¬¡ {batch_num} å®Œæˆ: {batch_success}/{len(batch)} æˆåŠŸ")
            
            # æ‰¹æ¬¡é—´çŸ­æš‚ä¼‘æ¯
            if batch_num < total_batches:
                import time
                time.sleep(0.5)
        
        logger.info(f"ğŸ‰ æ•°æ®æ›´æ–°å®Œæˆ: {total_updated}/{len(stocks)} æˆåŠŸ")
    
    def _update_single_stock(self, ts_code: str, start_date: str, end_date: str) -> bool:
        """æ›´æ–°å•åªè‚¡ç¥¨æ•°æ®"""
        try:
            # è·å–æ—¥çº¿æ•°æ®
            df = self.ts_api.daily(
                ts_code=ts_code, 
                start_date=start_date, 
                end_date=end_date
            )
            
            if not df.empty:
                # æ·»åŠ æ•°æ®å¤„ç†å­—æ®µ
                df['change'] = df['close'] - df['pre_close']
                df['change_pct'] = df['pct_chg']
                df['created_at'] = datetime.now()
                
                # æ’å…¥æ•°æ®åº“ (ä½¿ç”¨ REPLACE INTO é¿å…é‡å¤)
                self.db.insert_dataframe('daily_data', df, replace=True)
                return True
            else:
                logger.warning(f"âš ï¸ {ts_code} æ— æ•°æ®")
                return False
                
        except Exception as e:
            logger.error(f"âŒ æ›´æ–° {ts_code} å¤±è´¥: {e}")
            return False
    
    def sync_specific_stocks(self, stock_codes: list, days: int = 30):
        """åŒæ­¥æŒ‡å®šè‚¡ç¥¨æ•°æ®"""
        logger.info(f"ğŸ¯ åŒæ­¥æŒ‡å®šè‚¡ç¥¨æ•°æ®: {stock_codes}")
        self._parallel_update_daily_data(stock_codes, days)
    
    def get_data_summary(self):
        """è·å–æ•°æ®æ¦‚è§ˆ"""
        try:
            # è‚¡ç¥¨æ€»æ•°
            stock_count_sql = "SELECT COUNT(*) as count FROM stock_basic WHERE list_status = 'L'"
            stock_count = self.db.fetch_data(stock_count_sql).iloc[0]['count']
            
            # æœ€æ–°æ•°æ®æ—¥æœŸ
            latest_date_sql = "SELECT MAX(trade_date) as latest_date FROM daily_data"
            latest_date = self.db.fetch_data(latest_date_sql).iloc[0]['latest_date']
            
            # æ•°æ®æ€»é‡
            data_count_sql = "SELECT COUNT(*) as count FROM daily_data"
            data_count = self.db.fetch_data(data_count_sql).iloc[0]['count']
            
            # ä»Šæ—¥æ›´æ–°è‚¡ç¥¨æ•°
            today = datetime.now().strftime('%Y-%m-%d')
            today_update_sql = f"SELECT COUNT(DISTINCT ts_code) as count FROM daily_data WHERE DATE(created_at) = '{today}'"
            today_updates = self.db.fetch_data(today_update_sql).iloc[0]['count']
            
            summary = {
                'total_stocks': stock_count,
                'latest_data_date': str(latest_date),
                'total_data_records': data_count,
                'today_updated_stocks': today_updates
            }
            
            logger.info("ğŸ“Š æ•°æ®æ¦‚è§ˆ:")
            logger.info(f"   æ€»è‚¡ç¥¨æ•°: {summary['total_stocks']}")
            logger.info(f"   æœ€æ–°æ•°æ®æ—¥æœŸ: {summary['latest_data_date']}")
            logger.info(f"   æ€»æ•°æ®è®°å½•: {summary['total_data_records']:,}")
            logger.info(f"   ä»Šæ—¥æ›´æ–°è‚¡ç¥¨: {summary['today_updated_stocks']}")
            
            return summary
            
        except Exception as e:
            logger.error(f"è·å–æ•°æ®æ¦‚è§ˆå¤±è´¥: {e}")
            return {}

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='è‚¡ç¥¨æ•°æ®å¿«é€ŸåŒæ­¥å·¥å…·')
    parser.add_argument('--days', type=int, default=30, help='åŒæ­¥å¤©æ•° (é»˜è®¤30å¤©)')
    parser.add_argument('--stocks', nargs='*', help='æŒ‡å®šè‚¡ç¥¨ä»£ç  (å¯é€‰)')
    parser.add_argument('--summary', action='store_true', help='æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ')
    
    args = parser.parse_args()
    
    sync = QuickDataSync()
    
    try:
        if args.summary:
            sync.get_data_summary()
        elif args.stocks:
            sync.sync_specific_stocks(args.stocks, args.days)
        else:
            sync.sync_latest_data(args.days)
            sync.get_data_summary()
            
    except KeyboardInterrupt:
        logger.info("âŒ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"âŒ åŒæ­¥å¤±è´¥: {e}")

if __name__ == "__main__":
    main()