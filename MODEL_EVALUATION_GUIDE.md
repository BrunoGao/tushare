# ljwx-stock 模型效果验证系统

## 系统概述

已成功实现完整的模型评估框架，用于验证训练后的ljwx-stock模型效果。系统提供全面的测试用例、性能指标和可视化界面，帮助用户了解模型的训练质量和实际表现。

## 核心功能

### 1. 评估框架 (`model_evaluation/evaluation_framework.py`)
- **测试用例管理**: 17个预定义测试用例，涵盖6大类别
- **多维度评估**: 关键词匹配、情感分析、相关性、连贯性、准确性
- **性能监控**: 响应时间、成功率、总体分数统计
- **数据持久化**: SQLite数据库存储评估历史

### 2. 测试类别
- **技术分析**: RSI、MACD、均线等技术指标分析
- **风险评估**: 高波动、新股等风险识别
- **市场情绪**: 牛熊市场情绪判断
- **投资策略**: 资金配置、策略对比
- **基本面分析**: PE、ROE等财务指标评估
- **边界测试**: 异常输入处理能力

### 3. Web界面功能
- **模型选择**: 自动检测可用的ljwx-stock模型
- **评估配置**: 类别筛选、难度选择、超时设置
- **实时监控**: WebSocket实时显示评估进度
- **结果可视化**: 分类性能图表、成功率指标
- **快速测试**: 单次问答测试功能
- **模型对比**: 多模型性能横向比较

### 4. 评估指标
- **总体分数**: 0-1分制综合评分
- **成功率**: 通过测试用例比例
- **响应时间**: 平均、最小、最大响应时间
- **分类表现**: 各测试类别得分统计
- **难度分析**: 不同难度级别表现对比

## 使用方法

### 启动评估系统
1. 确保已安装依赖: `pip install -r web_interface/requirements.txt`
2. 启动Web界面: `python web_interface/app.py`
3. 访问: `http://localhost:5002`
4. 进入"效果监控"标签页

### 运行模型评估
1. **选择模型**: 从下拉列表选择要评估的模型
2. **配置参数**: 
   - 测试类别: 全部或特定类别
   - 难度等级: 简单/中等/困难
   - 超时时间: 10-120秒
3. **开始评估**: 点击"开始评估"按钮
4. **查看结果**: 实时监控进度，完成后查看详细结果

### 快速测试
1. 选择模型
2. 输入测试问题
3. 点击"测试"查看模型回答
4. 查看响应时间和回答质量

### 模型对比
1. 点击"模型对比"按钮
2. 选择2个或更多模型
3. 查看横向对比结果

## 技术实现

### 后端架构
- **Flask应用**: RESTful API + WebSocket实时通信
- **评估引擎**: 多线程异步执行评估任务
- **指标计算**: NumPy统计分析
- **数据存储**: SQLite轻量级数据库

### 前端界面
- **Bootstrap 5**: 响应式现代化界面
- **Chart.js**: 性能数据可视化
- **WebSocket**: 实时进度更新
- **模态框**: 测试用例查看、模型对比

### 评估算法
- **关键词匹配**: 期望关键词出现比例
- **情感分析**: 正面/负面/中性词汇检测
- **相关性评分**: 金融词汇密度 + 回答长度合理性
- **连贯性评分**: 完整句子 + 逻辑连接词
- **准确性评分**: 难度权重 + 专业术语 + 错误检测

## 测试用例示例

### 技术分析类 (中等难度)
```
输入: 平安银行(000001.SZ)当前价格12.50元，5日均线12.30，20日均线12.10，RSI为65，MACD为0.08，成交量放大，请分析投资机会
期望: 包含"均线"、"RSI"、"MACD"、"成交量"、"投资"、"分析"等关键词
情感: 积极
```

### 风险评估类 (简单难度)
```
输入: 某股票一天内涨停又跌停，波动率极大，投资风险如何？
期望: 包含"涨停"、"跌停"、"波动率"、"风险"、"高风险"等关键词
情感: 消极
```

## 性能标准

### 评分标准
- **优秀**: 总体分数 ≥ 0.8
- **良好**: 总体分数 ≥ 0.6
- **需改进**: 总体分数 < 0.6

### 响应时间
- **快速**: < 5秒
- **正常**: 5-15秒  
- **较慢**: > 15秒

### 成功率期望
- **生产就绪**: 成功率 ≥ 80%
- **测试阶段**: 成功率 ≥ 60%
- **开发阶段**: 成功率 ≥ 40%

## 扩展功能

### 可添加功能
1. **自定义测试用例**: 用户自定义问题和期望答案
2. **A/B测试**: 多版本模型并行测试
3. **批量评估**: 定时自动评估任务
4. **详细报告**: PDF格式评估报告导出
5. **API集成**: 外部系统调用评估接口

### 监控集成
- **告警系统**: 性能下降自动通知
- **趋势分析**: 历史性能变化趋势
- **基准测试**: 与标准模型对比

## 注意事项

1. **模型要求**: 确保Ollama中有可用的ljwx-stock模型
2. **资源占用**: 评估过程会占用CPU和内存资源
3. **超时设置**: 根据模型复杂度调整合理超时时间
4. **网络连接**: 部分功能需要稳定的网络连接
5. **数据备份**: 定期备份评估历史数据

## 总结

该评估系统提供了完整的模型质量验证解决方案，从测试用例设计到结果可视化，全面覆盖了模型评估的各个环节。通过客观的指标和直观的界面，帮助开发者和用户了解模型的实际表现，为模型优化提供数据支持。